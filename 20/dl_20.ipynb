{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your Recurrent Neural Network: Step by Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dinos.txt\", \"r\") as file:\n",
    "    data = file.readlines()\n",
    "    data = '<eos>'.join(data).lower()\n",
    "    data = data.split('<eos>')\n",
    "    random.shuffle(data)\n",
    "\n",
    "chars = ''.join(data)\n",
    "vocab = sorted(list(set(chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['serendipaceratops\\n',\n",
       " 'peishansaurus\\n',\n",
       " 'pneumatoarthrus\\n',\n",
       " 'vulcanodon\\n',\n",
       " 'dimodosaurus\\n',\n",
       " 'coronosaurus\\n',\n",
       " 'shuangbaisaurus\\n',\n",
       " 'eugongbusaurus\\n',\n",
       " 'canardia\\n',\n",
       " 'megalosaurus\\n',\n",
       " 'kittysaurus\\n',\n",
       " 'saichania\\n',\n",
       " 'arcusaurus\\n',\n",
       " 'dandakosaurus\\n',\n",
       " 'siamodracon\\n',\n",
       " 'leptospondylus\\n',\n",
       " 'cheneosaurus\\n',\n",
       " 'opisthocoelicaudia\\n',\n",
       " 'gongpoquansaurus\\n',\n",
       " 'megadontosaurus\\n',\n",
       " 'adamantisaurus\\n',\n",
       " 'quilmesaurus\\n',\n",
       " 'notohypsilophodon\\n',\n",
       " 'diabloceratops\\n',\n",
       " 'pyroraptor\\n',\n",
       " 'loncosaurus\\n',\n",
       " 'aragosaurus\\n',\n",
       " 'mantellodon\\n',\n",
       " 'chuxiongosaurus\\n',\n",
       " 'brasileosaurus\\n',\n",
       " 'serikornis\\n',\n",
       " 'zhenyuanlong\\n',\n",
       " 'shidaisaurus\\n',\n",
       " 'mantellisaurus\\n',\n",
       " 'auroraceratops\\n',\n",
       " 'archaeornis\\n',\n",
       " 'yibinosaurus\\n',\n",
       " 'zupaysaurus\\n',\n",
       " 'vectensia\\n',\n",
       " 'adeopapposaurus\\n',\n",
       " 'velociraptor\\n',\n",
       " 'syntarsus\\n',\n",
       " 'pachyrhinosaurus\\n',\n",
       " 'byronosaurus\\n',\n",
       " 'avaceratops\\n',\n",
       " 'geminiraptor\\n',\n",
       " 'parrosaurus\\n',\n",
       " 'hierosaurus\\n',\n",
       " 'protorosaurus\\n',\n",
       " 'edmontonia\\n',\n",
       " 'trimucrodon\\n',\n",
       " 'xenoposeidon\\n',\n",
       " 'gobivenator\\n',\n",
       " 'achelousaurus\\n',\n",
       " 'palaeoctonus\\n',\n",
       " 'leonerasaurus\\n',\n",
       " 'barilium\\n',\n",
       " 'euhelopus\\n',\n",
       " 'byranjaffia\\n',\n",
       " 'variraptor\\n',\n",
       " 'acanthopholis\\n',\n",
       " 'graciliraptor\\n',\n",
       " 'velocipes\\n',\n",
       " 'chialingosaurus\\n',\n",
       " 'dysganus\\n',\n",
       " 'rhabdodon\\n',\n",
       " 'spinosaurus\\n',\n",
       " 'muyelensaurus\\n',\n",
       " 'asiatosaurus\\n',\n",
       " 'ouranosaurus\\n',\n",
       " 'gojirasaurus\\n',\n",
       " 'animantarx\\n',\n",
       " 'delapparentia\\n',\n",
       " 'olorotitan\\n',\n",
       " 'lusotitan\\n',\n",
       " 'abydosaurus\\n',\n",
       " 'malawisaurus\\n',\n",
       " 'morelladon\\n',\n",
       " 'breviceratops\\n',\n",
       " 'nteregosaurus\\n',\n",
       " 'proceratosaurus\\n',\n",
       " 'cerasinops\\n',\n",
       " 'stenotholus\\n',\n",
       " 'dromaeosauroides\\n',\n",
       " 'ankistrodon\\n',\n",
       " 'hungarosaurus\\n',\n",
       " 'losillasaurus\\n',\n",
       " 'gavinosaurus\\n',\n",
       " 'mandschurosaurus\\n',\n",
       " 'borealosaurus\\n',\n",
       " 'struthiomimus\\n',\n",
       " 'erlikosaurus\\n',\n",
       " 'lophorhothon\\n',\n",
       " 'wyomingraptor\\n',\n",
       " 'elrhazosaurus\\n',\n",
       " 'teleocrater\\n',\n",
       " 'shunosaurus\\n',\n",
       " 'soriatitan\\n',\n",
       " 'basutodon\\n',\n",
       " 'rahiolisaurus\\n',\n",
       " 'tenontosaurus\\n',\n",
       " 'euoplocephalus\\n',\n",
       " 'penelopognathus\\n',\n",
       " 'sirindhorna\\n',\n",
       " 'squalodon\\n',\n",
       " 'willinakaqe\\n',\n",
       " 'linhevenator\\n',\n",
       " 'sonorasaurus\\n',\n",
       " 'fukuititan\\n',\n",
       " 'gallimimus\\n',\n",
       " 'deinocheirus\\n',\n",
       " 'orthogoniosaurus\\n',\n",
       " 'bellusaurus\\n',\n",
       " 'brohisaurus\\n',\n",
       " 'microcephale\\n',\n",
       " 'megaraptor\\n',\n",
       " 'muttaburrasaurus\\n',\n",
       " 'judiceratops\\n',\n",
       " 'taurovenator\\n',\n",
       " 'vahiny\\n',\n",
       " 'argentinosaurus\\n',\n",
       " 'qingxiusaurus\\n',\n",
       " 'raptorex\\n',\n",
       " 'teratophoneus\\n',\n",
       " 'osmakasaurus\\n',\n",
       " 'coelophysis\\n',\n",
       " 'pukyongosaurus\\n',\n",
       " 'rhoetosaurus\\n',\n",
       " 'magnamanus\\n',\n",
       " 'microcoelus\\n',\n",
       " 'regnosaurus\\n',\n",
       " 'bradycneme\\n',\n",
       " 'maleevus\\n',\n",
       " 'procheneosaurus\\n',\n",
       " 'sellosaurus\\n',\n",
       " 'rachitrema\\n',\n",
       " 'huaxiaosaurus\\n',\n",
       " 'crichtonpelta\\n',\n",
       " 'tomodon\\n',\n",
       " 'zapalasaurus\\n',\n",
       " 'wellnhoferia\\n',\n",
       " 'astrodon\\n',\n",
       " 'szechuanosaurus\\n',\n",
       " 'sanpasaurus\\n',\n",
       " 'zhuchengosaurus\\n',\n",
       " 'prenoceratops\\n',\n",
       " 'erketu\\n',\n",
       " 'narambuenatitan\\n',\n",
       " 'crichtonsaurus\\n',\n",
       " 'calamosaurus\\n',\n",
       " 'kuszholia\\n',\n",
       " 'zhuchengtitan\\n',\n",
       " 'yamaceratops\\n',\n",
       " 'limnornis\\n',\n",
       " 'dynamosaurus\\n',\n",
       " 'brachytaenius\\n',\n",
       " 'ultrasauros\\n',\n",
       " 'ningyuansaurus\\n',\n",
       " 'macelognathus\\n',\n",
       " 'anatosaurus\\n',\n",
       " 'velocisaurus\\n',\n",
       " 'calamospondylus\\n',\n",
       " 'klamelisauruskol\\n',\n",
       " 'griphornis\\n',\n",
       " 'illustration\\n',\n",
       " 'blikanasaurus\\n',\n",
       " 'titanosaurus\\n',\n",
       " 'rioarribasaurus\\n',\n",
       " 'kentrosaurus\\n',\n",
       " 'linheraptor\\n',\n",
       " 'malarguesaurus\\n',\n",
       " 'macrophalangia\\n',\n",
       " 'sphenospondylus\\n',\n",
       " 'proiguanodon\\n',\n",
       " 'galtonia\\n',\n",
       " 'qantassaurus\\n',\n",
       " 'theiophytalia\\n',\n",
       " 'haplocanthus\\n',\n",
       " 'amargasaurus\\n',\n",
       " 'xinjiangovenator\\n',\n",
       " 'lamplughsaura\\n',\n",
       " 'therosaurus\\n',\n",
       " 'hoplosaurus\\n',\n",
       " 'dryptosauroides\\n',\n",
       " 'kotasaurus\\n',\n",
       " 'martharaptor\\n',\n",
       " 'sanjuansaurus\\n',\n",
       " 'astrophocaudia\\n',\n",
       " 'levnesovia\\n',\n",
       " 'dysalotosaurus\\n',\n",
       " 'protarchaeopteryx\\n',\n",
       " 'chinshakiangosaurus\\n',\n",
       " 'protoceratops\\n',\n",
       " 'epanterias\\n',\n",
       " 'beipiaosaurus\\n',\n",
       " 'jingshanosaurus\\n',\n",
       " 'honghesaurus\\n',\n",
       " 'mussaurus\\n',\n",
       " 'angloposeidon\\n',\n",
       " 'lophostropheus\\n',\n",
       " 'lohuecotitan\\n',\n",
       " 'sauraechinodon\\n',\n",
       " 'haplocheirus\\n',\n",
       " 'lagerpeton\\n',\n",
       " 'metriacanthosaurus\\n',\n",
       " 'amtosaurus\\n',\n",
       " 'suchomimus\\n',\n",
       " 'cionodon\\n',\n",
       " 'apatosaurus\\n',\n",
       " 'shanyangosaurus\\n',\n",
       " 'uberabatitan\\n',\n",
       " 'tatankaceratops\\n',\n",
       " 'algoasaurus\\n',\n",
       " 'polyodontosaurus\\n',\n",
       " 'corythosaurus\\n',\n",
       " 'gravitholus\\n',\n",
       " 'platyceratops\\n',\n",
       " 'agathaumas\\n',\n",
       " 'tsaagan\\n',\n",
       " 'dasygnathoides\\n',\n",
       " 'huanghetitan\\n',\n",
       " 'sauropelta\\n',\n",
       " 'leyesaurus\\n',\n",
       " 'turiasaurus\\n',\n",
       " 'arrhinoceratops\\n',\n",
       " 'luanpingosaurus\\n',\n",
       " 'venenosaurus\\n',\n",
       " 'tsintaosaurus\\n',\n",
       " 'titanoceratops\\n',\n",
       " 'huanansaurus\\n',\n",
       " 'tetragonosaurus\\n',\n",
       " 'marasuchus\\n',\n",
       " 'ferganasaurus\\n',\n",
       " 'avipes\\n',\n",
       " 'maleevosaurus\\n',\n",
       " 'kileskus\\n',\n",
       " 'bihariosaurus\\n',\n",
       " 'acristavus\\n',\n",
       " 'brachyceratops\\n',\n",
       " 'hoplitosaurus\\n',\n",
       " 'mamenchisaurus\\n',\n",
       " 'sonidosaurus\\n',\n",
       " 'nyasasaurus\\n',\n",
       " 'cumnoria\\n',\n",
       " 'huehuecanauhtlus\\n',\n",
       " 'banji\\n',\n",
       " 'microceratops\\n',\n",
       " 'palaeopteryx\\n',\n",
       " 'paralititan\\n',\n",
       " 'pitekunsaurus\\n',\n",
       " 'europelta\\n',\n",
       " 'postosuchus\\n',\n",
       " 'stokesosaurus\\n',\n",
       " 'mojoceratops\\n',\n",
       " 'microraptor\\n',\n",
       " 'murusraptor\\n',\n",
       " 'torosaurus\\n',\n",
       " 'palaeosaurus\\n',\n",
       " 'othnielosaurus\\n',\n",
       " 'dongyangosaurus\\n',\n",
       " 'afrovenator\\n',\n",
       " 'picrodon\\n',\n",
       " 'gorgosaurus\\n',\n",
       " 'aardonyx\\n',\n",
       " 'manospondylus\\n',\n",
       " 'tonouchisaurus\\n',\n",
       " 'eotyrannus\\n',\n",
       " 'epichirostenotes\\n',\n",
       " 'anatotitan\\n',\n",
       " 'trialestes\\n',\n",
       " 'yunxianosaurus\\n',\n",
       " 'monoclonius\\n',\n",
       " 'archaeornithoides\\n',\n",
       " 'limaysaurus\\n',\n",
       " 'apatoraptor\\n',\n",
       " 'tichosteus\\n',\n",
       " 'agujaceratops\\n',\n",
       " 'clasmodosaurus\\n',\n",
       " 'crataeomus\\n',\n",
       " 'proa\\n',\n",
       " 'talenkauen\\n',\n",
       " 'morinosaurus\\n',\n",
       " 'hanwulosaurus\\n',\n",
       " 'bakesaurus\\n',\n",
       " 'spinophorosaurus\\n',\n",
       " 'atacamatitan\\n',\n",
       " 'nanningosaurus\\n',\n",
       " 'nemegtomaia\\n',\n",
       " 'rahonavis\\n',\n",
       " 'stygimoloch\\n',\n",
       " 'jintasaurus\\n',\n",
       " 'aucasaurus\\n',\n",
       " 'probrachylophosaurus\\n',\n",
       " 'coelurosauravus\\n',\n",
       " 'syngonosaurus\\n',\n",
       " 'lepidocheirosaurus\\n',\n",
       " 'prosaurolophus\\n',\n",
       " 'echinodon\\n',\n",
       " 'sinocalliopteryx\\n',\n",
       " 'shamosaurus\\n',\n",
       " 'pinacosaurus\\n',\n",
       " 'zaraapelta\\n',\n",
       " 'hadrosaurus\\n',\n",
       " 'jiangxisaurus\\n',\n",
       " 'betasuchus\\n',\n",
       " 'pandoravenator\\n',\n",
       " 'xixiasaurus\\n',\n",
       " 'beelemodon\\n',\n",
       " 'eurolimnornis\\n',\n",
       " 'goyocephale\\n',\n",
       " 'astrodontaurus\\n',\n",
       " 'iguanacolossus\\n',\n",
       " 'dakosaurus\\n',\n",
       " 'clepsysaurus\\n',\n",
       " 'jensenosaurus\\n',\n",
       " 'acheroraptor\\n',\n",
       " 'cruxicheiros\\n',\n",
       " 'riojasuchus\\n',\n",
       " 'boreonykus\\n',\n",
       " 'diplotomodon\\n',\n",
       " 'yunganglong\\n',\n",
       " 'propanoplosaurus\\n',\n",
       " 'lamaceratops\\n',\n",
       " 'deinodon\\n',\n",
       " 'ratchasimasaurus\\n',\n",
       " 'ornithopsis\\n',\n",
       " 'ischyrosaurus\\n',\n",
       " 'xianshanosaurus\\n',\n",
       " 'chuandongocoelurus\\n',\n",
       " 'syrmosaurus\\n',\n",
       " 'nodocephalosaurus\\n',\n",
       " 'ammosaurus\\n',\n",
       " 'massospondylus\\n',\n",
       " 'technosaurus\\n',\n",
       " 'elaltitan\\n',\n",
       " 'luanchuanraptor\\n',\n",
       " 'coloradia\\n',\n",
       " 'citipati\\n',\n",
       " 'frenguellisaurus\\n',\n",
       " 'morosaurus\\n',\n",
       " 'liaoningosaurus\\n',\n",
       " 'smilodon\\n',\n",
       " 'tornieria\\n',\n",
       " 'sugiyamasaurus\\n',\n",
       " 'laquintasaura\\n',\n",
       " 'rebbachisaurus\\n',\n",
       " 'conchoraptor\\n',\n",
       " 'emausaurus\\n',\n",
       " 'aviatyrannis\\n',\n",
       " 'cathetosaurus\\n',\n",
       " 'gracilisuchus\\n',\n",
       " 'medusaceratops\\n',\n",
       " 'gigantoscelus\\n',\n",
       " 'abdallahsaurus\\n',\n",
       " 'draconyx\\n',\n",
       " 'daemonosaurus\\n',\n",
       " 'pachysaurops\\n',\n",
       " 'ohmdenosaurus\\n',\n",
       " 'isaberrysaura\\n',\n",
       " 'orcomimus\\n',\n",
       " 'savannasaurus\\n',\n",
       " 'sarcosaurus\\n',\n",
       " 'lexovisaurus\\n',\n",
       " 'zhuchengceratops\\n',\n",
       " 'tarbosaurus\\n',\n",
       " 'indosaurus\\n',\n",
       " 'harpymimus\\n',\n",
       " 'zhanghenglong\\n',\n",
       " 'rhopalodon\\n',\n",
       " 'alaskacephale\\n',\n",
       " 'diplodocus\\n',\n",
       " 'caudipteryx\\n',\n",
       " 'urbacodon\\n',\n",
       " 'monkonosaurus\\n',\n",
       " 'eucoelophysis\\n',\n",
       " 'tsagantegia\\n',\n",
       " 'shuvuuia\\n',\n",
       " 'glacialisaurus\\n',\n",
       " 'shenzhousaurus\\n',\n",
       " 'daurosaurus\\n',\n",
       " 'jiutaisaurus\\n',\n",
       " 'panamericansaurus\\n',\n",
       " 'changdusaurus\\n',\n",
       " 'sauroniops\\n',\n",
       " 'utahraptor\\n',\n",
       " 'epidexipteryx\\n',\n",
       " 'nyororosaurus\\n',\n",
       " 'procerosaurus\\n',\n",
       " 'camptosaurus\\n',\n",
       " 'ekrixinatosaurus\\n',\n",
       " 'sahaliyania\\n',\n",
       " 'archaeoceratops\\n',\n",
       " 'pteropelyx\\n',\n",
       " 'vagaceratops\\n',\n",
       " 'camelotia\\n',\n",
       " 'sinopelta\\n',\n",
       " 'nothronychus\\n',\n",
       " 'tyrannotitan\\n',\n",
       " 'janenschia\\n',\n",
       " 'otogosaurus\\n',\n",
       " 'angulomastacator\\n',\n",
       " 'herrerasaurus\\n',\n",
       " 'araucanoraptor\\n',\n",
       " 'skorpiovenator\\n',\n",
       " 'tatankacephalus\\n',\n",
       " 'tapuiasaurus\\n',\n",
       " 'eucnemesaurus\\n',\n",
       " 'chilesaurus\\n',\n",
       " 'prenocephale\\n',\n",
       " 'tianyulong\\n',\n",
       " 'gastonia\\n',\n",
       " 'apatodon\\n',\n",
       " 'gwyneddosaurus\\n',\n",
       " 'ornithoides\\n',\n",
       " 'astrodonius\\n',\n",
       " 'uteodon\\n',\n",
       " 'zizhongosaurus\\n',\n",
       " 'pachyspondylus\\n',\n",
       " 'dromiceiomimus\\n',\n",
       " 'thescelosaurus\\n',\n",
       " 'jubbulpuria\\n',\n",
       " 'yezosaurus\\n',\n",
       " 'liaoceratops\\n',\n",
       " 'regaliceratops\\n',\n",
       " 'anoplosaurus\\n',\n",
       " 'tongtianlong\\n',\n",
       " 'nanuqsaurus\\n',\n",
       " 'chiayusaurus\\n',\n",
       " 'stegopelta\\n',\n",
       " 'pneumatoraptor\\n',\n",
       " 'jurapteryx\\n',\n",
       " 'teihivenator\\n',\n",
       " 'hippodraco\\n',\n",
       " 'oshanosaurus\\n',\n",
       " 'carnotaurus\\n',\n",
       " 'sidormimus\\n',\n",
       " 'magyarosaurus\\n',\n",
       " 'proplanicoxa\\n',\n",
       " 'pedopenna\\n',\n",
       " 'protiguanodon\\n',\n",
       " 'protognathosaurus\\n',\n",
       " 'fukuivenator\\n',\n",
       " 'jiangjunosaurus\\n',\n",
       " 'megapnosaurus\\n',\n",
       " 'triunfosaurus\\n',\n",
       " 'zhuchengtyrannus\\n',\n",
       " 'minmi\\n',\n",
       " 'siats\\n',\n",
       " 'damalasaurus\\n',\n",
       " 'aristosaurus\\n',\n",
       " 'unaysaurus\\n',\n",
       " 'rinconsaurus\\n',\n",
       " 'machairoceratops\\n',\n",
       " 'mymoorapelta\\n',\n",
       " 'gannansaurus\\n',\n",
       " 'kakuru\\n',\n",
       " 'montanoceratops\\n',\n",
       " 'monolophosaurus\\n',\n",
       " 'helopus\\n',\n",
       " 'jobaria\\n',\n",
       " 'chirostenotes\\n',\n",
       " 'albalophosaurus\\n',\n",
       " 'ornithomimus\\n',\n",
       " 'fendusaurus\\n',\n",
       " 'tarchia\\n',\n",
       " 'horshamosaurus\\n',\n",
       " 'batyrosaurus\\n',\n",
       " 'ephoenosaurus\\n',\n",
       " 'brontoraptor\\n',\n",
       " 'calamospondylus\\n',\n",
       " 'atlascopcosaurus\\n',\n",
       " 'brontomerus\\n',\n",
       " 'oviraptor\\n',\n",
       " 'chindesaurus\\n',\n",
       " 'scleromochlus\\n',\n",
       " 'krzyzanowskisaurus\\n',\n",
       " 'pellegrinisaurus\\n',\n",
       " 'daxiatitan\\n',\n",
       " 'zapsalis\\n',\n",
       " 'avimimus\\n',\n",
       " 'lametasaurus\\n',\n",
       " 'hadrosauravus\\n',\n",
       " 'centemodon\\n',\n",
       " 'yangchuanosaurus\\n',\n",
       " 'megadactylus\\n',\n",
       " 'hypsibema\\n',\n",
       " 'eupodosaurus\\n',\n",
       " 'dianchungosaurus\\n',\n",
       " 'fukuiraptor\\n',\n",
       " 'nanotyrannus\\n',\n",
       " 'zuniceratops\\n',\n",
       " 'koparion\\n',\n",
       " 'australodocus\\n',\n",
       " 'lapampasaurus\\n',\n",
       " 'sinosauropteryx\\n',\n",
       " 'marmarospondylus\\n',\n",
       " 'yueosaurus\\n',\n",
       " 'koshisaurus\\n',\n",
       " 'paronychodon\\n',\n",
       " 'psittacosaurus\\n',\n",
       " 'polacanthoides\\n',\n",
       " 'wyleyia\\n',\n",
       " 'ischioceratops\\n',\n",
       " 'amargastegos\\n',\n",
       " 'tendaguria\\n',\n",
       " 'pelorosaurus\\n',\n",
       " 'pleurocoelus\\n',\n",
       " 'juravenator\\n',\n",
       " 'tangvayosaurus\\n',\n",
       " 'bicentenaria\\n',\n",
       " 'becklespinax\\n',\n",
       " 'uintasaurus\\n',\n",
       " 'avalonianus\\n',\n",
       " 'chondrosteosaurus\\n',\n",
       " 'agnosphitys\\n',\n",
       " 'eoraptor\\n',\n",
       " 'lewisuchus\\n',\n",
       " 'appalachiosaurus\\n',\n",
       " 'europatitan\\n',\n",
       " 'dongbeititan\\n',\n",
       " 'cryptoraptor\\n',\n",
       " 'kelmayisaurus\\n',\n",
       " 'sanchusaurus\\n',\n",
       " 'fusuisaurus\\n',\n",
       " 'mifunesaurus\\n',\n",
       " 'efraasia\\n',\n",
       " 'antarctopelta\\n',\n",
       " 'laplatasaurus\\n',\n",
       " 'arcovenator\\n',\n",
       " 'diluvicursor\\n',\n",
       " 'haplocanthosaurus\\n',\n",
       " 'valdosaurus\\n',\n",
       " 'gobititan\\n',\n",
       " 'struthiosaurus\\n',\n",
       " 'yizhousaurus\\n',\n",
       " 'pachysauriscus\\n',\n",
       " 'kunmingosaurus\\n',\n",
       " 'cladeiodon\\n',\n",
       " 'angolatitan\\n',\n",
       " 'omeisaurus\\n',\n",
       " 'nasutoceratops\\n',\n",
       " 'overosaurus\\n',\n",
       " 'streptospondylus\\n',\n",
       " 'roccosaurus\\n',\n",
       " 'saurophaganax\\n',\n",
       " 'eolambia\\n',\n",
       " 'doryphorosaurus\\n',\n",
       " 'parasaurolophus\\n',\n",
       " 'lufengosaurus\\n',\n",
       " 'agustinia\\n',\n",
       " 'gilmoreosaurus\\n',\n",
       " 'oligosaurus\\n',\n",
       " 'ovoraptor\\n',\n",
       " 'coelurus\\n',\n",
       " 'anzu\\n',\n",
       " 'denversaurus\\n',\n",
       " 'fusinasus\\n',\n",
       " 'silvisaurus\\n',\n",
       " 'gansutitan\\n',\n",
       " 'panoplosaurus\\n',\n",
       " 'allosaurus\\n',\n",
       " 'yurgovuchia\\n',\n",
       " 'mononychus\\n',\n",
       " 'triassolestes\\n',\n",
       " 'velafrons\\n',\n",
       " 'austrocheirus\\n',\n",
       " 'wuerhosaurus\\n',\n",
       " 'barsboldia\\n',\n",
       " 'suuwassea\\n',\n",
       " 'ornithotarsus\\n',\n",
       " 'ostromia\\n',\n",
       " 'ugrunaaluk\\n',\n",
       " 'supersaurus\\n',\n",
       " 'parksosaurus\\n',\n",
       " 'xixiposaurus\\n',\n",
       " 'ugrosaurus\\n',\n",
       " 'duriatitan\\n',\n",
       " 'iguanodon\\n',\n",
       " 'danubiosaurus\\n',\n",
       " 'spiclypeus\\n',\n",
       " 'genusaurus\\n',\n",
       " 'gspsaurus\\n',\n",
       " 'elachistosuchus\\n',\n",
       " 'orosaurus\\n',\n",
       " 'barosaurus\\n',\n",
       " 'alwalkeria\\n',\n",
       " 'camptonotus\\n',\n",
       " 'neuquenraptor\\n',\n",
       " 'tianchungosaurus\\n',\n",
       " 'ceratosaurus\\n',\n",
       " 'ornithosuchus\\n',\n",
       " 'domeykosaurus\\n',\n",
       " 'scutellosaurus\\n',\n",
       " 'belodon\\n',\n",
       " 'chenanisaurus\\n',\n",
       " 'parasaurolophus\\n',\n",
       " 'thespesius\\n',\n",
       " 'aggiosaurus\\n',\n",
       " 'sinocoelurus\\n',\n",
       " 'sauroplites\\n',\n",
       " 'leipsanosaurus\\n',\n",
       " 'ischisaurus\\n',\n",
       " 'chaoyangsaurus\\n',\n",
       " 'albertavenator\\n',\n",
       " 'asiaceratops\\n',\n",
       " 'gideonmantellia\\n',\n",
       " 'xuanhanosaurus\\n',\n",
       " 'glyptodontopelta\\n',\n",
       " 'yunnanosaurus\\n',\n",
       " 'acrotholus\\n',\n",
       " 'liliensternus\\n',\n",
       " 'probactrosaurus\\n',\n",
       " 'rugocaudia\\n',\n",
       " 'siluosaurus\\n',\n",
       " 'caseosaurus\\n',\n",
       " 'xenoceratops\\n',\n",
       " 'gyposaurus\\n',\n",
       " 'zhongyuansaurus\\n',\n",
       " 'neimongosaurus\\n',\n",
       " 'tanystropheus\\n',\n",
       " 'diracodon\\n',\n",
       " 'huxleysaurus\\n',\n",
       " 'kitadanisaurus\\n',\n",
       " 'likhoelesaurus\\n',\n",
       " 'avisaurus\\n',\n",
       " 'shanshanosaurus\\n',\n",
       " 'bienosaurus\\n',\n",
       " 'chingkankousaurus\\n',\n",
       " 'walkersaurus\\n',\n",
       " 'vitakrisaurus\\n',\n",
       " 'compsognathus\\n',\n",
       " 'europasaurus\\n',\n",
       " 'abrosaurus\\n',\n",
       " 'tylosteus\\n',\n",
       " 'albisaurus\\n',\n",
       " 'shanag\\n',\n",
       " 'procompsognathus\\n',\n",
       " 'archaeodontosaurus\\n',\n",
       " 'xiongguanlong\\n',\n",
       " 'fukuisaurus\\n',\n",
       " 'peltosaurus\\n',\n",
       " 'mochlodon\\n',\n",
       " 'taveirosaurus\\n',\n",
       " 'borogovia\\n',\n",
       " 'macrogryphosaurus\\n',\n",
       " 'kayentavenator\\n',\n",
       " 'gongxianosaurus\\n',\n",
       " 'yulong\\n',\n",
       " 'yingshanosaurus\\n',\n",
       " 'zunityrannus\\n',\n",
       " 'limusaurus\\n',\n",
       " 'labocania\\n',\n",
       " 'masiakasaurus\\n',\n",
       " 'nanosaurus\\n',\n",
       " 'jainosaurus\\n',\n",
       " 'buriolestes\\n',\n",
       " 'kritosaurus\\n',\n",
       " 'lusitanosaurus\\n',\n",
       " 'sulaimanisaurus\\n',\n",
       " 'koutalisaurus\\n',\n",
       " 'itemirus\\n',\n",
       " 'saltriosaurus\\n',\n",
       " 'charonosaurus\\n',\n",
       " 'daanosaurus\\n',\n",
       " 'phaedrolosaurus\\n',\n",
       " 'skeleton\\n',\n",
       " 'microceratus\\n',\n",
       " 'pakisaurus\\n',\n",
       " 'sphaerotholus\\n',\n",
       " 'veterupristisaurus\\n',\n",
       " 'aepyornithomimus\\n',\n",
       " 'utahceratops\\n',\n",
       " 'alnashetri\\n',\n",
       " 'saltopus\\n',\n",
       " 'beibeilong\\n',\n",
       " 'aoniraptor\\n',\n",
       " 'tachiraptor\\n',\n",
       " 'concavenator\\n',\n",
       " 'longosaurus\\n',\n",
       " 'siamodon\\n',\n",
       " 'aquilops\\n',\n",
       " 'luoyanggia\\n',\n",
       " 'maiasaura\\n',\n",
       " 'neosaurus\\n',\n",
       " 'archaeornithomimus\\n',\n",
       " 'ornitholestes\\n',\n",
       " 'stegosaurides\\n',\n",
       " 'coelosaurus\\n',\n",
       " 'datonglong\\n',\n",
       " 'tanycolagreus\\n',\n",
       " 'juratyrant\\n',\n",
       " 'atlantosaurus\\n',\n",
       " 'xuanhuaceratops\\n',\n",
       " 'gigantoraptor\\n',\n",
       " 'tonganosaurus\\n',\n",
       " 'cedrorestes\\n',\n",
       " 'ojoceratops\\n',\n",
       " 'santanaraptor\\n',\n",
       " 'revueltosaurus\\n',\n",
       " 'yinlong\\n',\n",
       " 'macrodontophion\\n',\n",
       " 'bahariasaurus\\n',\n",
       " 'protecovasaurus\\n',\n",
       " 'amurosaurus\\n',\n",
       " 'saurornitholestes\\n',\n",
       " 'lanasaurus\\n',\n",
       " 'nopcsaspondylus\\n',\n",
       " 'elopteryx\\n',\n",
       " 'succinodon\\n',\n",
       " 'drinker\\n',\n",
       " 'ojoraptorsaurus\\n',\n",
       " 'ngexisaurus\\n',\n",
       " 'notoceratops\\n',\n",
       " 'camposaurus\\n',\n",
       " 'plateosauravus\\n',\n",
       " 'tylocephale\\n',\n",
       " 'brasilotitan\\n',\n",
       " 'craterosaurus\\n',\n",
       " 'scansoriopteryx\\n',\n",
       " 'tataouinea\\n',\n",
       " 'eustreptospondylus\\n',\n",
       " 'baotianmansaurus\\n',\n",
       " 'trinisaura\\n',\n",
       " 'guaibasaurus\\n',\n",
       " 'dongyangopelta\\n',\n",
       " 'burianosaurus\\n',\n",
       " 'huangshanlong\\n',\n",
       " 'priodontognathus\\n',\n",
       " 'orthomerus\\n',\n",
       " 'griphosaurus\\n',\n",
       " 'tribelesodon\\n',\n",
       " 'jaklapallisaurus\\n',\n",
       " 'chungkingosaurus\\n',\n",
       " 'nankangia\\n',\n",
       " 'aletopelta\\n',\n",
       " 'gryponyx\\n',\n",
       " 'manidens\\n',\n",
       " 'eucamerotus\\n',\n",
       " 'deltadromeus\\n',\n",
       " 'jeyawati\\n',\n",
       " 'genyodectes\\n',\n",
       " 'koreaceratops\\n',\n",
       " 'ponerosteus\\n',\n",
       " 'wiehenvenator\\n',\n",
       " 'zuul',\n",
       " 'ziapelta\\n',\n",
       " 'caenagnathus\\n',\n",
       " 'bonitasaura\\n',\n",
       " 'gigantosaurus\\n',\n",
       " 'mtotosaurus\\n',\n",
       " 'claosaurus\\n',\n",
       " 'lirainosaurus\\n',\n",
       " 'chasmosaurus\\n',\n",
       " 'thecospondylus\\n',\n",
       " 'ilokelesia\\n',\n",
       " 'sinusonasus\\n',\n",
       " 'anserimimus\\n',\n",
       " 'yehuecauhceratops\\n',\n",
       " 'azendohsaurus\\n',\n",
       " 'kulindadromeus\\n',\n",
       " 'tawa\\n',\n",
       " 'wadhurstia\\n',\n",
       " 'proyandusaurus\\n',\n",
       " 'eocursor\\n',\n",
       " 'jenghizkhan\\n',\n",
       " 'ampelosaurus\\n',\n",
       " 'pentaceratops\\n',\n",
       " 'amphisaurus\\n',\n",
       " 'edmarka\\n',\n",
       " 'heterosaurus\\n',\n",
       " 'majungatholus\\n',\n",
       " 'antrodemus\\n',\n",
       " 'rapetosaurus\\n',\n",
       " 'shaochilong\\n',\n",
       " 'albinykus\\n',\n",
       " 'shuvosaurus\\n',\n",
       " 'philovenator\\n',\n",
       " 'sigilmassasaurus\\n',\n",
       " 'fabrosaurus\\n',\n",
       " 'caulodon\\n',\n",
       " 'erectopus\\n',\n",
       " 'austroposeidon\\n',\n",
       " 'claorhynchus\\n',\n",
       " 'triceratops\\n',\n",
       " 'kazaklambia\\n',\n",
       " 'therizinosaurus\\n',\n",
       " 'kukufeldia\\n',\n",
       " 'centrosaurus\\n',\n",
       " 'dakotaraptor\\n',\n",
       " 'achillesaurus\\n',\n",
       " 'hortalotarsus\\n',\n",
       " 'amygdalodon\\n',\n",
       " 'tyrannosaurus\\n',\n",
       " 'ultrasaurus\\n',\n",
       " 'sinotyrannus\\n',\n",
       " 'orinosaurusorkoraptor\\n',\n",
       " 'titanosaurus\\n',\n",
       " 'viavenator\\n',\n",
       " 'lourinhasaurus\\n',\n",
       " 'rayososaurus\\n',\n",
       " 'dromicosaurus\\n',\n",
       " 'rileya\\n',\n",
       " 'sacisaurus\\n',\n",
       " 'choconsaurus\\n',\n",
       " 'moabosaurus\\n',\n",
       " 'rocasaurus\\n',\n",
       " 'campylodon\\n',\n",
       " 'leptorhynchos\\n',\n",
       " 'plesiohadros\\n',\n",
       " 'amphicoelias\\n',\n",
       " 'lesothosaurus\\n',\n",
       " 'koreanosaurus\\n',\n",
       " 'walgettosuchus\\n',\n",
       " 'heptasteornis\\n',\n",
       " 'hypselorhachis\\n',\n",
       " 'tethyshadros\\n',\n",
       " 'dromaeosaurus\\n',\n",
       " 'palaeoscincus\\n',\n",
       " 'yongjinglong\\n',\n",
       " 'dollodon\\n',\n",
       " 'rajasaurus\\n',\n",
       " 'saurolophus\\n',\n",
       " 'giganotosaurus\\n',\n",
       " 'datanglong\\n',\n",
       " 'stegoceras\\n',\n",
       " 'gigantspinosaurus\\n',\n",
       " 'qinlingosaurus\\n',\n",
       " 'hylaeosaurus\\n',\n",
       " 'mendozasaurus\\n',\n",
       " 'sphenosaurus\\n',\n",
       " 'kosmoceratops\\n',\n",
       " 'mei\\n',\n",
       " 'kunbarrasaurus\\n',\n",
       " 'leptoceratops\\n',\n",
       " 'nqwebasaurus\\n',\n",
       " 'tazoudasaurus\\n',\n",
       " 'nurosaurus\\n',\n",
       " 'yaverlandia\\n',\n",
       " 'bissektipelta\\n',\n",
       " 'galvesaurus\\n',\n",
       " 'lancangosaurus\\n',\n",
       " 'leinkupal\\n',\n",
       " 'laiyangosaurus\\n',\n",
       " 'priconodon\\n',\n",
       " 'sterrholophus\\n',\n",
       " 'xixianykus\\n',\n",
       " 'traukutitan\\n',\n",
       " 'gryphoceratops\\n',\n",
       " 'bolong\\n',\n",
       " 'zigongosaurus\\n',\n",
       " 'yimenosaurus\\n',\n",
       " 'isisaurus\\n',\n",
       " 'archaeoraptor\\n',\n",
       " 'razanandrongobe\\n',\n",
       " 'halticosaurus\\n',\n",
       " 'poposaurus\\n',\n",
       " 'laosaurus\\n',\n",
       " 'palaeocursornis\\n',\n",
       " 'sibirotitan\\n',\n",
       " 'unicerosaurus\\n',\n",
       " 'gobisaurus\\n',\n",
       " 'clarencea\\n',\n",
       " 'daliansaurus\\n',\n",
       " 'xenotarsosaurus\\n',\n",
       " 'yunmenglong\\n',\n",
       " 'eoceratops\\n',\n",
       " 'panphagia\\n',\n",
       " 'aachenosaurus\\n',\n",
       " 'valdoraptor\\n',\n",
       " 'niobrarasaurus\\n',\n",
       " 'sinopeltosaurus\\n',\n",
       " 'naashoibitosaurus\\n',\n",
       " 'podokesaurus\\n',\n",
       " 'futabasaurus\\n',\n",
       " 'embasaurus\\n',\n",
       " 'nectosaurus\\n',\n",
       " 'magnapaulia\\n',\n",
       " 'hanssuesia\\n',\n",
       " 'shanxia\\n',\n",
       " 'polyonax\\n',\n",
       " 'stenonychosaurus\\n',\n",
       " 'asylosaurus\\n',\n",
       " 'issasaurus\\n',\n",
       " 'lambeosaurus\\n',\n",
       " 'ligabuesaurus\\n',\n",
       " 'pectinodon\\n',\n",
       " 'chubutisaurus\\n',\n",
       " 'nambalia\\n',\n",
       " 'acrocanthosaurus\\n',\n",
       " 'leshansaurus\\n',\n",
       " 'hagryphus\\n',\n",
       " 'tenantosaurus\\n',\n",
       " 'aerosteon\\n',\n",
       " 'magnirostris\\n',\n",
       " 'aralosaurus\\n',\n",
       " 'mahakala\\n',\n",
       " 'proceratops\\n',\n",
       " 'zanclodon\\n',\n",
       " 'dinodocus\\n',\n",
       " 'tenchisaurus\\n',\n",
       " 'shantungosaurus\\n',\n",
       " 'linhenykus\\n',\n",
       " 'argyrosaurus\\n',\n",
       " 'wulagasaurus\\n',\n",
       " 'dystylosaurus\\n',\n",
       " 'ferganocephale\\n',\n",
       " 'daspletosaurus\\n',\n",
       " 'teratosaurus\\n',\n",
       " 'balaur\\n',\n",
       " 'microvenator\\n',\n",
       " 'umarsaurus\\n',\n",
       " 'mirischia\\n',\n",
       " 'poekilopleuron\\n',\n",
       " 'talos\\n',\n",
       " 'katsuyamasaurus\\n',\n",
       " 'styracosaurus\\n',\n",
       " 'paleosaurus\\n',\n",
       " 'palaeolimnornis\\n',\n",
       " 'herbstosaurus\\n',\n",
       " 'coeluroides\\n',\n",
       " 'changyuraptor\\n',\n",
       " 'ruyangosaurus\\n',\n",
       " 'godzillasaurus\\n',\n",
       " 'aurornis\\n',\n",
       " 'chilantaisaurus\\n',\n",
       " 'volkheimeria\\n',\n",
       " 'bonatitan\\n',\n",
       " 'cedarosaurus\\n',\n",
       " 'megacervixosaurus\\n',\n",
       " 'camarillasaurus\\n',\n",
       " 'panguraptor\\n',\n",
       " 'habodcraniosaurus\\n',\n",
       " 'agrosaurus\\n',\n",
       " 'rubeosaurus\\n',\n",
       " 'haya\\n',\n",
       " 'patagotitan\\n',\n",
       " 'gigantosaurus\\n',\n",
       " 'beishanlong\\n',\n",
       " 'zhejiangosaurus\\n',\n",
       " 'gryposaurus\\n',\n",
       " 'vouivria\\n',\n",
       " 'didanodondilong\\n',\n",
       " 'campylodoniscus\\n',\n",
       " 'chebsaurus\\n',\n",
       " 'chuanqilong\\n',\n",
       " 'jiangjunmiaosaurus\\n',\n",
       " 'symphyrophus\\n',\n",
       " 'tototlmimus\\n',\n",
       " 'dryosaurus\\n',\n",
       " 'sciurumimus\\n',\n",
       " 'hongshanosaurus\\n',\n",
       " 'elmisaurus\\n',\n",
       " 'arenysaurus\\n',\n",
       " 'bothriospondylus\\n',\n",
       " 'pulanesaura\\n',\n",
       " 'neuquensaurus\\n',\n",
       " 'hypselosaurus\\n',\n",
       " 'zuoyunlong\\n',\n",
       " 'yandusaurus\\n',\n",
       " 'corythoraptor\\n',\n",
       " 'udanoceratops\\n',\n",
       " 'venaticosuchus\\n',\n",
       " 'dracopelta\\n',\n",
       " 'yuanmousaurus\\n',\n",
       " 'nemegtosaurus\\n',\n",
       " 'piatnitzkysaurus\\n',\n",
       " 'oohkotokia\\n',\n",
       " 'dinheirosaurus\\n',\n",
       " 'ornithomimoides\\n',\n",
       " 'callovosaurus\\n',\n",
       " 'notocolossus\\n',\n",
       " 'microdontosaurus\\n',\n",
       " 'eohadrosaurus\\n',\n",
       " 'andesaurus\\n',\n",
       " 'koreanosaurus\\n',\n",
       " 'tehuelchesaurus\\n',\n",
       " 'jianchangosaurus\\n',\n",
       " 'sarcolestes\\n',\n",
       " 'velociraptor\\n',\n",
       " 'longisquama\\n',\n",
       " 'thecocoelurus\\n',\n",
       " 'angaturama\\n',\n",
       " 'nigersaurus\\n',\n",
       " 'latirhinus\\n',\n",
       " 'ceratops\\n',\n",
       " 'aorun\\n',\n",
       " 'ichthyovenator\\n',\n",
       " 'cathartesaura\\n',\n",
       " 'wannanosaurus\\n',\n",
       " 'ankylosaurus\\n',\n",
       " 'geranosaurus\\n',\n",
       " 'pycnonemosaurus\\n',\n",
       " 'seismosaurus\\n',\n",
       " 'gondwanatitan\\n',\n",
       " 'bagaraatan\\n',\n",
       " 'meroktenos\\n',\n",
       " 'gargoyleosaurus\\n',\n",
       " 'dinotyrannus\\n',\n",
       " 'dakotadon\\n',\n",
       " 'incisivosaurus\\n',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1536 names and 27 unique tokens in your data.\n"
     ]
    }
   ],
   "source": [
    "data_size = len(data)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print('There are {} names and {} unique tokens in your data.'.format(data_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx = {ch:i for i,ch in enumerate(vocab)}\n",
    "idx_to_char = {i:ch for i,ch in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\n',\n",
       " 1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_name = max([len(d) for d in data])+5\n",
    "eos_id = char_to_idx['\\n']\n",
    "\n",
    "X_train = np.zeros(shape=(data_size, max_length_name, vocab_size), dtype='float32')\n",
    "for i, name in enumerate(data):\n",
    "    for j, character in enumerate(name):\n",
    "        index = char_to_idx[character]\n",
    "        X_train[i,j,index] = 1.0\n",
    "    X_train[i,len(name):,eos_id] = 1.0\n",
    "\n",
    "Y_train = np.zeros(shape=(data_size, max_length_name, vocab_size), dtype='float32')\n",
    "for i in range(data_size):\n",
    "    for j in range(max_length_name-1):\n",
    "        Y_train[i,j,:] = X_train[i,j+1,:]\n",
    "    Y_train[i,max_length_name-1,eos_id] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN():\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        self.units = units\n",
    "        self.weights = []\n",
    "        self.built = False\n",
    "        \n",
    "    def add_weight(self, shape):\n",
    "        var_init = tf.random.normal(shape=shape, mean=0.0, stddev=0.05, dtype=\"float32\")\n",
    "        return tf.Variable(initial_value=var_init, trainable=True)\n",
    "        \n",
    "    def build(self, input_dims):\n",
    "        self.w_xh = self.add_weight(shape=(input_dims, self.units))\n",
    "        self.weights.append(self.w_xh)\n",
    "        self.w_hh = self.add_weight(shape=(self.units, self.units))\n",
    "        self.weights.append(self.w_hh)\n",
    "        self.b = self.add_weight(shape=(1, self.units))\n",
    "        self.weights.append(self.b)\n",
    "        self.built = True\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        if not self.built:\n",
    "            self.build(input_dims=inputs.shape[2])\n",
    "        outputs = []\n",
    "        h = tf.zeros(shape=(1,self.units))\n",
    "        for t in range(inputs.shape[1]):\n",
    "            h = tf.math.tanh(tf.matmul(inputs[:,t,:], self.w_xh) + tf.matmul(h, self.w_hh) + self.b)\n",
    "            outputs.append(h)\n",
    "        return tf.transpose(tf.convert_to_tensor(outputs), perm=[1,0,2])\n",
    "\n",
    "class Dense():\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        self.units = units\n",
    "        self.weights = []\n",
    "        self.built = False\n",
    "        \n",
    "    def add_weight(self, shape):\n",
    "        var_init = tf.random.normal(shape=shape, mean=0.0, stddev=0.05, dtype=\"float32\")\n",
    "        return tf.Variable(initial_value=var_init, trainable=True)\n",
    "        \n",
    "    def build(self, input_dims):\n",
    "        self.w = self.add_weight(shape=(input_dims, self.units))\n",
    "        self.weights.append(self.w)\n",
    "        self.b = self.add_weight(shape=(1, self.units))\n",
    "        self.weights.append(self.b)\n",
    "        self.built = True\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        if not self.built:\n",
    "            self.build(input_dims=inputs.shape[2])\n",
    "        z = tf.einsum('dtj, ji ->dti',inputs,self.w) + self.b\n",
    "        u = tf.math.exp(z)\n",
    "        return u/tf.math.reduce_sum(u, axis=2, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalCrossentropy():\n",
    "                    \n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return -tf.math.reduce_mean(tf.math.reduce_mean(tf.math.reduce_sum(y_true*tf.math.log(y_pred), axis=2), axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalAccuracy():\n",
    "                    \n",
    "    def __call__(self, y_true, y_pred):\n",
    "        y_pred_max = tf.cast(tf.math.argmax(y_pred, axis=2), dtype='float32')\n",
    "        y_true_max = tf.cast(tf.math.argmax(y_true, axis=2), dtype='float32')\n",
    "        return tf.math.reduce_mean(tf.math.reduce_mean(1-tf.square(tf.sign(y_true_max-y_pred_max)), axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam():\n",
    "\n",
    "    def __init__(self, model, learning_rate, beta_1, beta_2, epsilon):\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon= epsilon\n",
    "        self.stop_training = False\n",
    "        self.weights = []\n",
    "        self.built = False\n",
    "        \n",
    "    def add_weight(self, shape):\n",
    "        w_init = tf.zeros(shape=shape, dtype=\"float32\")\n",
    "        return  tf.Variable(initial_value=w_init, trainable=False)\n",
    "    \n",
    "    def build(self):\n",
    "        for weight in self.model.weights:\n",
    "            m = self.add_weight(shape=weight.shape)\n",
    "            v = self.add_weight(shape=weight.shape)\n",
    "            self.weights.append([m,v])\n",
    "        self.built = True\n",
    "            \n",
    "    def apply_gradients(self, grads_and_vars):\n",
    "        if not self.built:\n",
    "            self.build()\n",
    "        list_grads_and_vars = list(grads_and_vars)\n",
    "        for i in range(len(list_grads_and_vars)):\n",
    "            grad, var = list_grads_and_vars[i]\n",
    "            m = self.weights[i][0]\n",
    "            v = self.weights[i][1]\n",
    "            self.weights[i][0].assign(self.beta_1*m + (1-self.beta_1)*grad)  \n",
    "            self.weights[i][1].assign(self.beta_2*v + (1-self.beta_2)*grad*grad)\n",
    "            m_ = (1/(1-self.beta_1))*self.weights[i][0]\n",
    "            v_ = (1/(1-self.beta_2))*self.weights[i][1]\n",
    "            var.assign(var - self.learning_rate*m_/(tf.math.sqrt(v_)+self.epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgbarPrint():\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def on_epoch_begin(self, epoch):\n",
    "        self.start_time = tf.timestamp()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        now = tf.timestamp()\n",
    "        time = now - self.start_time\n",
    "        tf.print('Epochs {}/{} - Loss: {} - Metric: {}'.format(epoch+1, self.model.epochs, logs['loss'], logs['metric']))\n",
    "        tf.print('----- {}s -----'.format(tf.round(1000*time)/1000))\n",
    "        \n",
    "class ReduceLROnPlateau():\n",
    "        \n",
    "    def __init__(self, model, patience, error, reduce_factor, min_learning_rate):\n",
    "        self.model = model\n",
    "        self.patience = patience\n",
    "        self.error = error\n",
    "        self.reduce_factor = reduce_factor\n",
    "        self.min_learning_rate = min_learning_rate\n",
    "                        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch==0:\n",
    "            self.loss = logs['loss']\n",
    "            self.non_decreasing_epochs = 0\n",
    "        else:\n",
    "            if ((self.loss-logs['loss'])>self.error):\n",
    "                self.loss = logs['loss']\n",
    "                self.non_decreasing_epochs = 0\n",
    "            else:\n",
    "                self.non_decreasing_epochs = self.non_decreasing_epochs+1\n",
    "        if (self.non_decreasing_epochs == self.patience):\n",
    "            if (self.model.optimizer.learning_rate>self.min_learning_rate):\n",
    "                self.model.optimizer.learning_rate = self.reduce_factor*self.model.optimizer.learning_rate\n",
    "                self.non_decreasing_epochs = 0\n",
    "        \n",
    "class EarlyStopping():\n",
    "        \n",
    "    def __init__(self, model, patience, error):\n",
    "        self.model = model\n",
    "        self.patience = patience\n",
    "        self.error = error\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch==0:\n",
    "            self.loss = logs['loss']\n",
    "            self.non_decreasing_epochs = 0\n",
    "        else:\n",
    "            if ((self.loss-logs['loss'])>self.error):\n",
    "                self.loss = logs['loss']\n",
    "                self.non_decreasing_epochs = 0\n",
    "            else:\n",
    "                self.non_decreasing_epochs = self.non_decreasing_epochs+1\n",
    "        if (self.non_decreasing_epochs == self.patience):\n",
    "            self.model.optimizer.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.h1 = SimpleRNN(units=50)\n",
    "        self.h2 = Dense(units=Y_train.shape[2])\n",
    "        self.layers = [self.h1, self.h2]\n",
    "        self.weights = []\n",
    "        self.built = False\n",
    "     \n",
    "    def build(self):\n",
    "        for layer in self.layers:\n",
    "            for weight in layer.weights:\n",
    "                self.weights.append(weight)\n",
    "        self.built = True\n",
    "        \n",
    "    def __call__(self, inputs): \n",
    "        a1 = self.h1(inputs)\n",
    "        y = self.h2(a1)\n",
    "        if not self.built:\n",
    "            self.build()\n",
    "        return y \n",
    "                \n",
    "    def train_step(self, X, Y):\n",
    "        num_batches = X.shape[0]//self.batch_size\n",
    "        for batch in range(num_batches+1):\n",
    "            if batch<num_batches:\n",
    "                X_batch = X[batch*self.batch_size:(batch+1)*self.batch_size]\n",
    "                Y_batch = Y[batch*self.batch_size:(batch+1)*self.batch_size]\n",
    "            else:\n",
    "                X_batch = X[num_batches*self.batch_size:]\n",
    "                Y_batch = Y[num_batches*self.batch_size:]\n",
    "            with tf.GradientTape() as tape:\n",
    "                H = self(X_batch)\n",
    "                loss = self.loss(Y_batch, H)\n",
    "            grads = tape.gradient(loss, self.weights)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.weights))\n",
    "        H = self(X)\n",
    "        loss = self.loss(Y, H)\n",
    "        metric = self.metric(Y, H)\n",
    "        logs = {'loss': loss,\n",
    "                'metric': metric}\n",
    "        return logs\n",
    "        \n",
    "    def fit(self, X, Y, epochs=1000, learning_rate=0.01, batch_size=64):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size \n",
    "        self.loss = CategoricalCrossentropy()\n",
    "        self.metric = CategoricalAccuracy()\n",
    "        self.optimizer = Adam(model=self, learning_rate=self.learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07) \n",
    "        self.callbacks = [ProgbarPrint(model=self),\n",
    "                          ReduceLROnPlateau(model=self, patience=200, error=0.0001, reduce_factor=0.1, min_learning_rate=0.001),\n",
    "                          EarlyStopping(model=self, patience=500, error=0.0001)]\n",
    "        tf.print('Train on {} samples'.format(X.shape[0]))\n",
    "        for epoch in range(epochs):\n",
    "            self.callbacks[0].on_epoch_begin(epoch)\n",
    "            logs = self.train_step(tf.constant(X, dtype=\"float32\"), tf.constant(Y, dtype=\"float32\"))\n",
    "            for callback in self.callbacks:\n",
    "                callback.on_epoch_end(epoch, logs)\n",
    "            if self.optimizer.stop_training:\n",
    "                break\n",
    "            \n",
    "    def predict(self, inputs):\n",
    "        return self(tf.constant(inputs, dtype=\"float32\")).numpy()\n",
    "        \n",
    "    def evaluate(self, X, Y):\n",
    "        loss = self.loss(tf.constant(Y, dtype=\"float32\"), self(tf.constant(X, dtype=\"float32\")))\n",
    "        metric = self.metric(tf.constant(Y, dtype=\"float32\"), self(tf.constant(X, dtype=\"float32\")))\n",
    "        loss_numpy = loss.numpy()\n",
    "        metric_numpy = metric.numpy()\n",
    "        tf.print('Loss: {} - Metric: {}'.format(loss_numpy, metric_numpy))\n",
    "        return [loss_numpy, metric_numpy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1536 samples\n",
      "Epochs 1/1000 - Loss: 1.8629859685897827 - Metric: 0.6107177734375\n",
      "----- 0.853s -----\n",
      "Epochs 2/1000 - Loss: 1.7007414102554321 - Metric: 0.6677042841911316\n",
      "----- 0.789s -----\n",
      "Epochs 3/1000 - Loss: 1.0779882669448853 - Metric: 0.6991780400276184\n",
      "----- 0.767s -----\n",
      "Epochs 4/1000 - Loss: 0.9389252066612244 - Metric: 0.7223103642463684\n",
      "----- 0.733s -----\n",
      "Epochs 5/1000 - Loss: 0.8581793904304504 - Metric: 0.7483723759651184\n",
      "----- 0.727s -----\n",
      "Epochs 6/1000 - Loss: 0.8185132145881653 - Metric: 0.75201416015625\n",
      "----- 0.781s -----\n",
      "Epochs 7/1000 - Loss: 0.8040559887886047 - Metric: 0.7553914189338684\n",
      "----- 0.848s -----\n",
      "Epochs 8/1000 - Loss: 0.7582359313964844 - Metric: 0.7720133662223816\n",
      "----- 0.765s -----\n",
      "Epochs 9/1000 - Loss: 0.7414300441741943 - Metric: 0.78436279296875\n",
      "----- 0.762s -----\n",
      "Epochs 10/1000 - Loss: 0.7288547158241272 - Metric: 0.7892659306526184\n",
      "----- 0.738s -----\n",
      "Epochs 11/1000 - Loss: 0.7369187474250793 - Metric: 0.7849934697151184\n",
      "----- 0.734s -----\n",
      "Epochs 12/1000 - Loss: 0.7107886672019958 - Metric: 0.7917277216911316\n",
      "----- 0.732s -----\n",
      "Epochs 13/1000 - Loss: 0.719929039478302 - Metric: 0.7892252802848816\n",
      "----- 0.732s -----\n",
      "Epochs 14/1000 - Loss: 0.6970973014831543 - Metric: 0.7953287959098816\n",
      "----- 0.721s -----\n",
      "Epochs 15/1000 - Loss: 0.6971408724784851 - Metric: 0.7939249873161316\n",
      "----- 0.739s -----\n",
      "Epochs 16/1000 - Loss: 0.6861343383789062 - Metric: 0.7969970703125\n",
      "----- 0.773s -----\n",
      "Epochs 17/1000 - Loss: 0.6806728839874268 - Metric: 0.7977498173713684\n",
      "----- 0.772s -----\n",
      "Epochs 18/1000 - Loss: 0.6774253845214844 - Metric: 0.7976481318473816\n",
      "----- 1.084s -----\n",
      "Epochs 19/1000 - Loss: 0.6723071932792664 - Metric: 0.7981364130973816\n",
      "----- 0.889s -----\n",
      "Epochs 20/1000 - Loss: 0.6681380271911621 - Metric: 0.7987467646598816\n",
      "----- 0.778s -----\n",
      "Epochs 21/1000 - Loss: 0.6648504137992859 - Metric: 0.79937744140625\n",
      "----- 0.778s -----\n",
      "Epochs 22/1000 - Loss: 0.6614882946014404 - Metric: 0.8004150390625\n",
      "----- 0.902s -----\n",
      "Epochs 23/1000 - Loss: 0.6583833694458008 - Metric: 0.8007405400276184\n",
      "----- 0.823s -----\n",
      "Epochs 24/1000 - Loss: 0.6555238366127014 - Metric: 0.8010050654411316\n",
      "----- 0.736s -----\n",
      "Epochs 25/1000 - Loss: 0.6527805924415588 - Metric: 0.8010050654411316\n",
      "----- 0.738s -----\n",
      "Epochs 26/1000 - Loss: 0.6501956582069397 - Metric: 0.8017374873161316\n",
      "----- 0.771s -----\n",
      "Epochs 27/1000 - Loss: 0.6478152871131897 - Metric: 0.8021036982536316\n",
      "----- 0.75s -----\n",
      "Epochs 28/1000 - Loss: 0.6456155180931091 - Metric: 0.8024699091911316\n",
      "----- 0.902s -----\n",
      "Epochs 29/1000 - Loss: 0.6435232758522034 - Metric: 0.8028361201286316\n",
      "----- 0.762s -----\n",
      "Epochs 30/1000 - Loss: 0.6414886116981506 - Metric: 0.8035685420036316\n",
      "----- 0.755s -----\n",
      "Epochs 31/1000 - Loss: 0.6395124793052673 - Metric: 0.8040568232536316\n",
      "----- 0.781s -----\n",
      "Epochs 32/1000 - Loss: 0.6375705003738403 - Metric: 0.8044636845588684\n",
      "----- 0.729s -----\n",
      "Epochs 33/1000 - Loss: 0.6357192993164062 - Metric: 0.80511474609375\n",
      "----- 0.776s -----\n",
      "Epochs 34/1000 - Loss: 0.6338987946510315 - Metric: 0.8055623173713684\n",
      "----- 0.742s -----\n",
      "Epochs 35/1000 - Loss: 0.6320963501930237 - Metric: 0.80596923828125\n",
      "----- 0.749s -----\n",
      "Epochs 36/1000 - Loss: 0.6302970051765442 - Metric: 0.80621337890625\n",
      "----- 0.804s -----\n",
      "Epochs 37/1000 - Loss: 0.6284375786781311 - Metric: 0.8066202998161316\n",
      "----- 0.808s -----\n",
      "Epochs 38/1000 - Loss: 0.6263874173164368 - Metric: 0.8076578974723816\n",
      "----- 0.763s -----\n",
      "Epochs 39/1000 - Loss: 0.6246739029884338 - Metric: 0.8084513545036316\n",
      "----- 0.728s -----\n",
      "Epochs 40/1000 - Loss: 0.6221334934234619 - Metric: 0.8098347783088684\n",
      "----- 1.216s -----\n",
      "Epochs 41/1000 - Loss: 0.6203265190124512 - Metric: 0.8112589716911316\n",
      "----- 0.844s -----\n",
      "Epochs 42/1000 - Loss: 0.6178564429283142 - Metric: 0.8120524287223816\n",
      "----- 0.799s -----\n",
      "Epochs 43/1000 - Loss: 0.6159003376960754 - Metric: 0.8128865361213684\n",
      "----- 0.738s -----\n",
      "Epochs 44/1000 - Loss: 0.6136135458946228 - Metric: 0.8141682744026184\n",
      "----- 0.775s -----\n",
      "Epochs 45/1000 - Loss: 0.6117167472839355 - Metric: 0.8148396611213684\n",
      "----- 0.807s -----\n",
      "Epochs 46/1000 - Loss: 0.6096517443656921 - Metric: 0.8155314326286316\n",
      "----- 0.839s -----\n",
      "Epochs 47/1000 - Loss: 0.6079647541046143 - Metric: 0.815673828125\n",
      "----- 0.799s -----\n",
      "Epochs 48/1000 - Loss: 0.6061839461326599 - Metric: 0.81732177734375\n",
      "----- 0.851s -----\n",
      "Epochs 49/1000 - Loss: 0.6044131517410278 - Metric: 0.81805419921875\n",
      "----- 0.739s -----\n",
      "Epochs 50/1000 - Loss: 0.602816641330719 - Metric: 0.81842041015625\n",
      "----- 0.824s -----\n",
      "Epochs 51/1000 - Loss: 0.6013609170913696 - Metric: 0.8187052607536316\n",
      "----- 1.027s -----\n",
      "Epochs 52/1000 - Loss: 0.6000317335128784 - Metric: 0.8190104365348816\n",
      "----- 0.967s -----\n",
      "Epochs 53/1000 - Loss: 0.5988298058509827 - Metric: 0.81939697265625\n",
      "----- 0.895s -----\n",
      "Epochs 54/1000 - Loss: 0.5977528095245361 - Metric: 0.819580078125\n",
      "----- 0.754s -----\n",
      "Epochs 55/1000 - Loss: 0.5967587828636169 - Metric: 0.8193766474723816\n",
      "----- 0.779s -----\n",
      "Epochs 56/1000 - Loss: 0.5958713889122009 - Metric: 0.81976318359375\n",
      "----- 0.757s -----\n",
      "Epochs 57/1000 - Loss: 0.5944858193397522 - Metric: 0.82000732421875\n",
      "----- 0.765s -----\n",
      "Epochs 58/1000 - Loss: 0.5925036072731018 - Metric: 0.8207194209098816\n",
      "----- 0.745s -----\n",
      "Epochs 59/1000 - Loss: 0.5910415649414062 - Metric: 0.8209431767463684\n",
      "----- 0.756s -----\n",
      "Epochs 60/1000 - Loss: 0.5903939604759216 - Metric: 0.8214518427848816\n",
      "----- 0.759s -----\n",
      "Epochs 61/1000 - Loss: 0.5892934203147888 - Metric: 0.8216959834098816\n",
      "----- 0.789s -----\n",
      "Epochs 62/1000 - Loss: 0.5878825187683105 - Metric: 0.82220458984375\n",
      "----- 0.766s -----\n",
      "Epochs 63/1000 - Loss: 0.5863354206085205 - Metric: 0.8226725459098816\n",
      "----- 0.739s -----\n",
      "Epochs 64/1000 - Loss: 0.5849161744117737 - Metric: 0.82342529296875\n",
      "----- 0.738s -----\n",
      "Epochs 65/1000 - Loss: 0.5835393071174622 - Metric: 0.82373046875\n",
      "----- 0.722s -----\n",
      "Epochs 66/1000 - Loss: 0.5822427868843079 - Metric: 0.8239949345588684\n",
      "----- 0.732s -----\n",
      "Epochs 67/1000 - Loss: 0.5809702277183533 - Metric: 0.82440185546875\n",
      "----- 0.725s -----\n",
      "Epochs 68/1000 - Loss: 0.57972651720047 - Metric: 0.8248291015625\n",
      "----- 0.725s -----\n",
      "Epochs 69/1000 - Loss: 0.5784932971000671 - Metric: 0.8250732421875\n",
      "----- 0.728s -----\n",
      "Epochs 70/1000 - Loss: 0.5772681832313538 - Metric: 0.8255411982536316\n",
      "----- 0.72s -----\n",
      "Epochs 71/1000 - Loss: 0.5760456919670105 - Metric: 0.8262532353401184\n",
      "----- 0.727s -----\n",
      "Epochs 72/1000 - Loss: 0.5748254656791687 - Metric: 0.8269856572151184\n",
      "----- 0.774s -----\n",
      "Epochs 73/1000 - Loss: 0.5736075639724731 - Metric: 0.8277994990348816\n",
      "----- 0.845s -----\n",
      "Epochs 74/1000 - Loss: 0.5723934173583984 - Metric: 0.8283488154411316\n",
      "----- 0.763s -----\n",
      "Epochs 75/1000 - Loss: 0.5711846947669983 - Metric: 0.8287760615348816\n",
      "----- 0.855s -----\n",
      "Epochs 76/1000 - Loss: 0.5699833035469055 - Metric: 0.8292033076286316\n",
      "----- 0.731s -----\n",
      "Epochs 77/1000 - Loss: 0.5687922835350037 - Metric: 0.8295084834098816\n",
      "----- 0.721s -----\n",
      "Epochs 78/1000 - Loss: 0.5676153302192688 - Metric: 0.8296101689338684\n",
      "----- 0.735s -----\n",
      "Epochs 79/1000 - Loss: 0.5664556622505188 - Metric: 0.8302001953125\n",
      "----- 0.724s -----\n",
      "Epochs 80/1000 - Loss: 0.5653176307678223 - Metric: 0.83056640625\n",
      "----- 0.731s -----\n",
      "Epochs 81/1000 - Loss: 0.5642052292823792 - Metric: 0.8310953974723816\n",
      "----- 0.819s -----\n",
      "Epochs 82/1000 - Loss: 0.5631242394447327 - Metric: 0.831298828125\n",
      "----- 0.81s -----\n",
      "Epochs 83/1000 - Loss: 0.5620806813240051 - Metric: 0.8318074345588684\n",
      "----- 0.737s -----\n",
      "Epochs 84/1000 - Loss: 0.5610799193382263 - Metric: 0.8321940302848816\n",
      "----- 0.756s -----\n",
      "Epochs 85/1000 - Loss: 0.5601203441619873 - Metric: 0.832763671875\n",
      "----- 0.795s -----\n",
      "Epochs 86/1000 - Loss: 0.5591841340065002 - Metric: 0.8330485224723816\n",
      "----- 0.737s -----\n",
      "Epochs 87/1000 - Loss: 0.5582304000854492 - Metric: 0.8332316279411316\n",
      "----- 0.761s -----\n",
      "Epochs 88/1000 - Loss: 0.5572071075439453 - Metric: 0.8331705927848816\n",
      "----- 0.746s -----\n",
      "Epochs 89/1000 - Loss: 0.5560855865478516 - Metric: 0.8334757685661316\n",
      "----- 0.737s -----\n",
      "Epochs 90/1000 - Loss: 0.5548868775367737 - Metric: 0.83392333984375\n",
      "----- 0.766s -----\n",
      "Epochs 91/1000 - Loss: 0.5536695122718811 - Metric: 0.8341471552848816\n",
      "----- 0.794s -----\n",
      "Epochs 92/1000 - Loss: 0.5524894595146179 - Metric: 0.8343709111213684\n",
      "----- 0.78s -----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 93/1000 - Loss: 0.5513735413551331 - Metric: 0.8343505859375\n",
      "----- 0.758s -----\n",
      "Epochs 94/1000 - Loss: 0.5503204464912415 - Metric: 0.8348795771598816\n",
      "----- 0.836s -----\n",
      "Epochs 95/1000 - Loss: 0.5493125319480896 - Metric: 0.8350626826286316\n",
      "----- 0.754s -----\n",
      "Epochs 96/1000 - Loss: 0.5483300089836121 - Metric: 0.83538818359375\n",
      "----- 0.773s -----\n",
      "Epochs 97/1000 - Loss: 0.5473642349243164 - Metric: 0.8358154296875\n",
      "----- 0.719s -----\n",
      "Epochs 98/1000 - Loss: 0.5464163422584534 - Metric: 0.83612060546875\n",
      "----- 0.757s -----\n",
      "Epochs 99/1000 - Loss: 0.5454848408699036 - Metric: 0.8364054560661316\n",
      "----- 0.725s -----\n",
      "Epochs 100/1000 - Loss: 0.5445546507835388 - Metric: 0.8365071415901184\n",
      "----- 0.736s -----\n",
      "Epochs 101/1000 - Loss: 0.543606698513031 - Metric: 0.8369954228401184\n",
      "----- 0.793s -----\n",
      "Epochs 102/1000 - Loss: 0.5426365733146667 - Metric: 0.8369954228401184\n",
      "----- 0.715s -----\n",
      "Epochs 103/1000 - Loss: 0.5416595339775085 - Metric: 0.8373005986213684\n",
      "----- 0.717s -----\n",
      "Epochs 104/1000 - Loss: 0.5406952500343323 - Metric: 0.8374837040901184\n",
      "----- 0.715s -----\n",
      "Epochs 105/1000 - Loss: 0.5397514700889587 - Metric: 0.83746337890625\n",
      "----- 0.757s -----\n",
      "Epochs 106/1000 - Loss: 0.5388237833976746 - Metric: 0.8376261591911316\n",
      "----- 0.733s -----\n",
      "Epochs 107/1000 - Loss: 0.5379067063331604 - Metric: 0.8379109501838684\n",
      "----- 0.726s -----\n",
      "Epochs 108/1000 - Loss: 0.5369987487792969 - Metric: 0.8383992314338684\n",
      "----- 0.749s -----\n",
      "Epochs 109/1000 - Loss: 0.5361027717590332 - Metric: 0.83868408203125\n",
      "----- 0.816s -----\n",
      "Epochs 110/1000 - Loss: 0.5352206230163574 - Metric: 0.8388671875\n",
      "----- 0.772s -----\n",
      "Epochs 111/1000 - Loss: 0.5343502163887024 - Metric: 0.8393351435661316\n",
      "----- 0.803s -----\n",
      "Epochs 112/1000 - Loss: 0.5334906578063965 - Metric: 0.8396199345588684\n",
      "----- 0.724s -----\n",
      "Epochs 113/1000 - Loss: 0.5326457619667053 - Metric: 0.8398640751838684\n",
      "----- 0.741s -----\n",
      "Epochs 114/1000 - Loss: 0.5318186283111572 - Metric: 0.8403117060661316\n",
      "----- 0.728s -----\n",
      "Epochs 115/1000 - Loss: 0.5310071110725403 - Metric: 0.84051513671875\n",
      "----- 0.784s -----\n",
      "Epochs 116/1000 - Loss: 0.5302051901817322 - Metric: 0.8407999873161316\n",
      "----- 0.756s -----\n",
      "Epochs 117/1000 - Loss: 0.5294092297554016 - Metric: 0.8409016728401184\n",
      "----- 0.726s -----\n",
      "Epochs 118/1000 - Loss: 0.528620183467865 - Metric: 0.8411458134651184\n",
      "----- 0.729s -----\n",
      "Epochs 119/1000 - Loss: 0.5278416275978088 - Metric: 0.8417155146598816\n",
      "----- 0.73s -----\n",
      "Epochs 120/1000 - Loss: 0.527077317237854 - Metric: 0.8417561650276184\n",
      "----- 0.729s -----\n",
      "Epochs 121/1000 - Loss: 0.5263296961784363 - Metric: 0.8419189453125\n",
      "----- 0.728s -----\n",
      "Epochs 122/1000 - Loss: 0.5255975127220154 - Metric: 0.8420613408088684\n",
      "----- 0.724s -----\n",
      "Epochs 123/1000 - Loss: 0.5248740315437317 - Metric: 0.8422037959098816\n",
      "----- 0.729s -----\n",
      "Epochs 124/1000 - Loss: 0.524151623249054 - Metric: 0.84222412109375\n",
      "----- 0.752s -----\n",
      "Epochs 125/1000 - Loss: 0.5234296917915344 - Metric: 0.8422648310661316\n",
      "----- 0.763s -----\n",
      "Epochs 126/1000 - Loss: 0.5227170586585999 - Metric: 0.8425089716911316\n",
      "----- 0.797s -----\n",
      "Epochs 127/1000 - Loss: 0.5220250487327576 - Metric: 0.8430379033088684\n",
      "----- 0.805s -----\n",
      "Epochs 128/1000 - Loss: 0.5213587880134583 - Metric: 0.8435872197151184\n",
      "----- 0.738s -----\n",
      "Epochs 129/1000 - Loss: 0.5207167267799377 - Metric: 0.84375\n",
      "----- 0.756s -----\n",
      "Epochs 130/1000 - Loss: 0.5200955271720886 - Metric: 0.8441365361213684\n",
      "----- 0.738s -----\n",
      "Epochs 131/1000 - Loss: 0.519496500492096 - Metric: 0.8439534306526184\n",
      "----- 0.734s -----\n",
      "Epochs 132/1000 - Loss: 0.5189313292503357 - Metric: 0.8443806767463684\n",
      "----- 0.758s -----\n",
      "Epochs 133/1000 - Loss: 0.5184213519096375 - Metric: 0.84454345703125\n",
      "----- 0.726s -----\n",
      "Epochs 134/1000 - Loss: 0.5179888606071472 - Metric: 0.84490966796875\n",
      "----- 0.726s -----\n",
      "Epochs 135/1000 - Loss: 0.5176506042480469 - Metric: 0.8448893427848816\n",
      "----- 0.762s -----\n",
      "Epochs 136/1000 - Loss: 0.5174291133880615 - Metric: 0.8449299931526184\n",
      "----- 0.726s -----\n",
      "Epochs 137/1000 - Loss: 0.5173695683479309 - Metric: 0.8450520634651184\n",
      "----- 0.765s -----\n",
      "Epochs 138/1000 - Loss: 0.5175278782844543 - Metric: 0.8451945185661316\n",
      "----- 0.775s -----\n",
      "Epochs 139/1000 - Loss: 0.5178837180137634 - Metric: 0.84521484375\n",
      "----- 0.754s -----\n",
      "Epochs 140/1000 - Loss: 0.5178277492523193 - Metric: 0.8449503779411316\n",
      "----- 0.743s -----\n",
      "Epochs 141/1000 - Loss: 0.5148446559906006 - Metric: 0.8453165888786316\n",
      "----- 0.736s -----\n",
      "Epochs 142/1000 - Loss: 0.5190404057502747 - Metric: 0.8438517451286316\n",
      "----- 0.732s -----\n",
      "Epochs 143/1000 - Loss: 0.5223807692527771 - Metric: 0.8434855341911316\n",
      "----- 0.725s -----\n",
      "Epochs 144/1000 - Loss: 0.5156910419464111 - Metric: 0.8457438349723816\n",
      "----- 0.72s -----\n",
      "Epochs 145/1000 - Loss: 0.5154536962509155 - Metric: 0.844970703125\n",
      "----- 0.717s -----\n",
      "Epochs 146/1000 - Loss: 0.5156210064888 - Metric: 0.8449503779411316\n",
      "----- 0.779s -----\n",
      "Epochs 147/1000 - Loss: 0.5154566764831543 - Metric: 0.8449910283088684\n",
      "----- 2.549s -----\n",
      "Epochs 148/1000 - Loss: 0.5147876739501953 - Metric: 0.8451945185661316\n",
      "----- 1.669s -----\n",
      "Epochs 149/1000 - Loss: 0.5137572884559631 - Metric: 0.8457234501838684\n",
      "----- 1.641s -----\n",
      "Epochs 150/1000 - Loss: 0.5125750303268433 - Metric: 0.8461100459098816\n",
      "----- 1.563s -----\n",
      "Epochs 151/1000 - Loss: 0.5114843249320984 - Metric: 0.8463948369026184\n",
      "----- 1.708s -----\n",
      "Epochs 152/1000 - Loss: 0.5104759931564331 - Metric: 0.8467610478401184\n",
      "----- 1.516s -----\n",
      "Epochs 153/1000 - Loss: 0.5095460414886475 - Metric: 0.846923828125\n",
      "----- 0.845s -----\n",
      "Epochs 154/1000 - Loss: 0.5087137222290039 - Metric: 0.8472493290901184\n",
      "----- 0.799s -----\n",
      "Epochs 155/1000 - Loss: 0.5079708695411682 - Metric: 0.8474324345588684\n",
      "----- 0.744s -----\n",
      "Epochs 156/1000 - Loss: 0.5072504281997681 - Metric: 0.8474528193473816\n",
      "----- 0.771s -----\n",
      "Epochs 157/1000 - Loss: 0.506614625453949 - Metric: 0.84759521484375\n",
      "----- 0.734s -----\n",
      "Epochs 158/1000 - Loss: 0.5060952305793762 - Metric: 0.8478190302848816\n",
      "----- 0.758s -----\n",
      "Epochs 159/1000 - Loss: 0.5055539608001709 - Metric: 0.8480631709098816\n",
      "----- 0.736s -----\n",
      "Epochs 160/1000 - Loss: 0.5050468444824219 - Metric: 0.8477986454963684\n",
      "----- 0.736s -----\n",
      "Epochs 161/1000 - Loss: 0.5048256516456604 - Metric: 0.8479817509651184\n",
      "----- 0.733s -----\n",
      "Epochs 162/1000 - Loss: 0.504787266254425 - Metric: 0.8482869267463684\n",
      "----- 0.752s -----\n",
      "Epochs 163/1000 - Loss: 0.5043137073516846 - Metric: 0.8479207158088684\n",
      "----- 1.194s -----\n",
      "Epochs 164/1000 - Loss: 0.5045490860939026 - Metric: 0.84808349609375\n",
      "----- 1.49s -----\n",
      "Epochs 165/1000 - Loss: 0.5038273930549622 - Metric: 0.8485107421875\n",
      "----- 1.458s -----\n",
      "Epochs 166/1000 - Loss: 0.5038289427757263 - Metric: 0.8477986454963684\n",
      "----- 2.247s -----\n",
      "Epochs 167/1000 - Loss: 0.5043283104896545 - Metric: 0.847900390625\n",
      "----- 1.835s -----\n",
      "Epochs 168/1000 - Loss: 0.5038169026374817 - Metric: 0.84820556640625\n",
      "----- 1.666s -----\n",
      "Epochs 169/1000 - Loss: 0.5041153430938721 - Metric: 0.84796142578125\n",
      "----- 1.543s -----\n",
      "Epochs 170/1000 - Loss: 0.5041830539703369 - Metric: 0.847900390625\n",
      "----- 1.699s -----\n",
      "Epochs 171/1000 - Loss: 0.5047162175178528 - Metric: 0.8477579951286316\n",
      "----- 1.536s -----\n",
      "Epochs 172/1000 - Loss: 0.5053306221961975 - Metric: 0.84747314453125\n",
      "----- 1.612s -----\n",
      "Epochs 173/1000 - Loss: 0.5054619908332825 - Metric: 0.84759521484375\n",
      "----- 1.542s -----\n",
      "Epochs 174/1000 - Loss: 0.5063007473945618 - Metric: 0.8473917841911316\n",
      "----- 1.746s -----\n",
      "Epochs 175/1000 - Loss: 0.5075030326843262 - Metric: 0.846923828125\n",
      "----- 1.649s -----\n",
      "Epochs 176/1000 - Loss: 0.5079715847969055 - Metric: 0.846435546875\n",
      "----- 1.569s -----\n",
      "Epochs 177/1000 - Loss: 0.5105300545692444 - Metric: 0.8456624150276184\n",
      "----- 1.884s -----\n",
      "Epochs 178/1000 - Loss: 0.5147231817245483 - Metric: 0.8448486328125\n",
      "----- 1.55s -----\n",
      "Epochs 179/1000 - Loss: 0.5122080445289612 - Metric: 0.84564208984375\n",
      "----- 1.593s -----\n",
      "Epochs 180/1000 - Loss: 0.5001558065414429 - Metric: 0.84979248046875\n",
      "----- 0.99s -----\n",
      "Epochs 181/1000 - Loss: 0.49688515067100525 - Metric: 0.8515625\n",
      "----- 0.761s -----\n",
      "Epochs 182/1000 - Loss: 0.496392160654068 - Metric: 0.85150146484375\n",
      "----- 0.754s -----\n",
      "Epochs 183/1000 - Loss: 0.4974813461303711 - Metric: 0.8512980341911316\n",
      "----- 0.793s -----\n",
      "Epochs 184/1000 - Loss: 0.49863314628601074 - Metric: 0.85028076171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.759s -----\n",
      "Epochs 185/1000 - Loss: 0.4993503987789154 - Metric: 0.849853515625\n",
      "----- 0.747s -----\n",
      "Epochs 186/1000 - Loss: 0.49977168440818787 - Metric: 0.8497111201286316\n",
      "----- 0.73s -----\n",
      "Epochs 187/1000 - Loss: 0.4998803436756134 - Metric: 0.8498942255973816\n",
      "----- 0.745s -----\n",
      "Epochs 188/1000 - Loss: 0.49956226348876953 - Metric: 0.8500162959098816\n",
      "----- 0.772s -----\n",
      "Epochs 189/1000 - Loss: 0.49902796745300293 - Metric: 0.8499552607536316\n",
      "----- 0.775s -----\n",
      "Epochs 190/1000 - Loss: 0.4980524480342865 - Metric: 0.8504435420036316\n",
      "----- 0.742s -----\n",
      "Epochs 191/1000 - Loss: 0.49735260009765625 - Metric: 0.8507283329963684\n",
      "----- 0.795s -----\n",
      "Epochs 192/1000 - Loss: 0.4963715374469757 - Metric: 0.8512369990348816\n",
      "----- 0.738s -----\n",
      "Epochs 193/1000 - Loss: 0.49576857686042786 - Metric: 0.8512166142463684\n",
      "----- 0.735s -----\n",
      "Epochs 194/1000 - Loss: 0.4949217140674591 - Metric: 0.85162353515625\n",
      "----- 1.173s -----\n",
      "Epochs 195/1000 - Loss: 0.4945147931575775 - Metric: 0.8517863154411316\n",
      "----- 0.771s -----\n",
      "Epochs 196/1000 - Loss: 0.494185209274292 - Metric: 0.8520914912223816\n",
      "----- 0.73s -----\n",
      "Epochs 197/1000 - Loss: 0.49363550543785095 - Metric: 0.8524373173713684\n",
      "----- 0.746s -----\n",
      "Epochs 198/1000 - Loss: 0.4932887554168701 - Metric: 0.85235595703125\n",
      "----- 0.755s -----\n",
      "Epochs 199/1000 - Loss: 0.49291515350341797 - Metric: 0.8525593876838684\n",
      "----- 0.752s -----\n",
      "Epochs 200/1000 - Loss: 0.49272051453590393 - Metric: 0.8527018427848816\n",
      "----- 0.747s -----\n",
      "Epochs 201/1000 - Loss: 0.49225565791130066 - Metric: 0.8525593876838684\n",
      "----- 0.759s -----\n",
      "Epochs 202/1000 - Loss: 0.49226799607276917 - Metric: 0.8527628779411316\n",
      "----- 0.746s -----\n",
      "Epochs 203/1000 - Loss: 0.4921349287033081 - Metric: 0.852783203125\n",
      "----- 0.73s -----\n",
      "Epochs 204/1000 - Loss: 0.49216794967651367 - Metric: 0.8524983525276184\n",
      "----- 0.833s -----\n",
      "Epochs 205/1000 - Loss: 0.49197208881378174 - Metric: 0.8527628779411316\n",
      "----- 0.743s -----\n",
      "Epochs 206/1000 - Loss: 0.4920400083065033 - Metric: 0.8525797724723816\n",
      "----- 0.796s -----\n",
      "Epochs 207/1000 - Loss: 0.49221253395080566 - Metric: 0.8524577021598816\n",
      "----- 0.73s -----\n",
      "Epochs 208/1000 - Loss: 0.49385905265808105 - Metric: 0.8518269658088684\n",
      "----- 0.728s -----\n",
      "Epochs 209/1000 - Loss: 0.4958149492740631 - Metric: 0.8514811396598816\n",
      "----- 0.755s -----\n",
      "Epochs 210/1000 - Loss: 0.49936947226524353 - Metric: 0.8506062626838684\n",
      "----- 0.74s -----\n",
      "Epochs 211/1000 - Loss: 0.505615770816803 - Metric: 0.84820556640625\n",
      "----- 0.758s -----\n",
      "Epochs 212/1000 - Loss: 0.5043684840202332 - Metric: 0.8490193486213684\n",
      "----- 0.728s -----\n",
      "Epochs 213/1000 - Loss: 0.4908435344696045 - Metric: 0.85302734375\n",
      "----- 0.735s -----\n",
      "Epochs 214/1000 - Loss: 0.4867285490036011 - Metric: 0.8540242314338684\n",
      "----- 0.735s -----\n",
      "Epochs 215/1000 - Loss: 0.4877002239227295 - Metric: 0.8537394404411316\n",
      "----- 0.735s -----\n",
      "Epochs 216/1000 - Loss: 0.4893946945667267 - Metric: 0.8527424931526184\n",
      "----- 0.743s -----\n",
      "Epochs 217/1000 - Loss: 0.49084559082984924 - Metric: 0.85211181640625\n",
      "----- 0.724s -----\n",
      "Epochs 218/1000 - Loss: 0.492661714553833 - Metric: 0.8515421748161316\n",
      "----- 0.724s -----\n",
      "Epochs 219/1000 - Loss: 0.49069473147392273 - Metric: 0.8523356318473816\n",
      "----- 1.234s -----\n",
      "Epochs 220/1000 - Loss: 0.4865667521953583 - Metric: 0.8537800908088684\n",
      "----- 0.819s -----\n",
      "Epochs 221/1000 - Loss: 0.4841829836368561 - Metric: 0.85467529296875\n",
      "----- 0.785s -----\n",
      "Epochs 222/1000 - Loss: 0.4827049970626831 - Metric: 0.8550822138786316\n",
      "----- 0.73s -----\n",
      "Epochs 223/1000 - Loss: 0.4830363690853119 - Metric: 0.8550822138786316\n",
      "----- 0.723s -----\n",
      "Epochs 224/1000 - Loss: 0.48389068245887756 - Metric: 0.8546345829963684\n",
      "----- 0.718s -----\n",
      "Epochs 225/1000 - Loss: 0.4851038455963135 - Metric: 0.854248046875\n",
      "----- 0.719s -----\n",
      "Epochs 226/1000 - Loss: 0.4878601133823395 - Metric: 0.8532511591911316\n",
      "----- 0.715s -----\n",
      "Epochs 227/1000 - Loss: 0.4916856586933136 - Metric: 0.8518880009651184\n",
      "----- 0.717s -----\n",
      "Epochs 228/1000 - Loss: 0.49370837211608887 - Metric: 0.8513590693473816\n",
      "----- 0.724s -----\n",
      "Epochs 229/1000 - Loss: 0.48426082730293274 - Metric: 0.8540852665901184\n",
      "----- 0.716s -----\n",
      "Epochs 230/1000 - Loss: 0.4828058183193207 - Metric: 0.8544718623161316\n",
      "----- 0.741s -----\n",
      "Epochs 231/1000 - Loss: 0.4835251569747925 - Metric: 0.8542887568473816\n",
      "----- 0.721s -----\n",
      "Epochs 232/1000 - Loss: 0.48650529980659485 - Metric: 0.8534952998161316\n",
      "----- 0.711s -----\n",
      "Epochs 233/1000 - Loss: 0.48976650834083557 - Metric: 0.8519287109375\n",
      "----- 0.722s -----\n",
      "Epochs 234/1000 - Loss: 0.4923418462276459 - Metric: 0.85125732421875\n",
      "----- 0.724s -----\n",
      "Epochs 235/1000 - Loss: 0.48741647601127625 - Metric: 0.85321044921875\n",
      "----- 0.733s -----\n",
      "Epochs 236/1000 - Loss: 0.4855830669403076 - Metric: 0.8539021611213684\n",
      "----- 0.731s -----\n",
      "Epochs 237/1000 - Loss: 0.48561397194862366 - Metric: 0.8540242314338684\n",
      "----- 0.719s -----\n",
      "Epochs 238/1000 - Loss: 0.48741063475608826 - Metric: 0.8530680537223816\n",
      "----- 0.726s -----\n",
      "Epochs 239/1000 - Loss: 0.4886045455932617 - Metric: 0.8525797724723816\n",
      "----- 0.726s -----\n",
      "Epochs 240/1000 - Loss: 0.4893522262573242 - Metric: 0.8524577021598816\n",
      "----- 0.73s -----\n",
      "Epochs 241/1000 - Loss: 0.4884178638458252 - Metric: 0.8530680537223816\n",
      "----- 0.718s -----\n",
      "Epochs 242/1000 - Loss: 0.4858994483947754 - Metric: 0.8534952998161316\n",
      "----- 0.719s -----\n",
      "Epochs 243/1000 - Loss: 0.4834873676300049 - Metric: 0.8547566533088684\n",
      "----- 0.752s -----\n",
      "Epochs 244/1000 - Loss: 0.48283568024635315 - Metric: 0.8551228642463684\n",
      "----- 0.759s -----\n",
      "Epochs 245/1000 - Loss: 0.48229551315307617 - Metric: 0.8553059697151184\n",
      "----- 0.754s -----\n",
      "Epochs 246/1000 - Loss: 0.48304376006126404 - Metric: 0.8548380732536316\n",
      "----- 0.74s -----\n",
      "Epochs 247/1000 - Loss: 0.4831881523132324 - Metric: 0.85479736328125\n",
      "----- 0.734s -----\n",
      "Epochs 248/1000 - Loss: 0.4829164445400238 - Metric: 0.8547770380973816\n",
      "----- 0.735s -----\n",
      "Epochs 249/1000 - Loss: 0.4814530313014984 - Metric: 0.8554280400276184\n",
      "----- 0.74s -----\n",
      "Epochs 250/1000 - Loss: 0.4795871078968048 - Metric: 0.8563232421875\n",
      "----- 0.735s -----\n",
      "Epochs 251/1000 - Loss: 0.47853073477745056 - Metric: 0.8566080927848816\n",
      "----- 0.768s -----\n",
      "Epochs 252/1000 - Loss: 0.4782693386077881 - Metric: 0.8563435673713684\n",
      "----- 0.73s -----\n",
      "Epochs 253/1000 - Loss: 0.4790984094142914 - Metric: 0.8559367060661316\n",
      "----- 0.734s -----\n",
      "Epochs 254/1000 - Loss: 0.48018714785575867 - Metric: 0.85577392578125\n",
      "----- 0.736s -----\n",
      "Epochs 255/1000 - Loss: 0.48105940222740173 - Metric: 0.8552653193473816\n",
      "----- 0.737s -----\n",
      "Epochs 256/1000 - Loss: 0.4809618890285492 - Metric: 0.85540771484375\n",
      "----- 0.75s -----\n",
      "Epochs 257/1000 - Loss: 0.4787842333316803 - Metric: 0.85601806640625\n",
      "----- 0.738s -----\n",
      "Epochs 258/1000 - Loss: 0.4769243896007538 - Metric: 0.8565470576286316\n",
      "----- 0.744s -----\n",
      "Epochs 259/1000 - Loss: 0.4764823615550995 - Metric: 0.85675048828125\n",
      "----- 0.781s -----\n",
      "Epochs 260/1000 - Loss: 0.4766836166381836 - Metric: 0.8565673828125\n",
      "----- 0.747s -----\n",
      "Epochs 261/1000 - Loss: 0.47874316573143005 - Metric: 0.8557536005973816\n",
      "----- 0.773s -----\n",
      "Epochs 262/1000 - Loss: 0.4809669554233551 - Metric: 0.85479736328125\n",
      "----- 0.747s -----\n",
      "Epochs 263/1000 - Loss: 0.48089542984962463 - Metric: 0.8553059697151184\n",
      "----- 0.745s -----\n",
      "Epochs 264/1000 - Loss: 0.47704002261161804 - Metric: 0.8562418818473816\n",
      "----- 0.742s -----\n",
      "Epochs 265/1000 - Loss: 0.47755804657936096 - Metric: 0.85614013671875\n",
      "----- 0.742s -----\n",
      "Epochs 266/1000 - Loss: 0.47494471073150635 - Metric: 0.8570556640625\n",
      "----- 0.772s -----\n",
      "Epochs 267/1000 - Loss: 0.4770120084285736 - Metric: 0.8559163212776184\n",
      "----- 0.74s -----\n",
      "Epochs 268/1000 - Loss: 0.479245662689209 - Metric: 0.8554484248161316\n",
      "----- 0.737s -----\n",
      "Epochs 269/1000 - Loss: 0.4778585433959961 - Metric: 0.8558146357536316\n",
      "----- 0.758s -----\n",
      "Epochs 270/1000 - Loss: 0.4754435122013092 - Metric: 0.8561808466911316\n",
      "----- 0.75s -----\n",
      "Epochs 271/1000 - Loss: 0.47516945004463196 - Metric: 0.8564860224723816\n",
      "----- 0.766s -----\n",
      "Epochs 272/1000 - Loss: 0.4756596088409424 - Metric: 0.8564860224723816\n",
      "----- 0.735s -----\n",
      "Epochs 273/1000 - Loss: 0.47644510865211487 - Metric: 0.8563029170036316\n",
      "----- 0.744s -----\n",
      "Epochs 274/1000 - Loss: 0.47574177384376526 - Metric: 0.8565266728401184\n",
      "----- 0.795s -----\n",
      "Epochs 275/1000 - Loss: 0.47653186321258545 - Metric: 0.8565266728401184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.742s -----\n",
      "Epochs 276/1000 - Loss: 0.4772357642650604 - Metric: 0.8562214970588684\n",
      "----- 0.741s -----\n",
      "Epochs 277/1000 - Loss: 0.47860726714134216 - Metric: 0.85577392578125\n",
      "----- 0.738s -----\n",
      "Epochs 278/1000 - Loss: 0.486133337020874 - Metric: 0.8536173701286316\n",
      "----- 0.734s -----\n",
      "Epochs 279/1000 - Loss: 0.5236865878105164 - Metric: 0.8419392704963684\n",
      "----- 0.737s -----\n",
      "Epochs 280/1000 - Loss: 0.49306800961494446 - Metric: 0.8512369990348816\n",
      "----- 0.751s -----\n",
      "Epochs 281/1000 - Loss: 0.48156437277793884 - Metric: 0.8544108271598816\n",
      "----- 0.775s -----\n",
      "Epochs 282/1000 - Loss: 0.48410412669181824 - Metric: 0.8539225459098816\n",
      "----- 0.761s -----\n",
      "Epochs 283/1000 - Loss: 0.49358463287353516 - Metric: 0.8507487177848816\n",
      "----- 0.729s -----\n",
      "Epochs 284/1000 - Loss: 0.49190643429756165 - Metric: 0.8514607548713684\n",
      "----- 0.735s -----\n",
      "Epochs 285/1000 - Loss: 0.48143765330314636 - Metric: 0.8544921875\n",
      "----- 0.747s -----\n",
      "Epochs 286/1000 - Loss: 0.4777616560459137 - Metric: 0.8554890751838684\n",
      "----- 0.764s -----\n",
      "Epochs 287/1000 - Loss: 0.4777775704860687 - Metric: 0.8555704951286316\n",
      "----- 0.74s -----\n",
      "Epochs 288/1000 - Loss: 0.4796890318393707 - Metric: 0.8544921875\n",
      "----- 0.773s -----\n",
      "Epochs 289/1000 - Loss: 0.4821060597896576 - Metric: 0.85382080078125\n",
      "----- 0.798s -----\n",
      "Epochs 290/1000 - Loss: 0.4856616258621216 - Metric: 0.8528035283088684\n",
      "----- 0.744s -----\n",
      "Epochs 291/1000 - Loss: 0.4885903596878052 - Metric: 0.8520304560661316\n",
      "----- 0.771s -----\n",
      "Epochs 292/1000 - Loss: 0.4868641793727875 - Metric: 0.8523152470588684\n",
      "----- 0.77s -----\n",
      "Epochs 293/1000 - Loss: 0.48087310791015625 - Metric: 0.8546549677848816\n",
      "----- 0.755s -----\n",
      "Epochs 294/1000 - Loss: 0.47726383805274963 - Metric: 0.8556315302848816\n",
      "----- 0.769s -----\n",
      "Epochs 295/1000 - Loss: 0.47314098477363586 - Metric: 0.8567097783088684\n",
      "----- 0.836s -----\n",
      "Epochs 296/1000 - Loss: 0.47085556387901306 - Metric: 0.8577880859375\n",
      "----- 0.805s -----\n",
      "Epochs 297/1000 - Loss: 0.4703351557254791 - Metric: 0.8579304814338684\n",
      "----- 0.853s -----\n",
      "Epochs 298/1000 - Loss: 0.46952104568481445 - Metric: 0.8582356572151184\n",
      "----- 0.898s -----\n",
      "Epochs 299/1000 - Loss: 0.47066497802734375 - Metric: 0.85760498046875\n",
      "----- 0.76s -----\n",
      "Epochs 300/1000 - Loss: 0.47214019298553467 - Metric: 0.8571574091911316\n",
      "----- 0.764s -----\n",
      "Epochs 301/1000 - Loss: 0.4706972539424896 - Metric: 0.8580729365348816\n",
      "----- 0.768s -----\n",
      "Epochs 302/1000 - Loss: 0.47067832946777344 - Metric: 0.8578084111213684\n",
      "----- 0.75s -----\n",
      "Epochs 303/1000 - Loss: 0.4714207649230957 - Metric: 0.8575846552848816\n",
      "----- 0.756s -----\n",
      "Epochs 304/1000 - Loss: 0.47154149413108826 - Metric: 0.8576863408088684\n",
      "----- 0.772s -----\n",
      "Epochs 305/1000 - Loss: 0.47127842903137207 - Metric: 0.8578898310661316\n",
      "----- 0.765s -----\n",
      "Epochs 306/1000 - Loss: 0.47252511978149414 - Metric: 0.8567911982536316\n",
      "----- 0.733s -----\n",
      "Epochs 307/1000 - Loss: 0.4728979170322418 - Metric: 0.8571370244026184\n",
      "----- 0.758s -----\n",
      "Epochs 308/1000 - Loss: 0.47212088108062744 - Metric: 0.85723876953125\n",
      "----- 0.743s -----\n",
      "Epochs 309/1000 - Loss: 0.4731566905975342 - Metric: 0.8571574091911316\n",
      "----- 0.769s -----\n",
      "Epochs 310/1000 - Loss: 0.4723561108112335 - Metric: 0.8569539189338684\n",
      "----- 0.731s -----\n",
      "Epochs 311/1000 - Loss: 0.4736536741256714 - Metric: 0.8569743037223816\n",
      "----- 0.753s -----\n",
      "Epochs 312/1000 - Loss: 0.4734318256378174 - Metric: 0.8563029170036316\n",
      "----- 0.75s -----\n",
      "Epochs 313/1000 - Loss: 0.4749124348163605 - Metric: 0.85662841796875\n",
      "----- 0.757s -----\n",
      "Epochs 314/1000 - Loss: 0.47348713874816895 - Metric: 0.8567911982536316\n",
      "----- 0.788s -----\n",
      "Epochs 315/1000 - Loss: 0.4741886556148529 - Metric: 0.8564249873161316\n",
      "----- 0.733s -----\n",
      "Epochs 316/1000 - Loss: 0.4764964282512665 - Metric: 0.855712890625\n",
      "----- 0.717s -----\n",
      "Epochs 317/1000 - Loss: 0.4772270619869232 - Metric: 0.8560994267463684\n",
      "----- 0.746s -----\n",
      "Epochs 318/1000 - Loss: 0.4752911329269409 - Metric: 0.8565266728401184\n",
      "----- 0.753s -----\n",
      "Epochs 319/1000 - Loss: 0.47674503922462463 - Metric: 0.8561604619026184\n",
      "----- 0.779s -----\n",
      "Epochs 320/1000 - Loss: 0.478996604681015 - Metric: 0.8555094599723816\n",
      "----- 0.799s -----\n",
      "Epochs 321/1000 - Loss: 0.48150715231895447 - Metric: 0.85516357421875\n",
      "----- 0.757s -----\n",
      "Epochs 322/1000 - Loss: 0.4826488494873047 - Metric: 0.8543294072151184\n",
      "----- 0.755s -----\n",
      "Epochs 323/1000 - Loss: 0.4864468574523926 - Metric: 0.8530476689338684\n",
      "----- 0.878s -----\n",
      "Epochs 324/1000 - Loss: 0.49426746368408203 - Metric: 0.8509724736213684\n",
      "----- 0.772s -----\n",
      "Epochs 325/1000 - Loss: 0.49813541769981384 - Metric: 0.8498128056526184\n",
      "----- 0.867s -----\n",
      "Epochs 326/1000 - Loss: 0.5063456892967224 - Metric: 0.8470051884651184\n",
      "----- 0.773s -----\n",
      "Epochs 327/1000 - Loss: 0.49277862906455994 - Metric: 0.8499348759651184\n",
      "----- 0.818s -----\n",
      "Epochs 328/1000 - Loss: 0.47552362084388733 - Metric: 0.85577392578125\n",
      "----- 0.778s -----\n",
      "Epochs 329/1000 - Loss: 0.47477996349334717 - Metric: 0.8558756709098816\n",
      "----- 0.755s -----\n",
      "Epochs 330/1000 - Loss: 0.46817222237586975 - Metric: 0.8584187626838684\n",
      "----- 0.793s -----\n",
      "Epochs 331/1000 - Loss: 0.46567273139953613 - Metric: 0.85931396484375\n",
      "----- 0.881s -----\n",
      "Epochs 332/1000 - Loss: 0.4693996012210846 - Metric: 0.85833740234375\n",
      "----- 0.793s -----\n",
      "Epochs 333/1000 - Loss: 0.4682806432247162 - Metric: 0.8583781123161316\n",
      "----- 0.774s -----\n",
      "Epochs 334/1000 - Loss: 0.4722524881362915 - Metric: 0.8572794795036316\n",
      "----- 0.795s -----\n",
      "Epochs 335/1000 - Loss: 0.46825018525123596 - Metric: 0.8585408329963684\n",
      "----- 0.893s -----\n",
      "Epochs 336/1000 - Loss: 0.47365641593933105 - Metric: 0.856689453125\n",
      "----- 0.811s -----\n",
      "Epochs 337/1000 - Loss: 0.47221824526786804 - Metric: 0.8569132685661316\n",
      "----- 0.814s -----\n",
      "Epochs 338/1000 - Loss: 0.4763549864292145 - Metric: 0.8560383915901184\n",
      "----- 0.837s -----\n",
      "Epochs 339/1000 - Loss: 0.47236040234565735 - Metric: 0.8569132685661316\n",
      "----- 0.785s -----\n",
      "Epochs 340/1000 - Loss: 0.47856831550598145 - Metric: 0.8552653193473816\n",
      "----- 0.799s -----\n",
      "Epochs 341/1000 - Loss: 0.4716678857803345 - Metric: 0.8571370244026184\n",
      "----- 0.768s -----\n",
      "Epochs 342/1000 - Loss: 0.47404584288597107 - Metric: 0.8567708134651184\n",
      "----- 0.746s -----\n",
      "Epochs 343/1000 - Loss: 0.4730653762817383 - Metric: 0.8568928837776184\n",
      "----- 0.797s -----\n",
      "Epochs 344/1000 - Loss: 0.4722350835800171 - Metric: 0.85723876953125\n",
      "----- 0.81s -----\n",
      "Epochs 345/1000 - Loss: 0.4733078181743622 - Metric: 0.85675048828125\n",
      "----- 0.736s -----\n",
      "Epochs 346/1000 - Loss: 0.47295907139778137 - Metric: 0.8571574091911316\n",
      "----- 0.774s -----\n",
      "Epochs 347/1000 - Loss: 0.4703167974948883 - Metric: 0.8578084111213684\n",
      "----- 0.735s -----\n",
      "Epochs 348/1000 - Loss: 0.4727832078933716 - Metric: 0.8568318486213684\n",
      "----- 0.758s -----\n",
      "Epochs 349/1000 - Loss: 0.47157540917396545 - Metric: 0.8572184443473816\n",
      "----- 0.749s -----\n",
      "Epochs 350/1000 - Loss: 0.47135913372039795 - Metric: 0.85699462890625\n",
      "----- 0.798s -----\n",
      "Epochs 351/1000 - Loss: 0.47249290347099304 - Metric: 0.8568928837776184\n",
      "----- 0.797s -----\n",
      "Epochs 352/1000 - Loss: 0.4721105098724365 - Metric: 0.8569539189338684\n",
      "----- 0.789s -----\n",
      "Epochs 353/1000 - Loss: 0.4691725969314575 - Metric: 0.8573811650276184\n",
      "----- 0.782s -----\n",
      "Epochs 354/1000 - Loss: 0.4721352159976959 - Metric: 0.8570353388786316\n",
      "----- 0.823s -----\n",
      "Epochs 355/1000 - Loss: 0.47140416502952576 - Metric: 0.8568318486213684\n",
      "----- 0.788s -----\n",
      "Epochs 356/1000 - Loss: 0.4695097506046295 - Metric: 0.857666015625\n",
      "----- 0.737s -----\n",
      "Epochs 357/1000 - Loss: 0.47225770354270935 - Metric: 0.856689453125\n",
      "----- 0.734s -----\n",
      "Epochs 358/1000 - Loss: 0.47170719504356384 - Metric: 0.8571574091911316\n",
      "----- 0.753s -----\n",
      "Epochs 359/1000 - Loss: 0.4693852365016937 - Metric: 0.8576863408088684\n",
      "----- 0.755s -----\n",
      "Epochs 360/1000 - Loss: 0.47395119071006775 - Metric: 0.8558756709098816\n",
      "----- 0.724s -----\n",
      "Epochs 361/1000 - Loss: 0.46870294213294983 - Metric: 0.8578287959098816\n",
      "----- 0.75s -----\n",
      "Epochs 362/1000 - Loss: 0.4696877896785736 - Metric: 0.8575642704963684\n",
      "----- 0.721s -----\n",
      "Epochs 363/1000 - Loss: 0.4725516736507416 - Metric: 0.8575236201286316\n",
      "----- 0.793s -----\n",
      "Epochs 364/1000 - Loss: 0.4692838191986084 - Metric: 0.8573405146598816\n",
      "----- 0.744s -----\n",
      "Epochs 365/1000 - Loss: 0.47073841094970703 - Metric: 0.8576456904411316\n",
      "----- 0.745s -----\n",
      "Epochs 366/1000 - Loss: 0.4717857539653778 - Metric: 0.8572794795036316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.76s -----\n",
      "Epochs 367/1000 - Loss: 0.4676876962184906 - Metric: 0.8583170771598816\n",
      "----- 0.76s -----\n",
      "Epochs 368/1000 - Loss: 0.4673287868499756 - Metric: 0.85797119140625\n",
      "----- 0.756s -----\n",
      "Epochs 369/1000 - Loss: 0.4677465856075287 - Metric: 0.8579508662223816\n",
      "----- 0.75s -----\n",
      "Epochs 370/1000 - Loss: 0.46824121475219727 - Metric: 0.8573201298713684\n",
      "----- 0.739s -----\n",
      "Epochs 371/1000 - Loss: 0.4674740731716156 - Metric: 0.8570963740348816\n",
      "----- 0.723s -----\n",
      "Epochs 372/1000 - Loss: 0.46663951873779297 - Metric: 0.8571370244026184\n",
      "----- 0.739s -----\n",
      "Epochs 373/1000 - Loss: 0.47228431701660156 - Metric: 0.8565470576286316\n",
      "----- 0.927s -----\n",
      "Epochs 374/1000 - Loss: 0.47446155548095703 - Metric: 0.8554890751838684\n",
      "----- 0.74s -----\n",
      "Epochs 375/1000 - Loss: 0.46911969780921936 - Metric: 0.8568318486213684\n",
      "----- 0.741s -----\n",
      "Epochs 376/1000 - Loss: 0.47641924023628235 - Metric: 0.854736328125\n",
      "----- 0.743s -----\n",
      "Epochs 377/1000 - Loss: 0.47541508078575134 - Metric: 0.85546875\n",
      "----- 0.724s -----\n",
      "Epochs 378/1000 - Loss: 0.46587857604026794 - Metric: 0.8581339716911316\n",
      "----- 0.738s -----\n",
      "Epochs 379/1000 - Loss: 0.46710070967674255 - Metric: 0.8583170771598816\n",
      "----- 0.771s -----\n",
      "Epochs 380/1000 - Loss: 0.4702509939670563 - Metric: 0.8570963740348816\n",
      "----- 0.724s -----\n",
      "Epochs 381/1000 - Loss: 0.4636993110179901 - Metric: 0.85845947265625\n",
      "----- 0.73s -----\n",
      "Epochs 382/1000 - Loss: 0.46249938011169434 - Metric: 0.8587646484375\n",
      "----- 0.731s -----\n",
      "Epochs 383/1000 - Loss: 0.4707447588443756 - Metric: 0.8570353388786316\n",
      "----- 0.743s -----\n",
      "Epochs 384/1000 - Loss: 0.4614037573337555 - Metric: 0.8588053584098816\n",
      "----- 0.731s -----\n",
      "Epochs 385/1000 - Loss: 0.4614807665348053 - Metric: 0.8594563603401184\n",
      "----- 0.738s -----\n",
      "Epochs 386/1000 - Loss: 0.462907075881958 - Metric: 0.8596394658088684\n",
      "----- 0.739s -----\n",
      "Epochs 387/1000 - Loss: 0.45844766497612 - Metric: 0.8602498173713684\n",
      "----- 0.772s -----\n",
      "Epochs 388/1000 - Loss: 0.4581105709075928 - Metric: 0.8604329228401184\n",
      "----- 0.719s -----\n",
      "Epochs 389/1000 - Loss: 0.46663251519203186 - Metric: 0.8583781123161316\n",
      "----- 0.721s -----\n",
      "Epochs 390/1000 - Loss: 0.45696568489074707 - Metric: 0.860595703125\n",
      "----- 0.794s -----\n",
      "Epochs 391/1000 - Loss: 0.4574246406555176 - Metric: 0.8607177734375\n",
      "----- 0.758s -----\n",
      "Epochs 392/1000 - Loss: 0.46465691924095154 - Metric: 0.8587239384651184\n",
      "----- 0.731s -----\n",
      "Epochs 393/1000 - Loss: 0.45922982692718506 - Metric: 0.85968017578125\n",
      "----- 0.787s -----\n",
      "Epochs 394/1000 - Loss: 0.45698848366737366 - Metric: 0.8607584834098816\n",
      "----- 0.75s -----\n",
      "Epochs 395/1000 - Loss: 0.4595038890838623 - Metric: 0.8600260615348816\n",
      "----- 0.781s -----\n",
      "Epochs 396/1000 - Loss: 0.462534099817276 - Metric: 0.8594157099723816\n",
      "----- 0.73s -----\n",
      "Epochs 397/1000 - Loss: 0.4573296010494232 - Metric: 0.86004638671875\n",
      "----- 0.739s -----\n",
      "Epochs 398/1000 - Loss: 0.45737579464912415 - Metric: 0.8601887822151184\n",
      "----- 0.747s -----\n",
      "Epochs 399/1000 - Loss: 0.4591255486011505 - Metric: 0.8603922724723816\n",
      "----- 0.794s -----\n",
      "Epochs 400/1000 - Loss: 0.46252647042274475 - Metric: 0.8595377802848816\n",
      "----- 0.745s -----\n",
      "Epochs 401/1000 - Loss: 0.4584132730960846 - Metric: 0.8602091670036316\n",
      "----- 0.748s -----\n",
      "Epochs 402/1000 - Loss: 0.45619726181030273 - Metric: 0.86102294921875\n",
      "----- 0.789s -----\n",
      "Epochs 403/1000 - Loss: 0.45720550417900085 - Metric: 0.8605549931526184\n",
      "----- 0.798s -----\n",
      "Epochs 404/1000 - Loss: 0.46561893820762634 - Metric: 0.8583781123161316\n",
      "----- 0.782s -----\n",
      "Epochs 405/1000 - Loss: 0.4595552384853363 - Metric: 0.8596598505973816\n",
      "----- 0.786s -----\n",
      "Epochs 406/1000 - Loss: 0.4563395082950592 - Metric: 0.8602294921875\n",
      "----- 0.791s -----\n",
      "Epochs 407/1000 - Loss: 0.460303395986557 - Metric: 0.8601277470588684\n",
      "----- 0.78s -----\n",
      "Epochs 408/1000 - Loss: 0.4646056592464447 - Metric: 0.8583984375\n",
      "----- 0.792s -----\n",
      "Epochs 409/1000 - Loss: 0.4578165113925934 - Metric: 0.8599039912223816\n",
      "----- 0.84s -----\n",
      "Epochs 410/1000 - Loss: 0.45738744735717773 - Metric: 0.85980224609375\n",
      "----- 0.766s -----\n",
      "Epochs 411/1000 - Loss: 0.4628840386867523 - Metric: 0.8594157099723816\n",
      "----- 0.745s -----\n",
      "Epochs 412/1000 - Loss: 0.45648813247680664 - Metric: 0.8604939579963684\n",
      "----- 0.728s -----\n",
      "Epochs 413/1000 - Loss: 0.456449955701828 - Metric: 0.8601277470588684\n",
      "----- 0.866s -----\n",
      "Epochs 414/1000 - Loss: 0.460627943277359 - Metric: 0.8598836064338684\n",
      "----- 0.775s -----\n",
      "Epochs 415/1000 - Loss: 0.4580080509185791 - Metric: 0.8594563603401184\n",
      "----- 0.743s -----\n",
      "Epochs 416/1000 - Loss: 0.4565723240375519 - Metric: 0.86004638671875\n",
      "----- 0.742s -----\n",
      "Epochs 417/1000 - Loss: 0.45868173241615295 - Metric: 0.8597412109375\n",
      "----- 0.777s -----\n",
      "Epochs 418/1000 - Loss: 0.45861124992370605 - Metric: 0.86029052734375\n",
      "----- 0.728s -----\n",
      "Epochs 419/1000 - Loss: 0.4564312994480133 - Metric: 0.8603515625\n",
      "----- 0.719s -----\n",
      "Epochs 420/1000 - Loss: 0.45702576637268066 - Metric: 0.860107421875\n",
      "----- 0.72s -----\n",
      "Epochs 421/1000 - Loss: 0.45975127816200256 - Metric: 0.8597615361213684\n",
      "----- 0.748s -----\n",
      "Epochs 422/1000 - Loss: 0.46083351969718933 - Metric: 0.8595173954963684\n",
      "----- 0.806s -----\n",
      "Epochs 423/1000 - Loss: 0.4558895528316498 - Metric: 0.8605753779411316\n",
      "----- 0.776s -----\n",
      "Epochs 424/1000 - Loss: 0.4580002725124359 - Metric: 0.85955810546875\n",
      "----- 0.794s -----\n",
      "Epochs 425/1000 - Loss: 0.46104657649993896 - Metric: 0.859130859375\n",
      "----- 0.768s -----\n",
      "Epochs 426/1000 - Loss: 0.45638903975486755 - Metric: 0.8602702021598816\n",
      "----- 0.769s -----\n",
      "Epochs 427/1000 - Loss: 0.45800283551216125 - Metric: 0.8594767451286316\n",
      "----- 0.746s -----\n",
      "Epochs 428/1000 - Loss: 0.4583094120025635 - Metric: 0.85986328125\n",
      "----- 0.765s -----\n",
      "Epochs 429/1000 - Loss: 0.4562060534954071 - Metric: 0.8600870966911316\n",
      "----- 0.761s -----\n",
      "Epochs 430/1000 - Loss: 0.4569215774536133 - Metric: 0.8603922724723816\n",
      "----- 0.78s -----\n",
      "Epochs 431/1000 - Loss: 0.4592761695384979 - Metric: 0.85931396484375\n",
      "----- 0.783s -----\n",
      "Epochs 432/1000 - Loss: 0.4554923474788666 - Metric: 0.86053466796875\n",
      "----- 0.713s -----\n",
      "Epochs 433/1000 - Loss: 0.45735764503479004 - Metric: 0.8594157099723816\n",
      "----- 0.718s -----\n",
      "Epochs 434/1000 - Loss: 0.45769524574279785 - Metric: 0.8594157099723816\n",
      "----- 0.727s -----\n",
      "Epochs 435/1000 - Loss: 0.4566901624202728 - Metric: 0.8601887822151184\n",
      "----- 0.769s -----\n",
      "Epochs 436/1000 - Loss: 0.45791104435920715 - Metric: 0.8597005009651184\n",
      "----- 0.762s -----\n",
      "Epochs 437/1000 - Loss: 0.45628952980041504 - Metric: 0.86016845703125\n",
      "----- 0.74s -----\n",
      "Epochs 438/1000 - Loss: 0.45811501145362854 - Metric: 0.8598836064338684\n",
      "----- 0.753s -----\n",
      "Epochs 439/1000 - Loss: 0.45786190032958984 - Metric: 0.8594970703125\n",
      "----- 0.813s -----\n",
      "Epochs 440/1000 - Loss: 0.4573531150817871 - Metric: 0.8596394658088684\n",
      "----- 0.776s -----\n",
      "Epochs 441/1000 - Loss: 0.46486616134643555 - Metric: 0.8575439453125\n",
      "----- 0.759s -----\n",
      "Epochs 442/1000 - Loss: 0.46437469124794006 - Metric: 0.8574422001838684\n",
      "----- 0.785s -----\n",
      "Epochs 443/1000 - Loss: 0.47486916184425354 - Metric: 0.8549397587776184\n",
      "----- 0.74s -----\n",
      "Epochs 444/1000 - Loss: 0.47251948714256287 - Metric: 0.8559977412223816\n",
      "----- 0.809s -----\n",
      "Epochs 445/1000 - Loss: 0.48998454213142395 - Metric: 0.85040283203125\n",
      "----- 0.759s -----\n",
      "Epochs 446/1000 - Loss: 0.484118789434433 - Metric: 0.8521321415901184\n",
      "----- 0.777s -----\n",
      "Epochs 447/1000 - Loss: 0.4692787826061249 - Metric: 0.8571370244026184\n",
      "----- 0.802s -----\n",
      "Epochs 448/1000 - Loss: 0.4649408757686615 - Metric: 0.85791015625\n",
      "----- 0.802s -----\n",
      "Epochs 449/1000 - Loss: 0.46799108386039734 - Metric: 0.8566691279411316\n",
      "----- 0.828s -----\n",
      "Epochs 450/1000 - Loss: 0.4626164436340332 - Metric: 0.8578694462776184\n",
      "----- 0.785s -----\n",
      "Epochs 451/1000 - Loss: 0.4634087383747101 - Metric: 0.8581339716911316\n",
      "----- 0.765s -----\n",
      "Epochs 452/1000 - Loss: 0.4606219530105591 - Metric: 0.859375\n",
      "----- 0.758s -----\n",
      "Epochs 453/1000 - Loss: 0.4618328809738159 - Metric: 0.8594970703125\n",
      "----- 0.796s -----\n",
      "Epochs 454/1000 - Loss: 0.46236059069633484 - Metric: 0.8585408329963684\n",
      "----- 0.753s -----\n",
      "Epochs 455/1000 - Loss: 0.46104666590690613 - Metric: 0.8588663935661316\n",
      "----- 0.755s -----\n",
      "Epochs 456/1000 - Loss: 0.46079954504966736 - Metric: 0.85955810546875\n",
      "----- 0.759s -----\n",
      "Epochs 457/1000 - Loss: 0.4575561583042145 - Metric: 0.8606974482536316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.831s -----\n",
      "Epochs 458/1000 - Loss: 0.4586373269557953 - Metric: 0.8601887822151184\n",
      "----- 0.78s -----\n",
      "Epochs 459/1000 - Loss: 0.45546814799308777 - Metric: 0.8612874150276184\n",
      "----- 0.809s -----\n",
      "Epochs 460/1000 - Loss: 0.456211656332016 - Metric: 0.8614705204963684\n",
      "----- 0.795s -----\n",
      "Epochs 461/1000 - Loss: 0.4553562104701996 - Metric: 0.8614094853401184\n",
      "----- 0.798s -----\n",
      "Epochs 462/1000 - Loss: 0.4549527168273926 - Metric: 0.8617756962776184\n",
      "----- 0.798s -----\n",
      "Epochs 463/1000 - Loss: 0.4521547257900238 - Metric: 0.86224365234375\n",
      "----- 0.774s -----\n",
      "Epochs 464/1000 - Loss: 0.4537382423877716 - Metric: 0.86260986328125\n",
      "----- 0.761s -----\n",
      "Epochs 465/1000 - Loss: 0.45313021540641785 - Metric: 0.8623453974723816\n",
      "----- 0.779s -----\n",
      "Epochs 466/1000 - Loss: 0.45276081562042236 - Metric: 0.862548828125\n",
      "----- 0.774s -----\n",
      "Epochs 467/1000 - Loss: 0.45141348242759705 - Metric: 0.8625285029411316\n",
      "----- 0.75s -----\n",
      "Epochs 468/1000 - Loss: 0.4544887840747833 - Metric: 0.86199951171875\n",
      "----- 0.746s -----\n",
      "Epochs 469/1000 - Loss: 0.4501686990261078 - Metric: 0.8625691533088684\n",
      "----- 0.999s -----\n",
      "Epochs 470/1000 - Loss: 0.45528876781463623 - Metric: 0.8616943359375\n",
      "----- 0.829s -----\n",
      "Epochs 471/1000 - Loss: 0.45247530937194824 - Metric: 0.8617146611213684\n",
      "----- 1.598s -----\n",
      "Epochs 472/1000 - Loss: 0.4528307616710663 - Metric: 0.86273193359375\n",
      "----- 0.864s -----\n",
      "Epochs 473/1000 - Loss: 0.4544394016265869 - Metric: 0.86090087890625\n",
      "----- 0.826s -----\n",
      "Epochs 474/1000 - Loss: 0.457258939743042 - Metric: 0.86041259765625\n",
      "----- 0.76s -----\n",
      "Epochs 475/1000 - Loss: 0.4541045129299164 - Metric: 0.8611653447151184\n",
      "----- 0.742s -----\n",
      "Epochs 476/1000 - Loss: 0.4546132981777191 - Metric: 0.86163330078125\n",
      "----- 0.734s -----\n",
      "Epochs 477/1000 - Loss: 0.45661601424217224 - Metric: 0.8603922724723816\n",
      "----- 0.722s -----\n",
      "Epochs 478/1000 - Loss: 0.4591648578643799 - Metric: 0.8595377802848816\n",
      "----- 0.774s -----\n",
      "Epochs 479/1000 - Loss: 0.45165371894836426 - Metric: 0.8614705204963684\n",
      "----- 0.749s -----\n",
      "Epochs 480/1000 - Loss: 0.46007871627807617 - Metric: 0.8595377802848816\n",
      "----- 0.745s -----\n",
      "Epochs 481/1000 - Loss: 0.45327457785606384 - Metric: 0.8611043095588684\n",
      "----- 0.752s -----\n",
      "Epochs 482/1000 - Loss: 0.46033453941345215 - Metric: 0.8598429560661316\n",
      "----- 0.801s -----\n",
      "Epochs 483/1000 - Loss: 0.4556030035018921 - Metric: 0.860595703125\n",
      "----- 0.781s -----\n",
      "Epochs 484/1000 - Loss: 0.4564729630947113 - Metric: 0.86053466796875\n",
      "----- 0.758s -----\n",
      "Epochs 485/1000 - Loss: 0.46105799078941345 - Metric: 0.8595784306526184\n",
      "----- 0.788s -----\n",
      "Epochs 486/1000 - Loss: 0.45683977007865906 - Metric: 0.86065673828125\n",
      "----- 0.744s -----\n",
      "Epochs 487/1000 - Loss: 0.4546932876110077 - Metric: 0.8608195185661316\n",
      "----- 0.747s -----\n",
      "Epochs 488/1000 - Loss: 0.4615441858768463 - Metric: 0.8592122197151184\n",
      "----- 0.785s -----\n",
      "Epochs 489/1000 - Loss: 0.4585660696029663 - Metric: 0.8595173954963684\n",
      "----- 0.716s -----\n",
      "Epochs 490/1000 - Loss: 0.45460304617881775 - Metric: 0.8609822392463684\n",
      "----- 0.728s -----\n",
      "Epochs 491/1000 - Loss: 0.4625471532344818 - Metric: 0.8588053584098816\n",
      "----- 0.812s -----\n",
      "Epochs 492/1000 - Loss: 0.45570671558380127 - Metric: 0.8608195185661316\n",
      "----- 0.719s -----\n",
      "Epochs 493/1000 - Loss: 0.46070942282676697 - Metric: 0.8594767451286316\n",
      "----- 0.787s -----\n",
      "Epochs 494/1000 - Loss: 0.45544496178627014 - Metric: 0.86090087890625\n",
      "----- 0.776s -----\n",
      "Epochs 495/1000 - Loss: 0.4611985385417938 - Metric: 0.8585001826286316\n",
      "----- 0.738s -----\n",
      "Epochs 496/1000 - Loss: 0.4539453983306885 - Metric: 0.86126708984375\n",
      "----- 0.759s -----\n",
      "Epochs 497/1000 - Loss: 0.4544326961040497 - Metric: 0.8607991337776184\n",
      "----- 0.756s -----\n",
      "Epochs 498/1000 - Loss: 0.4619046747684479 - Metric: 0.859130859375\n",
      "----- 0.761s -----\n",
      "Epochs 499/1000 - Loss: 0.44950732588768005 - Metric: 0.8626912236213684\n",
      "----- 0.799s -----\n",
      "Epochs 500/1000 - Loss: 0.45605766773223877 - Metric: 0.8605753779411316\n",
      "----- 0.803s -----\n",
      "Epochs 501/1000 - Loss: 0.45446133613586426 - Metric: 0.861328125\n",
      "----- 0.728s -----\n",
      "Epochs 502/1000 - Loss: 0.4584207534790039 - Metric: 0.8604939579963684\n",
      "----- 0.753s -----\n",
      "Epochs 503/1000 - Loss: 0.47556543350219727 - Metric: 0.8553263545036316\n",
      "----- 0.717s -----\n",
      "Epochs 504/1000 - Loss: 0.4601093828678131 - Metric: 0.8600870966911316\n",
      "----- 0.714s -----\n",
      "Epochs 505/1000 - Loss: 0.45072779059410095 - Metric: 0.8624267578125\n",
      "----- 0.793s -----\n",
      "Epochs 506/1000 - Loss: 0.44725465774536133 - Metric: 0.8625895380973816\n",
      "----- 0.754s -----\n",
      "Epochs 507/1000 - Loss: 0.44659891724586487 - Metric: 0.8641764521598816\n",
      "----- 0.77s -----\n",
      "Epochs 508/1000 - Loss: 0.4470323324203491 - Metric: 0.8631795048713684\n",
      "----- 0.762s -----\n",
      "Epochs 509/1000 - Loss: 0.4455909729003906 - Metric: 0.8635661005973816\n",
      "----- 0.788s -----\n",
      "Epochs 510/1000 - Loss: 0.4472409784793854 - Metric: 0.86322021484375\n",
      "----- 0.751s -----\n",
      "Epochs 511/1000 - Loss: 0.4453420341014862 - Metric: 0.8637288212776184\n",
      "----- 0.775s -----\n",
      "Epochs 512/1000 - Loss: 0.4475988447666168 - Metric: 0.8633829951286316\n",
      "----- 0.815s -----\n",
      "Epochs 513/1000 - Loss: 0.4448187053203583 - Metric: 0.8636881709098816\n",
      "----- 0.789s -----\n",
      "Epochs 514/1000 - Loss: 0.4456864595413208 - Metric: 0.86370849609375\n",
      "----- 0.866s -----\n",
      "Epochs 515/1000 - Loss: 0.44613996148109436 - Metric: 0.8640339970588684\n",
      "----- 0.761s -----\n",
      "Epochs 516/1000 - Loss: 0.44415751099586487 - Metric: 0.8645222783088684\n",
      "----- 0.78s -----\n",
      "Epochs 517/1000 - Loss: 0.4471888244152069 - Metric: 0.8627522587776184\n",
      "----- 0.752s -----\n",
      "Epochs 518/1000 - Loss: 0.4444082975387573 - Metric: 0.86376953125\n",
      "----- 0.779s -----\n",
      "Epochs 519/1000 - Loss: 0.44527968764305115 - Metric: 0.8635050654411316\n",
      "----- 0.746s -----\n",
      "Epochs 520/1000 - Loss: 0.4457494020462036 - Metric: 0.8636067509651184\n",
      "----- 0.71s -----\n",
      "Epochs 521/1000 - Loss: 0.4459162652492523 - Metric: 0.86383056640625\n",
      "----- 0.713s -----\n",
      "Epochs 522/1000 - Loss: 0.4460477828979492 - Metric: 0.8637492060661316\n",
      "----- 0.748s -----\n",
      "Epochs 523/1000 - Loss: 0.4482741057872772 - Metric: 0.8633015751838684\n",
      "----- 0.769s -----\n",
      "Epochs 524/1000 - Loss: 0.4493846893310547 - Metric: 0.8629150390625\n",
      "----- 0.735s -----\n",
      "Epochs 525/1000 - Loss: 0.4480673372745514 - Metric: 0.8629963994026184\n",
      "----- 0.737s -----\n",
      "Epochs 526/1000 - Loss: 0.45338892936706543 - Metric: 0.8616740107536316\n",
      "----- 0.736s -----\n",
      "Epochs 527/1000 - Loss: 0.45203304290771484 - Metric: 0.86187744140625\n",
      "----- 0.784s -----\n",
      "Epochs 528/1000 - Loss: 0.4585394561290741 - Metric: 0.86016845703125\n",
      "----- 0.775s -----\n",
      "Epochs 529/1000 - Loss: 0.45425835251808167 - Metric: 0.8617146611213684\n",
      "----- 0.769s -----\n",
      "Epochs 530/1000 - Loss: 0.4698004424571991 - Metric: 0.85699462890625\n",
      "----- 0.744s -----\n",
      "Epochs 531/1000 - Loss: 0.45756077766418457 - Metric: 0.8603108525276184\n",
      "----- 0.733s -----\n",
      "Epochs 532/1000 - Loss: 0.4657013416290283 - Metric: 0.8582763671875\n",
      "----- 0.799s -----\n",
      "Epochs 533/1000 - Loss: 0.4612294137477875 - Metric: 0.859375\n",
      "----- 0.752s -----\n",
      "Epochs 534/1000 - Loss: 0.45217904448509216 - Metric: 0.8622843623161316\n",
      "----- 0.758s -----\n",
      "Epochs 535/1000 - Loss: 0.4609808921813965 - Metric: 0.85955810546875\n",
      "----- 0.736s -----\n",
      "Epochs 536/1000 - Loss: 0.46549156308174133 - Metric: 0.8580322265625\n",
      "----- 0.759s -----\n",
      "Epochs 537/1000 - Loss: 0.45249518752098083 - Metric: 0.86163330078125\n",
      "----- 0.731s -----\n",
      "Epochs 538/1000 - Loss: 0.4490329325199127 - Metric: 0.8623860478401184\n",
      "----- 0.739s -----\n",
      "Epochs 539/1000 - Loss: 0.4446631968021393 - Metric: 0.864501953125\n",
      "----- 0.737s -----\n",
      "Epochs 540/1000 - Loss: 0.44668400287628174 - Metric: 0.8635661005973816\n",
      "----- 0.785s -----\n",
      "Epochs 541/1000 - Loss: 0.443101167678833 - Metric: 0.864990234375\n",
      "----- 0.85s -----\n",
      "Epochs 542/1000 - Loss: 0.44675981998443604 - Metric: 0.8637492060661316\n",
      "----- 0.75s -----\n",
      "Epochs 543/1000 - Loss: 0.44908347725868225 - Metric: 0.8630778193473816\n",
      "----- 0.789s -----\n",
      "Epochs 544/1000 - Loss: 0.44858893752098083 - Metric: 0.8630574345588684\n",
      "----- 0.884s -----\n",
      "Epochs 545/1000 - Loss: 0.44916316866874695 - Metric: 0.86328125\n",
      "----- 0.817s -----\n",
      "Epochs 546/1000 - Loss: 0.4477027356624603 - Metric: 0.8635457158088684\n",
      "----- 0.781s -----\n",
      "Epochs 547/1000 - Loss: 0.4495549201965332 - Metric: 0.8633015751838684\n",
      "----- 0.787s -----\n",
      "Epochs 548/1000 - Loss: 0.4513200521469116 - Metric: 0.8630778193473816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.724s -----\n",
      "Epochs 549/1000 - Loss: 0.4499329626560211 - Metric: 0.8635050654411316\n",
      "----- 0.731s -----\n",
      "Epochs 550/1000 - Loss: 0.45232895016670227 - Metric: 0.8628336787223816\n",
      "----- 0.745s -----\n",
      "Epochs 551/1000 - Loss: 0.4470764398574829 - Metric: 0.8642578125\n",
      "----- 0.737s -----\n",
      "Epochs 552/1000 - Loss: 0.4503974914550781 - Metric: 0.8626912236213684\n",
      "----- 0.727s -----\n",
      "Epochs 553/1000 - Loss: 0.45059147477149963 - Metric: 0.8629353642463684\n",
      "----- 0.753s -----\n",
      "Epochs 554/1000 - Loss: 0.4502764642238617 - Metric: 0.8628336787223816\n",
      "----- 0.738s -----\n",
      "Epochs 555/1000 - Loss: 0.45406675338745117 - Metric: 0.8614705204963684\n",
      "----- 0.736s -----\n",
      "Epochs 556/1000 - Loss: 0.4618602693080902 - Metric: 0.8594157099723816\n",
      "----- 0.739s -----\n",
      "Epochs 557/1000 - Loss: 0.4735022485256195 - Metric: 0.8559367060661316\n",
      "----- 0.73s -----\n",
      "Epochs 558/1000 - Loss: 0.47088584303855896 - Metric: 0.8568522334098816\n",
      "----- 0.721s -----\n",
      "Epochs 559/1000 - Loss: 0.4664480686187744 - Metric: 0.8578287959098816\n",
      "----- 0.928s -----\n",
      "Epochs 560/1000 - Loss: 0.4472671449184418 - Metric: 0.864013671875\n",
      "----- 0.723s -----\n",
      "Epochs 561/1000 - Loss: 0.44635820388793945 - Metric: 0.86358642578125\n",
      "----- 0.715s -----\n",
      "Epochs 562/1000 - Loss: 0.45232608914375305 - Metric: 0.8623250126838684\n",
      "----- 0.714s -----\n",
      "Epochs 563/1000 - Loss: 0.4536294937133789 - Metric: 0.8615925908088684\n",
      "----- 0.723s -----\n",
      "Epochs 564/1000 - Loss: 0.44600236415863037 - Metric: 0.8642578125\n",
      "----- 0.733s -----\n",
      "Epochs 565/1000 - Loss: 0.44676685333251953 - Metric: 0.86328125\n",
      "----- 0.759s -----\n",
      "Epochs 566/1000 - Loss: 0.44962048530578613 - Metric: 0.86248779296875\n",
      "----- 0.718s -----\n",
      "Epochs 567/1000 - Loss: 0.45303305983543396 - Metric: 0.8619588017463684\n",
      "----- 0.718s -----\n",
      "Epochs 568/1000 - Loss: 0.45623502135276794 - Metric: 0.8601481318473816\n",
      "----- 0.726s -----\n",
      "Epochs 569/1000 - Loss: 0.4538584053516388 - Metric: 0.8609415888786316\n",
      "----- 0.729s -----\n",
      "Epochs 570/1000 - Loss: 0.4504036605358124 - Metric: 0.8619791865348816\n",
      "----- 0.728s -----\n",
      "Epochs 571/1000 - Loss: 0.44547238945961 - Metric: 0.8642171025276184\n",
      "----- 0.757s -----\n",
      "Epochs 572/1000 - Loss: 0.445576548576355 - Metric: 0.86383056640625\n",
      "----- 0.736s -----\n",
      "Epochs 573/1000 - Loss: 0.44601598381996155 - Metric: 0.86419677734375\n",
      "----- 0.729s -----\n",
      "Epochs 574/1000 - Loss: 0.45027247071266174 - Metric: 0.8633219599723816\n",
      "----- 0.717s -----\n",
      "Epochs 575/1000 - Loss: 0.4555644094944 - Metric: 0.8602702021598816\n",
      "----- 0.718s -----\n",
      "Epochs 576/1000 - Loss: 0.4521477520465851 - Metric: 0.8619588017463684\n",
      "----- 0.779s -----\n",
      "Epochs 577/1000 - Loss: 0.45357170701026917 - Metric: 0.8618571162223816\n",
      "----- 0.736s -----\n",
      "Epochs 578/1000 - Loss: 0.4474879503250122 - Metric: 0.8631795048713684\n",
      "----- 0.754s -----\n",
      "Epochs 579/1000 - Loss: 0.4469630718231201 - Metric: 0.8636881709098816\n",
      "----- 0.73s -----\n",
      "Epochs 580/1000 - Loss: 0.45645856857299805 - Metric: 0.860595703125\n",
      "----- 0.828s -----\n",
      "Epochs 581/1000 - Loss: 0.461688756942749 - Metric: 0.8591715693473816\n",
      "----- 0.759s -----\n",
      "Epochs 582/1000 - Loss: 0.46134743094444275 - Metric: 0.85919189453125\n",
      "----- 0.958s -----\n",
      "Epochs 583/1000 - Loss: 0.4591507911682129 - Metric: 0.8595173954963684\n",
      "----- 0.764s -----\n",
      "Epochs 584/1000 - Loss: 0.4445481598377228 - Metric: 0.8647868037223816\n",
      "----- 0.778s -----\n",
      "Epochs 585/1000 - Loss: 0.44415584206581116 - Metric: 0.8641154170036316\n",
      "----- 0.758s -----\n",
      "Epochs 586/1000 - Loss: 0.4509587585926056 - Metric: 0.862060546875\n",
      "----- 0.774s -----\n",
      "Epochs 587/1000 - Loss: 0.45062384009361267 - Metric: 0.8626912236213684\n",
      "----- 0.928s -----\n",
      "Epochs 588/1000 - Loss: 0.44833362102508545 - Metric: 0.86376953125\n",
      "----- 0.755s -----\n",
      "Epochs 589/1000 - Loss: 0.44566258788108826 - Metric: 0.8642171025276184\n",
      "----- 0.756s -----\n",
      "Epochs 590/1000 - Loss: 0.44520998001098633 - Metric: 0.8639933466911316\n",
      "----- 0.762s -----\n",
      "Epochs 591/1000 - Loss: 0.45473185181617737 - Metric: 0.8604533076286316\n",
      "----- 0.905s -----\n",
      "Epochs 592/1000 - Loss: 0.452341228723526 - Metric: 0.86163330078125\n",
      "----- 0.789s -----\n",
      "Epochs 593/1000 - Loss: 0.45433080196380615 - Metric: 0.86102294921875\n",
      "----- 0.805s -----\n",
      "Epochs 594/1000 - Loss: 0.45126795768737793 - Metric: 0.8616740107536316\n",
      "----- 0.765s -----\n",
      "Epochs 595/1000 - Loss: 0.44345006346702576 - Metric: 0.8646240234375\n",
      "----- 0.752s -----\n",
      "Epochs 596/1000 - Loss: 0.44505953788757324 - Metric: 0.8636677861213684\n",
      "----- 0.899s -----\n",
      "Epochs 597/1000 - Loss: 0.443864107131958 - Metric: 0.8647053837776184\n",
      "----- 0.769s -----\n",
      "Epochs 598/1000 - Loss: 0.4445037543773651 - Metric: 0.8645222783088684\n",
      "----- 0.784s -----\n",
      "Epochs 599/1000 - Loss: 0.45059093832969666 - Metric: 0.8626505732536316\n",
      "----- 0.775s -----\n",
      "Epochs 600/1000 - Loss: 0.44886377453804016 - Metric: 0.86260986328125\n",
      "----- 0.768s -----\n",
      "Epochs 601/1000 - Loss: 0.4555356800556183 - Metric: 0.86090087890625\n",
      "----- 0.917s -----\n",
      "Epochs 602/1000 - Loss: 0.4490222930908203 - Metric: 0.86297607421875\n",
      "----- 0.736s -----\n",
      "Epochs 603/1000 - Loss: 0.44736728072166443 - Metric: 0.8634033203125\n",
      "----- 0.736s -----\n",
      "Epochs 604/1000 - Loss: 0.4506608545780182 - Metric: 0.86224365234375\n",
      "----- 0.785s -----\n",
      "Epochs 605/1000 - Loss: 0.4565598964691162 - Metric: 0.8592326045036316\n",
      "----- 0.989s -----\n",
      "Epochs 606/1000 - Loss: 0.4590507447719574 - Metric: 0.8595377802848816\n",
      "----- 0.78s -----\n",
      "Epochs 607/1000 - Loss: 0.46205854415893555 - Metric: 0.8588460087776184\n",
      "----- 0.801s -----\n",
      "Epochs 608/1000 - Loss: 0.4511888027191162 - Metric: 0.86248779296875\n",
      "----- 0.802s -----\n",
      "Epochs 609/1000 - Loss: 0.4441905915737152 - Metric: 0.86370849609375\n",
      "----- 0.79s -----\n",
      "Epochs 610/1000 - Loss: 0.44411516189575195 - Metric: 0.8632405400276184\n",
      "----- 0.896s -----\n",
      "Epochs 611/1000 - Loss: 0.4479750096797943 - Metric: 0.86273193359375\n",
      "----- 0.764s -----\n",
      "Epochs 612/1000 - Loss: 0.4498002231121063 - Metric: 0.8622843623161316\n",
      "----- 0.766s -----\n",
      "Epochs 613/1000 - Loss: 0.4444314241409302 - Metric: 0.8646036982536316\n",
      "----- 0.759s -----\n",
      "Epochs 614/1000 - Loss: 0.44540977478027344 - Metric: 0.8636067509651184\n",
      "----- 0.77s -----\n",
      "Epochs 615/1000 - Loss: 0.4491206407546997 - Metric: 0.8624470829963684\n",
      "----- 0.875s -----\n",
      "Epochs 616/1000 - Loss: 0.4562608301639557 - Metric: 0.86016845703125\n",
      "----- 0.757s -----\n",
      "Epochs 617/1000 - Loss: 0.45937344431877136 - Metric: 0.85906982421875\n",
      "----- 0.754s -----\n",
      "Epochs 618/1000 - Loss: 0.4584082067012787 - Metric: 0.8595784306526184\n",
      "----- 0.751s -----\n",
      "Epochs 619/1000 - Loss: 0.45127272605895996 - Metric: 0.8616943359375\n",
      "----- 0.88s -----\n",
      "Epochs 620/1000 - Loss: 0.44656428694725037 - Metric: 0.86346435546875\n",
      "----- 0.854s -----\n",
      "Epochs 621/1000 - Loss: 0.4421826899051666 - Metric: 0.86456298828125\n",
      "----- 0.844s -----\n",
      "Epochs 622/1000 - Loss: 0.4456154406070709 - Metric: 0.86376953125\n",
      "----- 0.778s -----\n",
      "Epochs 623/1000 - Loss: 0.448174387216568 - Metric: 0.8627522587776184\n",
      "----- 0.733s -----\n",
      "Epochs 624/1000 - Loss: 0.45234599709510803 - Metric: 0.86126708984375\n",
      "----- 0.925s -----\n",
      "Epochs 625/1000 - Loss: 0.44677940011024475 - Metric: 0.8630574345588684\n",
      "----- 0.762s -----\n",
      "Epochs 626/1000 - Loss: 0.44743612408638 - Metric: 0.8636677861213684\n",
      "----- 0.743s -----\n",
      "Epochs 627/1000 - Loss: 0.44624218344688416 - Metric: 0.8633829951286316\n",
      "----- 0.739s -----\n",
      "Epochs 628/1000 - Loss: 0.44759246706962585 - Metric: 0.8623453974723816\n",
      "----- 0.743s -----\n",
      "Epochs 629/1000 - Loss: 0.4483141601085663 - Metric: 0.8623860478401184\n",
      "----- 0.896s -----\n",
      "Epochs 630/1000 - Loss: 0.45395636558532715 - Metric: 0.860595703125\n",
      "----- 0.759s -----\n",
      "Epochs 631/1000 - Loss: 0.4503633975982666 - Metric: 0.8614909052848816\n",
      "----- 0.776s -----\n",
      "Epochs 632/1000 - Loss: 0.4587828814983368 - Metric: 0.8590494990348816\n",
      "----- 0.784s -----\n",
      "Epochs 633/1000 - Loss: 0.44986164569854736 - Metric: 0.8619181513786316\n",
      "----- 0.81s -----\n",
      "Epochs 634/1000 - Loss: 0.4504932463169098 - Metric: 0.8612874150276184\n",
      "----- 0.973s -----\n",
      "Epochs 635/1000 - Loss: 0.4495961666107178 - Metric: 0.8614094853401184\n",
      "----- 0.808s -----\n",
      "Epochs 636/1000 - Loss: 0.44866621494293213 - Metric: 0.8624267578125\n",
      "----- 0.804s -----\n",
      "Epochs 637/1000 - Loss: 0.44357410073280334 - Metric: 0.86395263671875\n",
      "----- 0.785s -----\n",
      "Epochs 638/1000 - Loss: 0.4438711106777191 - Metric: 0.8637492060661316\n",
      "----- 0.978s -----\n",
      "Epochs 639/1000 - Loss: 0.44575485587120056 - Metric: 0.8639933466911316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.849s -----\n",
      "Epochs 640/1000 - Loss: 0.4466297924518585 - Metric: 0.86297607421875\n",
      "----- 0.746s -----\n",
      "Epochs 641/1000 - Loss: 0.45055094361305237 - Metric: 0.8621419072151184\n",
      "----- 0.759s -----\n",
      "Epochs 642/1000 - Loss: 0.4572724401950836 - Metric: 0.8600260615348816\n",
      "----- 0.784s -----\n",
      "Epochs 643/1000 - Loss: 0.4548821449279785 - Metric: 0.8610636591911316\n",
      "----- 0.753s -----\n",
      "Epochs 644/1000 - Loss: 0.45175495743751526 - Metric: 0.861328125\n",
      "----- 0.738s -----\n",
      "Epochs 645/1000 - Loss: 0.4535259008407593 - Metric: 0.8604736328125\n",
      "----- 0.76s -----\n",
      "Epochs 646/1000 - Loss: 0.45785439014434814 - Metric: 0.8590291142463684\n",
      "----- 0.752s -----\n",
      "Epochs 647/1000 - Loss: 0.4671598970890045 - Metric: 0.8560994267463684\n",
      "----- 0.773s -----\n",
      "Epochs 648/1000 - Loss: 0.4576960504055023 - Metric: 0.8592529296875\n",
      "----- 0.77s -----\n",
      "Epochs 649/1000 - Loss: 0.44880518317222595 - Metric: 0.8620198369026184\n",
      "----- 0.752s -----\n",
      "Epochs 650/1000 - Loss: 0.44308510422706604 - Metric: 0.8631591796875\n",
      "----- 0.726s -----\n",
      "Epochs 651/1000 - Loss: 0.44407328963279724 - Metric: 0.8643391728401184\n",
      "----- 0.74s -----\n",
      "Epochs 652/1000 - Loss: 0.44376340508461 - Metric: 0.8636677861213684\n",
      "----- 0.761s -----\n",
      "Epochs 653/1000 - Loss: 0.4461636543273926 - Metric: 0.8628743290901184\n",
      "----- 0.765s -----\n",
      "Epochs 654/1000 - Loss: 0.44200387597084045 - Metric: 0.8631795048713684\n",
      "----- 0.742s -----\n",
      "Epochs 655/1000 - Loss: 0.44401001930236816 - Metric: 0.8630574345588684\n",
      "----- 0.797s -----\n",
      "Epochs 656/1000 - Loss: 0.4455282986164093 - Metric: 0.8625895380973816\n",
      "----- 0.833s -----\n",
      "Epochs 657/1000 - Loss: 0.44209983944892883 - Metric: 0.86407470703125\n",
      "----- 0.797s -----\n",
      "Epochs 658/1000 - Loss: 0.4500918388366699 - Metric: 0.8618571162223816\n",
      "----- 0.794s -----\n",
      "Epochs 659/1000 - Loss: 0.45097360014915466 - Metric: 0.8608195185661316\n",
      "----- 0.867s -----\n",
      "Epochs 660/1000 - Loss: 0.45612916350364685 - Metric: 0.8600056767463684\n",
      "----- 0.762s -----\n",
      "Epochs 661/1000 - Loss: 0.45839807391166687 - Metric: 0.85888671875\n",
      "----- 0.778s -----\n",
      "Epochs 662/1000 - Loss: 0.45839551091194153 - Metric: 0.8594563603401184\n",
      "----- 0.765s -----\n",
      "Epochs 663/1000 - Loss: 0.4522085189819336 - Metric: 0.8609619140625\n",
      "----- 0.764s -----\n",
      "Epochs 664/1000 - Loss: 0.4466913938522339 - Metric: 0.8617960810661316\n",
      "----- 0.755s -----\n",
      "Epochs 665/1000 - Loss: 0.4422966539859772 - Metric: 0.86328125\n",
      "----- 0.784s -----\n",
      "Epochs 666/1000 - Loss: 0.4424913227558136 - Metric: 0.8644816279411316\n",
      "----- 0.766s -----\n",
      "Epochs 667/1000 - Loss: 0.4474809467792511 - Metric: 0.8627116084098816\n",
      "----- 0.947s -----\n",
      "Epochs 668/1000 - Loss: 0.4483150541782379 - Metric: 0.86297607421875\n",
      "----- 0.778s -----\n",
      "Epochs 669/1000 - Loss: 0.45361483097076416 - Metric: 0.86090087890625\n",
      "----- 0.777s -----\n",
      "Epochs 670/1000 - Loss: 0.44897595047950745 - Metric: 0.8623860478401184\n",
      "----- 0.784s -----\n",
      "Epochs 671/1000 - Loss: 0.44525814056396484 - Metric: 0.8632405400276184\n",
      "----- 0.799s -----\n",
      "Epochs 672/1000 - Loss: 0.4431370794773102 - Metric: 0.8636067509651184\n",
      "----- 0.794s -----\n",
      "Epochs 673/1000 - Loss: 0.45558997988700867 - Metric: 0.8602091670036316\n",
      "----- 0.772s -----\n",
      "Epochs 674/1000 - Loss: 0.4626336991786957 - Metric: 0.8585408329963684\n",
      "----- 0.737s -----\n",
      "Epochs 675/1000 - Loss: 0.46496641635894775 - Metric: 0.8568522334098816\n",
      "----- 0.888s -----\n",
      "Epochs 676/1000 - Loss: 0.4539087116718292 - Metric: 0.8601277470588684\n",
      "----- 0.725s -----\n",
      "Epochs 677/1000 - Loss: 0.4425133168697357 - Metric: 0.8630574345588684\n",
      "----- 0.715s -----\n",
      "Epochs 678/1000 - Loss: 0.4429560601711273 - Metric: 0.8641154170036316\n",
      "----- 0.784s -----\n",
      "Epochs 679/1000 - Loss: 0.445084810256958 - Metric: 0.8628132939338684\n",
      "----- 0.761s -----\n",
      "Epochs 680/1000 - Loss: 0.4444509446620941 - Metric: 0.8633015751838684\n",
      "----- 0.745s -----\n",
      "Epochs 681/1000 - Loss: 0.44508644938468933 - Metric: 0.8623250126838684\n",
      "----- 0.711s -----\n",
      "Epochs 682/1000 - Loss: 0.44253239035606384 - Metric: 0.8636677861213684\n",
      "----- 0.909s -----\n",
      "Epochs 683/1000 - Loss: 0.4441258907318115 - Metric: 0.8637898564338684\n",
      "----- 0.805s -----\n",
      "Epochs 684/1000 - Loss: 0.44858911633491516 - Metric: 0.8625285029411316\n",
      "----- 1.054s -----\n",
      "Epochs 685/1000 - Loss: 0.4544554650783539 - Metric: 0.8611043095588684\n",
      "----- 1.251s -----\n",
      "Epochs 686/1000 - Loss: 0.45510029792785645 - Metric: 0.85992431640625\n",
      "----- 1.063s -----\n",
      "Epochs 687/1000 - Loss: 0.4463382661342621 - Metric: 0.86334228515625\n",
      "----- 0.946s -----\n",
      "Epochs 688/1000 - Loss: 0.4470078945159912 - Metric: 0.86279296875\n",
      "----- 0.808s -----\n",
      "Epochs 689/1000 - Loss: 0.4451018273830414 - Metric: 0.8628743290901184\n",
      "----- 0.858s -----\n",
      "Epochs 690/1000 - Loss: 0.4419609606266022 - Metric: 0.8637492060661316\n",
      "----- 1.189s -----\n",
      "Epochs 691/1000 - Loss: 0.4412476718425751 - Metric: 0.8644816279411316\n",
      "----- 1.04s -----\n",
      "Epochs 692/1000 - Loss: 0.4381852149963379 - Metric: 0.86572265625\n",
      "----- 0.975s -----\n",
      "Epochs 693/1000 - Loss: 0.442376047372818 - Metric: 0.86383056640625\n",
      "----- 1.137s -----\n",
      "Epochs 694/1000 - Loss: 0.44020795822143555 - Metric: 0.86468505859375\n",
      "----- 0.905s -----\n",
      "Epochs 695/1000 - Loss: 0.44375482201576233 - Metric: 0.8633829951286316\n",
      "----- 0.932s -----\n",
      "Epochs 696/1000 - Loss: 0.4436739981174469 - Metric: 0.8631998896598816\n",
      "----- 1.117s -----\n",
      "Epochs 697/1000 - Loss: 0.4419274628162384 - Metric: 0.8636271357536316\n",
      "----- 0.855s -----\n",
      "Epochs 698/1000 - Loss: 0.4420027434825897 - Metric: 0.8641560673713684\n",
      "----- 1.052s -----\n",
      "Epochs 699/1000 - Loss: 0.44369396567344666 - Metric: 0.8636271357536316\n",
      "----- 0.811s -----\n",
      "Epochs 700/1000 - Loss: 0.4415772259235382 - Metric: 0.8638916015625\n",
      "----- 0.784s -----\n",
      "Epochs 701/1000 - Loss: 0.4412600100040436 - Metric: 0.86407470703125\n",
      "----- 0.807s -----\n",
      "Epochs 702/1000 - Loss: 0.4428994655609131 - Metric: 0.8638712763786316\n",
      "----- 0.742s -----\n",
      "Epochs 703/1000 - Loss: 0.4499092996120453 - Metric: 0.8613484501838684\n",
      "----- 0.715s -----\n",
      "Epochs 704/1000 - Loss: 0.46052655577659607 - Metric: 0.8586222529411316\n",
      "----- 0.774s -----\n",
      "Epochs 705/1000 - Loss: 0.4602454602718353 - Metric: 0.8587239384651184\n",
      "----- 0.752s -----\n",
      "Epochs 706/1000 - Loss: 0.46925416588783264 - Metric: 0.85595703125\n",
      "----- 1.082s -----\n",
      "Epochs 707/1000 - Loss: 0.45056748390197754 - Metric: 0.8616536259651184\n",
      "----- 0.906s -----\n",
      "Epochs 708/1000 - Loss: 0.4429967403411865 - Metric: 0.8632405400276184\n",
      "----- 0.884s -----\n",
      "Epochs 709/1000 - Loss: 0.43979835510253906 - Metric: 0.8647053837776184\n",
      "----- 0.86s -----\n",
      "Epochs 710/1000 - Loss: 0.44400501251220703 - Metric: 0.8637898564338684\n",
      "----- 1.004s -----\n",
      "Epochs 711/1000 - Loss: 0.4409773349761963 - Metric: 0.8648681640625\n",
      "----- 0.942s -----\n",
      "Epochs 712/1000 - Loss: 0.44461342692375183 - Metric: 0.86431884765625\n",
      "----- 1.465s -----\n",
      "Epochs 713/1000 - Loss: 0.44025373458862305 - Metric: 0.8648884892463684\n",
      "----- 1.52s -----\n",
      "Epochs 714/1000 - Loss: 0.43954166769981384 - Metric: 0.86395263671875\n",
      "----- 1.348s -----\n",
      "Epochs 715/1000 - Loss: 0.4481518268585205 - Metric: 0.8621622920036316\n",
      "----- 1.342s -----\n",
      "Epochs 716/1000 - Loss: 0.4609973728656769 - Metric: 0.8583781123161316\n",
      "----- 1.024s -----\n",
      "Epochs 717/1000 - Loss: 0.4504971504211426 - Metric: 0.86138916015625\n",
      "----- 0.963s -----\n",
      "Epochs 718/1000 - Loss: 0.4406006336212158 - Metric: 0.8647053837776184\n",
      "----- 1.072s -----\n",
      "Epochs 719/1000 - Loss: 0.4363817274570465 - Metric: 0.8661295771598816\n",
      "----- 1.058s -----\n",
      "Epochs 720/1000 - Loss: 0.436715692281723 - Metric: 0.8660075068473816\n",
      "----- 0.821s -----\n",
      "Epochs 721/1000 - Loss: 0.43907037377357483 - Metric: 0.8656005859375\n",
      "----- 0.78s -----\n",
      "Epochs 722/1000 - Loss: 0.4372577667236328 - Metric: 0.8656209111213684\n",
      "----- 0.769s -----\n",
      "Epochs 723/1000 - Loss: 0.43776026368141174 - Metric: 0.8655192255973816\n",
      "----- 0.999s -----\n",
      "Epochs 724/1000 - Loss: 0.43987131118774414 - Metric: 0.8646443486213684\n",
      "----- 0.811s -----\n",
      "Epochs 725/1000 - Loss: 0.4452399015426636 - Metric: 0.8629150390625\n",
      "----- 1.009s -----\n",
      "Epochs 726/1000 - Loss: 0.449920654296875 - Metric: 0.86151123046875\n",
      "----- 1.01s -----\n",
      "Epochs 727/1000 - Loss: 0.44752609729766846 - Metric: 0.8622233271598816\n",
      "----- 0.836s -----\n",
      "Epochs 728/1000 - Loss: 0.45559728145599365 - Metric: 0.8605549931526184\n",
      "----- 0.789s -----\n",
      "Epochs 729/1000 - Loss: 0.444242924451828 - Metric: 0.8634846806526184\n",
      "----- 0.736s -----\n",
      "Epochs 730/1000 - Loss: 0.44894900918006897 - Metric: 0.86187744140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.724s -----\n",
      "Epochs 731/1000 - Loss: 0.43977198004722595 - Metric: 0.8653971552848816\n",
      "----- 0.819s -----\n",
      "Epochs 732/1000 - Loss: 0.43902459740638733 - Metric: 0.8650105595588684\n",
      "----- 0.768s -----\n",
      "Epochs 733/1000 - Loss: 0.4387001097202301 - Metric: 0.8658650517463684\n",
      "----- 0.762s -----\n",
      "Epochs 734/1000 - Loss: 0.43735471367836 - Metric: 0.8662922978401184\n",
      "----- 0.859s -----\n",
      "Epochs 735/1000 - Loss: 0.43741750717163086 - Metric: 0.8658244013786316\n",
      "----- 1.074s -----\n",
      "Epochs 736/1000 - Loss: 0.43977227807044983 - Metric: 0.8656005859375\n",
      "----- 1.109s -----\n",
      "Epochs 737/1000 - Loss: 0.43909287452697754 - Metric: 0.8653564453125\n",
      "----- 1.38s -----\n",
      "Epochs 738/1000 - Loss: 0.43637290596961975 - Metric: 0.8659871220588684\n",
      "----- 1.032s -----\n",
      "Epochs 739/1000 - Loss: 0.4372759759426117 - Metric: 0.86505126953125\n",
      "----- 1.098s -----\n",
      "Epochs 740/1000 - Loss: 0.4409407079219818 - Metric: 0.8655802607536316\n",
      "----- 0.852s -----\n",
      "Epochs 741/1000 - Loss: 0.44164538383483887 - Metric: 0.8642374873161316\n",
      "----- 0.744s -----\n",
      "Epochs 742/1000 - Loss: 0.45217177271842957 - Metric: 0.860595703125\n",
      "----- 0.707s -----\n",
      "Epochs 743/1000 - Loss: 0.45844295620918274 - Metric: 0.8598225712776184\n",
      "----- 0.765s -----\n",
      "Epochs 744/1000 - Loss: 0.4637015163898468 - Metric: 0.8576253056526184\n",
      "----- 0.752s -----\n",
      "Epochs 745/1000 - Loss: 0.45571771264076233 - Metric: 0.8604939579963684\n",
      "----- 0.777s -----\n",
      "Epochs 746/1000 - Loss: 0.44146624207496643 - Metric: 0.86474609375\n",
      "----- 0.826s -----\n",
      "Epochs 747/1000 - Loss: 0.4422483444213867 - Metric: 0.8640950322151184\n",
      "----- 0.869s -----\n",
      "Epochs 748/1000 - Loss: 0.44022056460380554 - Metric: 0.8656005859375\n",
      "----- 0.755s -----\n",
      "Epochs 749/1000 - Loss: 0.43764543533325195 - Metric: 0.8658244013786316\n",
      "----- 0.747s -----\n",
      "Epochs 750/1000 - Loss: 0.4361549913883209 - Metric: 0.8664143681526184\n",
      "----- 0.776s -----\n",
      "Epochs 751/1000 - Loss: 0.43784213066101074 - Metric: 0.8652547001838684\n",
      "----- 0.799s -----\n",
      "Epochs 752/1000 - Loss: 0.4378916323184967 - Metric: 0.8660685420036316\n",
      "----- 0.79s -----\n",
      "Epochs 753/1000 - Loss: 0.4496046006679535 - Metric: 0.8626301884651184\n",
      "----- 0.761s -----\n",
      "Epochs 754/1000 - Loss: 0.44898614287376404 - Metric: 0.8624267578125\n",
      "----- 0.935s -----\n",
      "Epochs 755/1000 - Loss: 0.45696771144866943 - Metric: 0.8602091670036316\n",
      "----- 0.838s -----\n",
      "Epochs 756/1000 - Loss: 0.45813289284706116 - Metric: 0.8598836064338684\n",
      "----- 0.734s -----\n",
      "Epochs 757/1000 - Loss: 0.4402553141117096 - Metric: 0.86480712890625\n",
      "----- 0.791s -----\n",
      "Epochs 758/1000 - Loss: 0.43503689765930176 - Metric: 0.8662109375\n",
      "----- 0.826s -----\n",
      "Epochs 759/1000 - Loss: 0.439026802778244 - Metric: 0.8649088740348816\n",
      "----- 0.893s -----\n",
      "Epochs 760/1000 - Loss: 0.43936023116111755 - Metric: 0.8653157353401184\n",
      "----- 0.832s -----\n",
      "Epochs 761/1000 - Loss: 0.4390324056148529 - Metric: 0.8650105595588684\n",
      "----- 0.803s -----\n",
      "Epochs 762/1000 - Loss: 0.4348631799221039 - Metric: 0.86688232421875\n",
      "----- 0.929s -----\n",
      "Epochs 763/1000 - Loss: 0.437595009803772 - Metric: 0.8658854365348816\n",
      "----- 0.787s -----\n",
      "Epochs 764/1000 - Loss: 0.4465463161468506 - Metric: 0.8631388545036316\n",
      "----- 0.718s -----\n",
      "Epochs 765/1000 - Loss: 0.4503195285797119 - Metric: 0.86187744140625\n",
      "----- 0.814s -----\n",
      "Epochs 766/1000 - Loss: 0.4586356580257416 - Metric: 0.8595377802848816\n",
      "----- 0.905s -----\n",
      "Epochs 767/1000 - Loss: 0.4439394176006317 - Metric: 0.8639119267463684\n",
      "----- 0.855s -----\n",
      "Epochs 768/1000 - Loss: 0.4360162019729614 - Metric: 0.8658650517463684\n",
      "----- 0.766s -----\n",
      "Epochs 769/1000 - Loss: 0.4348335564136505 - Metric: 0.866455078125\n",
      "----- 0.784s -----\n",
      "Epochs 770/1000 - Loss: 0.4327222406864166 - Metric: 0.8673095703125\n",
      "----- 0.886s -----\n",
      "Epochs 771/1000 - Loss: 0.43565869331359863 - Metric: 0.86627197265625\n",
      "----- 0.781s -----\n",
      "Epochs 772/1000 - Loss: 0.43340790271759033 - Metric: 0.8671671748161316\n",
      "----- 0.749s -----\n",
      "Epochs 773/1000 - Loss: 0.43335285782814026 - Metric: 0.8666788935661316\n",
      "----- 0.719s -----\n",
      "Epochs 774/1000 - Loss: 0.43625354766845703 - Metric: 0.8662312626838684\n",
      "----- 0.715s -----\n",
      "Epochs 775/1000 - Loss: 0.43868932127952576 - Metric: 0.8658244013786316\n",
      "----- 0.716s -----\n",
      "Epochs 776/1000 - Loss: 0.4408479928970337 - Metric: 0.86431884765625\n",
      "----- 0.719s -----\n",
      "Epochs 777/1000 - Loss: 0.4440823793411255 - Metric: 0.8637898564338684\n",
      "----- 0.745s -----\n",
      "Epochs 778/1000 - Loss: 0.43936362862586975 - Metric: 0.8652547001838684\n",
      "----- 0.976s -----\n",
      "Epochs 779/1000 - Loss: 0.44449806213378906 - Metric: 0.86456298828125\n",
      "----- 0.811s -----\n",
      "Epochs 780/1000 - Loss: 0.44323381781578064 - Metric: 0.8641154170036316\n",
      "----- 0.75s -----\n",
      "Epochs 781/1000 - Loss: 0.43904218077659607 - Metric: 0.8653767704963684\n",
      "----- 0.786s -----\n",
      "Epochs 782/1000 - Loss: 0.439157098531723 - Metric: 0.8656819462776184\n",
      "----- 0.776s -----\n",
      "Epochs 783/1000 - Loss: 0.4357518255710602 - Metric: 0.8664143681526184\n",
      "----- 0.752s -----\n",
      "Epochs 784/1000 - Loss: 0.4337475597858429 - Metric: 0.8671061396598816\n",
      "----- 0.715s -----\n",
      "Epochs 785/1000 - Loss: 0.438868910074234 - Metric: 0.8659871220588684\n",
      "----- 0.705s -----\n",
      "Epochs 786/1000 - Loss: 0.43247494101524353 - Metric: 0.8666585087776184\n",
      "----- 0.845s -----\n",
      "Epochs 787/1000 - Loss: 0.4328196048736572 - Metric: 0.86663818359375\n",
      "----- 0.719s -----\n",
      "Epochs 788/1000 - Loss: 0.43352237343788147 - Metric: 0.86773681640625\n",
      "----- 0.728s -----\n",
      "Epochs 789/1000 - Loss: 0.4335966110229492 - Metric: 0.8669230341911316\n",
      "----- 0.885s -----\n",
      "Epochs 790/1000 - Loss: 0.43595412373542786 - Metric: 0.8662312626838684\n",
      "----- 0.888s -----\n",
      "Epochs 791/1000 - Loss: 0.4324090778827667 - Metric: 0.867431640625\n",
      "----- 0.87s -----\n",
      "Epochs 792/1000 - Loss: 0.4369679391384125 - Metric: 0.8653564453125\n",
      "----- 0.908s -----\n",
      "Epochs 793/1000 - Loss: 0.4363361895084381 - Metric: 0.8658447265625\n",
      "----- 0.882s -----\n",
      "Epochs 794/1000 - Loss: 0.43596330285072327 - Metric: 0.8660888671875\n",
      "----- 0.875s -----\n",
      "Epochs 795/1000 - Loss: 0.43795427680015564 - Metric: 0.8658854365348816\n",
      "----- 0.772s -----\n",
      "Epochs 796/1000 - Loss: 0.43422794342041016 - Metric: 0.8669636845588684\n",
      "----- 0.74s -----\n",
      "Epochs 797/1000 - Loss: 0.43849289417266846 - Metric: 0.8658447265625\n",
      "----- 0.759s -----\n",
      "Epochs 798/1000 - Loss: 0.4355132579803467 - Metric: 0.8662109375\n",
      "----- 0.746s -----\n",
      "Epochs 799/1000 - Loss: 0.43398770689964294 - Metric: 0.8667399287223816\n",
      "----- 0.746s -----\n",
      "Epochs 800/1000 - Loss: 0.4369942247867584 - Metric: 0.8658244013786316\n",
      "----- 0.812s -----\n",
      "Epochs 801/1000 - Loss: 0.4417957365512848 - Metric: 0.8639323115348816\n",
      "----- 0.711s -----\n",
      "Epochs 802/1000 - Loss: 0.43685927987098694 - Metric: 0.8657633662223816\n",
      "----- 0.711s -----\n",
      "Epochs 803/1000 - Loss: 0.45095428824424744 - Metric: 0.8611653447151184\n",
      "----- 0.716s -----\n",
      "Epochs 804/1000 - Loss: 0.4426249563694 - Metric: 0.8646036982536316\n",
      "----- 0.735s -----\n",
      "Epochs 805/1000 - Loss: 0.45908477902412415 - Metric: 0.8587646484375\n",
      "----- 0.71s -----\n",
      "Epochs 806/1000 - Loss: 0.45366644859313965 - Metric: 0.8611857295036316\n",
      "----- 0.712s -----\n",
      "Epochs 807/1000 - Loss: 0.4575100839138031 - Metric: 0.8596598505973816\n",
      "----- 0.723s -----\n",
      "Epochs 808/1000 - Loss: 0.4556882381439209 - Metric: 0.8607177734375\n",
      "----- 0.938s -----\n",
      "Epochs 809/1000 - Loss: 0.45105159282684326 - Metric: 0.86212158203125\n",
      "----- 0.759s -----\n",
      "Epochs 810/1000 - Loss: 0.44647684693336487 - Metric: 0.8634440302848816\n",
      "----- 0.792s -----\n",
      "Epochs 811/1000 - Loss: 0.43655040860176086 - Metric: 0.8662312626838684\n",
      "----- 0.799s -----\n",
      "Epochs 812/1000 - Loss: 0.43402209877967834 - Metric: 0.86639404296875\n",
      "----- 0.798s -----\n",
      "Epochs 813/1000 - Loss: 0.43654438853263855 - Metric: 0.8654988408088684\n",
      "----- 0.81s -----\n",
      "Epochs 814/1000 - Loss: 0.4377833604812622 - Metric: 0.8651123046875\n",
      "----- 0.807s -----\n",
      "Epochs 815/1000 - Loss: 0.4409249722957611 - Metric: 0.8647664189338684\n",
      "----- 0.764s -----\n",
      "Epochs 816/1000 - Loss: 0.440352201461792 - Metric: 0.8647053837776184\n",
      "----- 0.837s -----\n",
      "Epochs 817/1000 - Loss: 0.4414786398410797 - Metric: 0.8638508915901184\n",
      "----- 0.71s -----\n",
      "Epochs 818/1000 - Loss: 0.4408620595932007 - Metric: 0.8648681640625\n",
      "----- 0.717s -----\n",
      "Epochs 819/1000 - Loss: 0.44323182106018066 - Metric: 0.8638508915901184\n",
      "----- 0.712s -----\n",
      "Epochs 820/1000 - Loss: 0.44924283027648926 - Metric: 0.86175537109375\n",
      "----- 0.71s -----\n",
      "Epochs 821/1000 - Loss: 0.4455648958683014 - Metric: 0.8633626103401184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.725s -----\n",
      "Epochs 822/1000 - Loss: 0.4422447979450226 - Metric: 0.8635457158088684\n",
      "----- 0.706s -----\n",
      "Epochs 823/1000 - Loss: 0.4369446337223053 - Metric: 0.8656005859375\n",
      "----- 0.799s -----\n",
      "Epochs 824/1000 - Loss: 0.43362656235694885 - Metric: 0.8665364384651184\n",
      "----- 0.737s -----\n",
      "Epochs 825/1000 - Loss: 0.4316519796848297 - Metric: 0.8677978515625\n",
      "----- 0.74s -----\n",
      "Epochs 826/1000 - Loss: 0.43371906876564026 - Metric: 0.8674113154411316\n",
      "----- 0.728s -----\n",
      "Epochs 827/1000 - Loss: 0.4309968948364258 - Metric: 0.8676554560661316\n",
      "----- 0.728s -----\n",
      "Epochs 828/1000 - Loss: 0.43065890669822693 - Metric: 0.8678995966911316\n",
      "----- 0.714s -----\n",
      "Epochs 829/1000 - Loss: 0.42904844880104065 - Metric: 0.8682861328125\n",
      "----- 0.704s -----\n",
      "Epochs 830/1000 - Loss: 0.43002942204475403 - Metric: 0.8679606318473816\n",
      "----- 0.704s -----\n",
      "Epochs 831/1000 - Loss: 0.43142732977867126 - Metric: 0.86724853515625\n",
      "----- 0.831s -----\n",
      "Epochs 832/1000 - Loss: 0.42833948135375977 - Metric: 0.8685302734375\n",
      "----- 0.746s -----\n",
      "Epochs 833/1000 - Loss: 0.42970800399780273 - Metric: 0.8683878779411316\n",
      "----- 0.709s -----\n",
      "Epochs 834/1000 - Loss: 0.4329198896884918 - Metric: 0.8673095703125\n",
      "----- 0.717s -----\n",
      "Epochs 835/1000 - Loss: 0.43305471539497375 - Metric: 0.86651611328125\n",
      "----- 0.747s -----\n",
      "Epochs 836/1000 - Loss: 0.4316948354244232 - Metric: 0.8674519658088684\n",
      "----- 0.735s -----\n",
      "Epochs 837/1000 - Loss: 0.4295627176761627 - Metric: 0.8686726689338684\n",
      "----- 0.766s -----\n",
      "Epochs 838/1000 - Loss: 0.43794670701026917 - Metric: 0.86578369140625\n",
      "----- 0.746s -----\n",
      "Epochs 839/1000 - Loss: 0.438402384519577 - Metric: 0.8651530146598816\n",
      "----- 0.734s -----\n",
      "Epochs 840/1000 - Loss: 0.43943706154823303 - Metric: 0.8646240234375\n",
      "----- 0.737s -----\n",
      "Epochs 841/1000 - Loss: 0.4418179988861084 - Metric: 0.8643391728401184\n",
      "----- 0.728s -----\n",
      "Epochs 842/1000 - Loss: 0.4431208074092865 - Metric: 0.8638916015625\n",
      "----- 0.758s -----\n",
      "Epochs 843/1000 - Loss: 0.44894108176231384 - Metric: 0.86260986328125\n",
      "----- 0.741s -----\n",
      "Epochs 844/1000 - Loss: 0.4530412256717682 - Metric: 0.8612263798713684\n",
      "----- 0.725s -----\n",
      "Epochs 845/1000 - Loss: 0.4471520185470581 - Metric: 0.86328125\n",
      "----- 0.749s -----\n",
      "Epochs 846/1000 - Loss: 0.45136937499046326 - Metric: 0.8624064326286316\n",
      "----- 0.717s -----\n",
      "Epochs 847/1000 - Loss: 0.450715035200119 - Metric: 0.8617756962776184\n",
      "----- 0.726s -----\n",
      "Epochs 848/1000 - Loss: 0.44632086157798767 - Metric: 0.8629150390625\n",
      "----- 0.729s -----\n",
      "Epochs 849/1000 - Loss: 0.4460628032684326 - Metric: 0.8631184697151184\n",
      "----- 0.742s -----\n",
      "Epochs 850/1000 - Loss: 0.4398967921733856 - Metric: 0.8649495244026184\n",
      "----- 0.787s -----\n",
      "Epochs 851/1000 - Loss: 0.4347398281097412 - Metric: 0.8658244013786316\n",
      "----- 0.75s -----\n",
      "Epochs 852/1000 - Loss: 0.43567919731140137 - Metric: 0.8660888671875\n",
      "----- 0.746s -----\n",
      "Epochs 853/1000 - Loss: 0.44314447045326233 - Metric: 0.8631184697151184\n",
      "----- 0.731s -----\n",
      "Epochs 854/1000 - Loss: 0.4428233802318573 - Metric: 0.86383056640625\n",
      "----- 0.737s -----\n",
      "Epochs 855/1000 - Loss: 0.4327642619609833 - Metric: 0.8666788935661316\n",
      "----- 0.727s -----\n",
      "Epochs 856/1000 - Loss: 0.4323398768901825 - Metric: 0.8668009638786316\n",
      "----- 0.719s -----\n",
      "Epochs 857/1000 - Loss: 0.4302043616771698 - Metric: 0.8682047724723816\n",
      "----- 0.723s -----\n",
      "Epochs 858/1000 - Loss: 0.4300152063369751 - Metric: 0.8677164912223816\n",
      "----- 0.735s -----\n",
      "Epochs 859/1000 - Loss: 0.4306836426258087 - Metric: 0.86773681640625\n",
      "----- 0.722s -----\n",
      "Epochs 860/1000 - Loss: 0.43318191170692444 - Metric: 0.8673298954963684\n",
      "----- 0.719s -----\n",
      "Epochs 861/1000 - Loss: 0.43044379353523254 - Metric: 0.8677978515625\n",
      "----- 0.78s -----\n",
      "Epochs 862/1000 - Loss: 0.43430936336517334 - Metric: 0.86614990234375\n",
      "----- 0.793s -----\n",
      "Epochs 863/1000 - Loss: 0.4340939521789551 - Metric: 0.86651611328125\n",
      "----- 0.717s -----\n",
      "Epochs 864/1000 - Loss: 0.4346407353878021 - Metric: 0.86688232421875\n",
      "----- 0.731s -----\n",
      "Epochs 865/1000 - Loss: 0.4395182430744171 - Metric: 0.8653361201286316\n",
      "----- 0.798s -----\n",
      "Epochs 866/1000 - Loss: 0.43711137771606445 - Metric: 0.8655192255973816\n",
      "----- 0.725s -----\n",
      "Epochs 867/1000 - Loss: 0.4383804500102997 - Metric: 0.8660075068473816\n",
      "----- 0.724s -----\n",
      "Epochs 868/1000 - Loss: 0.44131144881248474 - Metric: 0.8642781376838684\n",
      "----- 0.71s -----\n",
      "Epochs 869/1000 - Loss: 0.44871941208839417 - Metric: 0.8619791865348816\n",
      "----- 0.724s -----\n",
      "Epochs 870/1000 - Loss: 0.434009313583374 - Metric: 0.86688232421875\n",
      "----- 0.71s -----\n",
      "Epochs 871/1000 - Loss: 0.46814218163490295 - Metric: 0.85711669921875\n",
      "----- 0.721s -----\n",
      "Epochs 872/1000 - Loss: 0.43972882628440857 - Metric: 0.8654378056526184\n",
      "----- 0.721s -----\n",
      "Epochs 873/1000 - Loss: 0.4455443322658539 - Metric: 0.8629353642463684\n",
      "----- 0.724s -----\n",
      "Epochs 874/1000 - Loss: 0.4426826238632202 - Metric: 0.86407470703125\n",
      "----- 0.728s -----\n",
      "Epochs 875/1000 - Loss: 0.4418443441390991 - Metric: 0.8636474609375\n",
      "----- 0.734s -----\n",
      "Epochs 876/1000 - Loss: 0.4437141418457031 - Metric: 0.8630778193473816\n",
      "----- 0.747s -----\n",
      "Epochs 877/1000 - Loss: 0.43822208046913147 - Metric: 0.86572265625\n",
      "----- 0.76s -----\n",
      "Epochs 878/1000 - Loss: 0.4368300437927246 - Metric: 0.8656819462776184\n",
      "----- 0.737s -----\n",
      "Epochs 879/1000 - Loss: 0.43725427985191345 - Metric: 0.8657429814338684\n",
      "----- 0.738s -----\n",
      "Epochs 880/1000 - Loss: 0.43420013785362244 - Metric: 0.8669026494026184\n",
      "----- 0.724s -----\n",
      "Epochs 881/1000 - Loss: 0.4318677484989166 - Metric: 0.8674113154411316\n",
      "----- 0.753s -----\n",
      "Epochs 882/1000 - Loss: 0.4310886859893799 - Metric: 0.8675740361213684\n",
      "----- 0.708s -----\n",
      "Epochs 883/1000 - Loss: 0.43197712302207947 - Metric: 0.8675130009651184\n",
      "----- 0.724s -----\n",
      "Epochs 884/1000 - Loss: 0.4332204759120941 - Metric: 0.8664347529411316\n",
      "----- 0.732s -----\n",
      "Epochs 885/1000 - Loss: 0.4356953203678131 - Metric: 0.8660685420036316\n",
      "----- 0.724s -----\n",
      "Epochs 886/1000 - Loss: 0.4330616891384125 - Metric: 0.8673909306526184\n",
      "----- 0.721s -----\n",
      "Epochs 887/1000 - Loss: 0.43412044644355774 - Metric: 0.8666585087776184\n",
      "----- 0.726s -----\n",
      "Epochs 888/1000 - Loss: 0.43568921089172363 - Metric: 0.8656819462776184\n",
      "----- 0.718s -----\n",
      "Epochs 889/1000 - Loss: 0.4346925914287567 - Metric: 0.8668009638786316\n",
      "----- 0.783s -----\n",
      "Epochs 890/1000 - Loss: 0.43461477756500244 - Metric: 0.8671061396598816\n",
      "----- 0.749s -----\n",
      "Epochs 891/1000 - Loss: 0.4398723542690277 - Metric: 0.8646443486213684\n",
      "----- 0.724s -----\n",
      "Epochs 892/1000 - Loss: 0.4437601864337921 - Metric: 0.8637492060661316\n",
      "----- 0.824s -----\n",
      "Epochs 893/1000 - Loss: 0.4455684721469879 - Metric: 0.8629557490348816\n",
      "----- 1.056s -----\n",
      "Epochs 894/1000 - Loss: 0.4545787572860718 - Metric: 0.86126708984375\n",
      "----- 0.82s -----\n",
      "Epochs 895/1000 - Loss: 0.4443265497684479 - Metric: 0.8634236454963684\n",
      "----- 0.842s -----\n",
      "Epochs 896/1000 - Loss: 0.44145384430885315 - Metric: 0.8643798828125\n",
      "----- 0.732s -----\n",
      "Epochs 897/1000 - Loss: 0.4414915144443512 - Metric: 0.8636067509651184\n",
      "----- 0.729s -----\n",
      "Epochs 898/1000 - Loss: 0.4416160583496094 - Metric: 0.8647868037223816\n",
      "----- 0.721s -----\n",
      "Epochs 899/1000 - Loss: 0.43971097469329834 - Metric: 0.865234375\n",
      "----- 0.733s -----\n",
      "Epochs 900/1000 - Loss: 0.43256720900535583 - Metric: 0.86749267578125\n",
      "----- 0.745s -----\n",
      "Epochs 901/1000 - Loss: 0.4305900037288666 - Metric: 0.8672282099723816\n",
      "----- 0.724s -----\n",
      "Epochs 902/1000 - Loss: 0.42791983485221863 - Metric: 0.86846923828125\n",
      "----- 0.724s -----\n",
      "Epochs 903/1000 - Loss: 0.42905116081237793 - Metric: 0.8686116337776184\n",
      "----- 0.754s -----\n",
      "Epochs 904/1000 - Loss: 0.42795905470848083 - Metric: 0.8683674931526184\n",
      "----- 0.719s -----\n",
      "Epochs 905/1000 - Loss: 0.4294711649417877 - Metric: 0.8685302734375\n",
      "----- 0.721s -----\n",
      "Epochs 906/1000 - Loss: 0.4315938651561737 - Metric: 0.86798095703125\n",
      "----- 0.737s -----\n",
      "Epochs 907/1000 - Loss: 0.4318457841873169 - Metric: 0.86761474609375\n",
      "----- 0.734s -----\n",
      "Epochs 908/1000 - Loss: 0.4307209551334381 - Metric: 0.8676350712776184\n",
      "----- 0.805s -----\n",
      "Epochs 909/1000 - Loss: 0.4339383542537689 - Metric: 0.86627197265625\n",
      "----- 0.762s -----\n",
      "Epochs 910/1000 - Loss: 0.4309215545654297 - Metric: 0.8675130009651184\n",
      "----- 0.734s -----\n",
      "Epochs 911/1000 - Loss: 0.4344886541366577 - Metric: 0.8663533329963684\n",
      "----- 0.769s -----\n",
      "Epochs 912/1000 - Loss: 0.4409604072570801 - Metric: 0.8649699091911316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.724s -----\n",
      "Epochs 913/1000 - Loss: 0.43634772300720215 - Metric: 0.8662109375\n",
      "----- 0.722s -----\n",
      "Epochs 914/1000 - Loss: 0.44896364212036133 - Metric: 0.86212158203125\n",
      "----- 0.711s -----\n",
      "Epochs 915/1000 - Loss: 0.4576941728591919 - Metric: 0.8594767451286316\n",
      "----- 0.743s -----\n",
      "Epochs 916/1000 - Loss: 0.45166802406311035 - Metric: 0.8616536259651184\n",
      "----- 0.768s -----\n",
      "Epochs 917/1000 - Loss: 0.45692959427833557 - Metric: 0.8594767451286316\n",
      "----- 0.756s -----\n",
      "Epochs 918/1000 - Loss: 0.45469486713409424 - Metric: 0.8599039912223816\n",
      "----- 0.725s -----\n",
      "Epochs 919/1000 - Loss: 0.43829312920570374 - Metric: 0.8662516474723816\n",
      "----- 0.734s -----\n",
      "Epochs 920/1000 - Loss: 0.4384554922580719 - Metric: 0.8653767704963684\n",
      "----- 0.728s -----\n",
      "Epochs 921/1000 - Loss: 0.4307072162628174 - Metric: 0.867919921875\n",
      "----- 0.72s -----\n",
      "Epochs 922/1000 - Loss: 0.4393278658390045 - Metric: 0.8641154170036316\n",
      "----- 0.721s -----\n",
      "Epochs 923/1000 - Loss: 0.4431510269641876 - Metric: 0.8636271357536316\n",
      "----- 0.733s -----\n",
      "Epochs 924/1000 - Loss: 0.4351353943347931 - Metric: 0.8660685420036316\n",
      "----- 0.761s -----\n",
      "Epochs 925/1000 - Loss: 0.4322628676891327 - Metric: 0.8673502802848816\n",
      "----- 0.727s -----\n",
      "Epochs 926/1000 - Loss: 0.4341198205947876 - Metric: 0.8669636845588684\n",
      "----- 0.763s -----\n",
      "Epochs 927/1000 - Loss: 0.43944141268730164 - Metric: 0.8651936650276184\n",
      "----- 0.822s -----\n",
      "Epochs 928/1000 - Loss: 0.4440148174762726 - Metric: 0.864013671875\n",
      "----- 2.296s -----\n",
      "Epochs 929/1000 - Loss: 0.44572004675865173 - Metric: 0.8641764521598816\n",
      "----- 1.717s -----\n",
      "Epochs 930/1000 - Loss: 0.4445527493953705 - Metric: 0.86431884765625\n",
      "----- 1.681s -----\n",
      "Epochs 931/1000 - Loss: 0.4386833608150482 - Metric: 0.8648884892463684\n",
      "----- 1.788s -----\n",
      "Epochs 932/1000 - Loss: 0.431927353143692 - Metric: 0.86773681640625\n",
      "----- 1.832s -----\n",
      "Epochs 933/1000 - Loss: 0.42723119258880615 - Metric: 0.8695271611213684\n",
      "----- 2.071s -----\n",
      "Epochs 934/1000 - Loss: 0.42725446820259094 - Metric: 0.8695271611213684\n",
      "----- 1.931s -----\n",
      "Epochs 935/1000 - Loss: 0.4273012578487396 - Metric: 0.8692830204963684\n",
      "----- 1.892s -----\n",
      "Epochs 936/1000 - Loss: 0.42984604835510254 - Metric: 0.8684895634651184\n",
      "----- 1.915s -----\n",
      "Epochs 937/1000 - Loss: 0.4281791150569916 - Metric: 0.8678181767463684\n",
      "----- 1.807s -----\n",
      "Epochs 938/1000 - Loss: 0.4288421869277954 - Metric: 0.86785888671875\n",
      "----- 1.711s -----\n",
      "Epochs 939/1000 - Loss: 0.4298090934753418 - Metric: 0.8681233525276184\n",
      "----- 1.911s -----\n",
      "Epochs 940/1000 - Loss: 0.43290814757347107 - Metric: 0.8674519658088684\n",
      "----- 1.561s -----\n",
      "Epochs 941/1000 - Loss: 0.43364787101745605 - Metric: 0.8669840693473816\n",
      "----- 1.636s -----\n",
      "Epochs 942/1000 - Loss: 0.43025830388069153 - Metric: 0.8672688603401184\n",
      "----- 1.773s -----\n",
      "Epochs 943/1000 - Loss: 0.4373249113559723 - Metric: 0.8656819462776184\n",
      "----- 1.828s -----\n",
      "Epochs 944/1000 - Loss: 0.46026015281677246 - Metric: 0.8599039912223816\n",
      "----- 1.712s -----\n",
      "Epochs 945/1000 - Loss: 0.454632431268692 - Metric: 0.8601277470588684\n",
      "----- 1.63s -----\n",
      "Epochs 946/1000 - Loss: 0.45892825722694397 - Metric: 0.85955810546875\n",
      "----- 1.3s -----\n",
      "Epochs 947/1000 - Loss: 0.44445309042930603 - Metric: 0.8635457158088684\n",
      "----- 0.758s -----\n",
      "Epochs 948/1000 - Loss: 0.43326255679130554 - Metric: 0.8660685420036316\n",
      "----- 0.745s -----\n",
      "Epochs 949/1000 - Loss: 0.4315483570098877 - Metric: 0.86761474609375\n",
      "----- 0.734s -----\n",
      "Epochs 950/1000 - Loss: 0.42800116539001465 - Metric: 0.8695271611213684\n",
      "----- 0.732s -----\n",
      "Epochs 951/1000 - Loss: 0.4280525743961334 - Metric: 0.8681233525276184\n",
      "----- 0.72s -----\n",
      "Epochs 952/1000 - Loss: 0.42820873856544495 - Metric: 0.86895751953125\n",
      "----- 0.717s -----\n",
      "Epochs 953/1000 - Loss: 0.42920932173728943 - Metric: 0.8683268427848816\n",
      "----- 0.735s -----\n",
      "Epochs 954/1000 - Loss: 0.43308964371681213 - Metric: 0.8670451045036316\n",
      "----- 0.741s -----\n",
      "Epochs 955/1000 - Loss: 0.4297940731048584 - Metric: 0.8685505986213684\n",
      "----- 0.735s -----\n",
      "Epochs 956/1000 - Loss: 0.4357433617115021 - Metric: 0.8658854365348816\n",
      "----- 0.716s -----\n",
      "Epochs 957/1000 - Loss: 0.43885648250579834 - Metric: 0.8657633662223816\n",
      "----- 0.719s -----\n",
      "Epochs 958/1000 - Loss: 0.44339290261268616 - Metric: 0.8640543818473816\n",
      "----- 0.713s -----\n",
      "Epochs 959/1000 - Loss: 0.44675397872924805 - Metric: 0.86273193359375\n",
      "----- 0.728s -----\n",
      "Epochs 960/1000 - Loss: 0.44121575355529785 - Metric: 0.8642985224723816\n",
      "----- 0.727s -----\n",
      "Epochs 961/1000 - Loss: 0.44736447930336 - Metric: 0.8625691533088684\n",
      "----- 0.734s -----\n",
      "Epochs 962/1000 - Loss: 0.4440433979034424 - Metric: 0.8633219599723816\n",
      "----- 0.728s -----\n",
      "Epochs 963/1000 - Loss: 0.4439767301082611 - Metric: 0.86395263671875\n",
      "----- 0.728s -----\n",
      "Epochs 964/1000 - Loss: 0.43508172035217285 - Metric: 0.8661702275276184\n",
      "----- 0.773s -----\n",
      "Epochs 965/1000 - Loss: 0.44275984168052673 - Metric: 0.8638916015625\n",
      "----- 0.731s -----\n",
      "Epochs 966/1000 - Loss: 0.43219098448753357 - Metric: 0.8665568232536316\n",
      "----- 0.732s -----\n",
      "Epochs 967/1000 - Loss: 0.42901793122291565 - Metric: 0.8678792119026184\n",
      "----- 0.757s -----\n",
      "Epochs 968/1000 - Loss: 0.4296635091304779 - Metric: 0.8676961064338684\n",
      "----- 0.722s -----\n",
      "Epochs 969/1000 - Loss: 0.43221330642700195 - Metric: 0.8672078251838684\n",
      "----- 0.726s -----\n",
      "Epochs 970/1000 - Loss: 0.43279024958610535 - Metric: 0.8671467900276184\n",
      "----- 0.725s -----\n",
      "Epochs 971/1000 - Loss: 0.4300614297389984 - Metric: 0.8678385615348816\n",
      "----- 0.774s -----\n",
      "Epochs 972/1000 - Loss: 0.43098488450050354 - Metric: 0.8673298954963684\n",
      "----- 0.736s -----\n",
      "Epochs 973/1000 - Loss: 0.4355517327785492 - Metric: 0.8662922978401184\n",
      "----- 0.721s -----\n",
      "Epochs 974/1000 - Loss: 0.4374478757381439 - Metric: 0.8655192255973816\n",
      "----- 0.733s -----\n",
      "Epochs 975/1000 - Loss: 0.4446774423122406 - Metric: 0.86370849609375\n",
      "----- 0.722s -----\n",
      "Epochs 976/1000 - Loss: 0.4509310722351074 - Metric: 0.86273193359375\n",
      "----- 0.719s -----\n",
      "Epochs 977/1000 - Loss: 0.4403263032436371 - Metric: 0.8650715947151184\n",
      "----- 0.727s -----\n",
      "Epochs 978/1000 - Loss: 0.44101276993751526 - Metric: 0.8647664189338684\n",
      "----- 0.731s -----\n",
      "Epochs 979/1000 - Loss: 0.43185141682624817 - Metric: 0.8673095703125\n",
      "----- 0.746s -----\n",
      "Epochs 980/1000 - Loss: 0.4340619742870331 - Metric: 0.8672078251838684\n",
      "----- 0.724s -----\n",
      "Epochs 981/1000 - Loss: 0.4298979341983795 - Metric: 0.8681437373161316\n",
      "----- 0.725s -----\n",
      "Epochs 982/1000 - Loss: 0.43268153071403503 - Metric: 0.86798095703125\n",
      "----- 0.725s -----\n",
      "Epochs 983/1000 - Loss: 0.4292238652706146 - Metric: 0.868408203125\n",
      "----- 0.722s -----\n",
      "Epochs 984/1000 - Loss: 0.43344393372535706 - Metric: 0.8665364384651184\n",
      "----- 1.01s -----\n",
      "Epochs 985/1000 - Loss: 0.4308265149593353 - Metric: 0.86810302734375\n",
      "----- 0.867s -----\n",
      "Epochs 986/1000 - Loss: 0.42764386534690857 - Metric: 0.8690185546875\n",
      "----- 0.74s -----\n",
      "Epochs 987/1000 - Loss: 0.42640742659568787 - Metric: 0.86920166015625\n",
      "----- 0.724s -----\n",
      "Epochs 988/1000 - Loss: 0.42904701828956604 - Metric: 0.8683064579963684\n",
      "----- 0.731s -----\n",
      "Epochs 989/1000 - Loss: 0.4292510449886322 - Metric: 0.8679606318473816\n",
      "----- 0.734s -----\n",
      "Epochs 990/1000 - Loss: 0.4309174716472626 - Metric: 0.8684285283088684\n",
      "----- 0.719s -----\n",
      "Epochs 991/1000 - Loss: 0.43110501766204834 - Metric: 0.8675740361213684\n",
      "----- 0.726s -----\n",
      "Epochs 992/1000 - Loss: 0.4357300102710724 - Metric: 0.8661295771598816\n",
      "----- 0.74s -----\n",
      "Epochs 993/1000 - Loss: 0.43868979811668396 - Metric: 0.8655598759651184\n",
      "----- 0.728s -----\n",
      "Epochs 994/1000 - Loss: 0.4492438733577728 - Metric: 0.8624064326286316\n",
      "----- 0.743s -----\n",
      "Epochs 995/1000 - Loss: 0.44605180621147156 - Metric: 0.8628947138786316\n",
      "----- 0.72s -----\n",
      "Epochs 996/1000 - Loss: 0.44308122992515564 - Metric: 0.86328125\n",
      "----- 0.768s -----\n",
      "Epochs 997/1000 - Loss: 0.45035815238952637 - Metric: 0.8616536259651184\n",
      "----- 0.72s -----\n",
      "Epochs 998/1000 - Loss: 0.4460671842098236 - Metric: 0.8624267578125\n",
      "----- 0.721s -----\n",
      "Epochs 999/1000 - Loss: 0.4398571252822876 - Metric: 0.8648681640625\n",
      "----- 0.77s -----\n",
      "Epochs 1000/1000 - Loss: 0.4389174282550812 - Metric: 0.8651530146598816\n",
      "----- 0.747s -----\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Name: serendipaceratops - Predicted Name: salenaosaseratops\n",
      "Original Name: peishansaurus - Predicted Name: panshantaurus\n",
      "Original Name: pneumatoarthrus - Predicted Name: paeuratossasous\n",
      "Original Name: vulcanodon - Predicted Name: veatanoson\n",
      "Original Name: dimodosaurus - Predicted Name: danohosaurus\n",
      "Original Name: coronosaurus - Predicted Name: chlhsosaurus\n",
      "Original Name: shuangbaisaurus - Predicted Name: saaanggisaaurus\n",
      "Original Name: eugongbusaurus - Predicted Name: eoclngsasaurus\n",
      "Original Name: canardia - Predicted Name: chmamoiau\n",
      "Original Name: megalosaurus - Predicted Name: magalosaurus\n",
      "Original Name: kittysaurus - Predicted Name: kuntasaurus\n",
      "Original Name: saichania - Predicted Name: sauchanoa\n",
      "Original Name: arcusaurus - Predicted Name: anchsaurus\n",
      "Original Name: dandakosaurus - Predicted Name: dacdanisaurus\n",
      "Original Name: siamodracon - Predicted Name: sanmisoittp\n",
      "Original Name: leptospondylus - Predicted Name: laiiolaondylus\n",
      "Original Name: cheneosaurus - Predicted Name: chansnnaurus\n",
      "Original Name: opisthocoelicaudia - Predicted Name: oriroooserloauusia\n",
      "Original Name: gongpoquansaurus - Predicted Name: gabgsosuaniaurus\n",
      "Original Name: megadontosaurus - Predicted Name: magalon\n",
      "Original Name: adamantisaurus - Predicted Name: anamantitaurus\n",
      "Original Name: quilmesaurus - Predicted Name: qiiloeraurus\n",
      "Original Name: notohypsilophodon - Predicted Name: netisusaooophoron\n",
      "Original Name: diabloceratops - Predicted Name: danlioreratops\n",
      "Original Name: pyroraptor - Predicted Name: paaosaptor\n",
      "Original Name: loncosaurus - Predicted Name: lanyisaurus\n",
      "Original Name: aragosaurus - Predicted Name: anclosaurus\n",
      "Original Name: mantellodon - Predicted Name: magiarooson\n",
      "Original Name: chuxiongosaurus - Predicted Name: chasisngosaurus\n",
      "Original Name: brasileosaurus - Predicted Name: baactlossaurus\n",
      "Original Name: serikornis - Predicted Name: salekosnit\n",
      "Original Name: zhenyuanlong - Predicted Name: zhusoaanlungo\n",
      "Original Name: shidaisaurus - Predicted Name: saanonnaurus\n",
      "Original Name: mantellisaurus - Predicted Name: magiaroosaurus\n",
      "Original Name: auroraceratops - Predicted Name: anroroseratops\n",
      "Original Name: archaeornis - Predicted Name: anchaeosnit\n",
      "Original Name: yibinosaurus - Predicted Name: yuainosaurus\n",
      "Original Name: zupaysaurus - Predicted Name: zhoacsaurus\n",
      "Original Name: vectensia - Predicted Name: velarniaa\n",
      "Original Name: adeopapposaurus - Predicted Name: analpeltosaurus\n",
      "Original Name: velociraptor - Predicted Name: velocesaptor\n",
      "Original Name: syntarsus - Predicted Name: saltanuis\n",
      "Original Name: pachyrhinosaurus - Predicted Name: parhyloinosaurus\n",
      "Original Name: byronosaurus - Predicted Name: baronosaurus\n",
      "Original Name: avaceratops - Predicted Name: aniseratops\n",
      "Original Name: geminiraptor - Predicted Name: ganonssaptor\n",
      "Original Name: parrosaurus - Predicted Name: paraosaurus\n",
      "Original Name: hierosaurus - Predicted Name: hesposaurus\n",
      "Original Name: protorosaurus - Predicted Name: paotocasaurus\n",
      "Original Name: edmontonia - Predicted Name: eoronthsya\n",
      "Original Name: trimucrodon - Predicted Name: taiaanhosont\n",
      "Original Name: xenoposeidon - Predicted Name: xinocasaison\n",
      "Original Name: gobivenator - Predicted Name: gabisanator\n",
      "Original Name: achelousaurus - Predicted Name: anhilossaurus\n",
      "Original Name: palaeoctonus - Predicted Name: paraeoseesus\n",
      "Original Name: leonerasaurus - Predicted Name: lainsnopaurus\n",
      "Original Name: barilium - Predicted Name: barasoas\n",
      "Original Name: euhelopus - Predicted Name: eoculmshs\n",
      "Original Name: byranjaffia - Predicted Name: baronjitfot\n",
      "Original Name: variraptor - Predicted Name: velinaptor\n",
      "Original Name: acanthopholis - Predicted Name: anhnahophosoaa\n",
      "Original Name: graciliraptor - Predicted Name: gaacolosaptor\n",
      "Original Name: velocipes - Predicted Name: velocesas\n",
      "Original Name: chialingosaurus - Predicted Name: chansiag\n",
      "Original Name: dysganus - Predicted Name: dasaanus\n",
      "Original Name: rhabdodon - Predicted Name: raabiosin\n",
      "Original Name: spinosaurus - Predicted Name: sainosaurus\n",
      "Original Name: muyelensaurus - Predicted Name: marulongaurus\n",
      "Original Name: asiatosaurus - Predicted Name: antlcasaurus\n",
      "Original Name: ouranosaurus - Predicted Name: orrsnosaurus\n",
      "Original Name: gojirasaurus - Predicted Name: gabisapaurus\n",
      "Original Name: animantarx - Predicted Name: angsanharu\n",
      "Original Name: delapparentia - Predicted Name: dalanpansssos\n",
      "Original Name: olorotitan - Predicted Name: orosositan\n",
      "Original Name: lusotitan - Predicted Name: lativitan\n",
      "Original Name: abydosaurus - Predicted Name: anraodaurus\n",
      "Original Name: malawisaurus - Predicted Name: magarasaurus\n",
      "Original Name: morelladon - Predicted Name: manillason\n",
      "Original Name: breviceratops - Predicted Name: baaciceratops\n",
      "Original Name: nteregosaurus - Predicted Name: nearovosaurus\n",
      "Original Name: proceratosaurus - Predicted Name: paoterapopaurus\n",
      "Original Name: cerasinops - Predicted Name: chtamanoss\n",
      "Original Name: stenotholus - Predicted Name: saerohyosus\n",
      "Original Name: dromaeosauroides - Predicted Name: daacatssaurusles\n",
      "Original Name: ankistrodon - Predicted Name: angyloooson\n",
      "Original Name: hungarosaurus - Predicted Name: heagonasaurus\n",
      "Original Name: losillasaurus - Predicted Name: laninlasaurus\n",
      "Original Name: gavinosaurus - Predicted Name: galinosaurus\n",
      "Original Name: mandschurosaurus - Predicted Name: magioohisosaurus\n",
      "Original Name: borealosaurus - Predicted Name: bareorisaurus\n",
      "Original Name: struthiomimus - Predicted Name: saeuthaosamas\n",
      "Original Name: erlikosaurus - Predicted Name: eocikosaurus\n",
      "Original Name: lophorhothon - Predicted Name: lantosoinhosg\n",
      "Original Name: wyomingraptor - Predicted Name: wanmangoaptor\n",
      "Original Name: elrhazosaurus - Predicted Name: eoaiaconaurus\n",
      "Original Name: teleocrater - Predicted Name: tanacteitoui\n",
      "Original Name: shunosaurus - Predicted Name: saaaasaurus\n",
      "Original Name: soriatitan - Predicted Name: sanintitan\n",
      "Original Name: basutodon - Predicted Name: barhtopon\n",
      "Original Name: rahiolisaurus - Predicted Name: rahhteisaurus\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    name = ''\n",
    "    for idx in np.argmax(X_train[i,:,:], axis=1):\n",
    "        name = name + idx_to_char[idx]\n",
    "        if idx==0:\n",
    "            break\n",
    "    name_prediction = name[0]\n",
    "    for idx in np.argmax(model.predict(X_train)[i,:,:], axis=1):\n",
    "        name_prediction = name_prediction + idx_to_char[idx]\n",
    "        if idx==0:\n",
    "            break\n",
    "    print('Original Name: {} - Predicted Name: {}'.format(name.split()[0], name_prediction.split()[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
